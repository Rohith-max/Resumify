2025-04-16 16:32:37,072 - ResumeServer - INFO - Server running on http://localhost:8000
2025-04-16 16:43:10,578 - ResumeServer - INFO - Server stopping...
2025-04-16 16:43:10,579 - ResumeServer - INFO - Server stopped
2025-04-16 16:43:18,903 - ResumeServer - INFO - Server running on http://localhost:8000
2025-04-16 16:44:07,827 - ResumeServer - INFO - Server running on http://localhost:8000
2025-04-16 16:46:07,748 - ResumeServer - INFO - Server running on http://localhost:8000
2025-04-16 16:46:10,873 - ResumeServer - INFO - Server stopping...
2025-04-16 16:46:10,873 - ResumeServer - INFO - Server stopped
2025-04-16 16:46:21,200 - ResumeServer - INFO - GET request for /
2025-04-16 16:46:21,202 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 16:46:21,205 - ResumeServer - INFO - Served index.html successfully
2025-04-16 16:46:36,376 - ResumeServer - INFO - POST request to /generate (Content-Length: 6912)
2025-04-16 16:46:36,377 - ResumeServer - INFO - Processing /generate request
2025-04-16 16:46:36,380 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp44oex9st
2025-04-16 16:46:36,381 - ResumeServer - DEBUG - Parsing form data
2025-04-16 16:46:36,386 - ResumeServer - DEBUG - Form fields: ['job_desc', 'resume']
2025-04-16 16:46:36,387 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=posting.txt
2025-04-16 16:46:36,387 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 16:46:36,392 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 16:46:36,393 - ResumeServer - INFO - Generating resume...
2025-04-16 16:46:36,397 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 16:46:36,400 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 16:46:36,401 - ResumeServer - INFO - Initializing Groq client...
2025-04-16 16:46:37,512 - ResumeServer - INFO - Preparing messages for AI request...
2025-04-16 16:46:37,513 - ResumeServer - DEBUG - Using standard prompt (no template)
2025-04-16 16:46:37,513 - ResumeServer - INFO - Sending request to Groq API...
2025-04-16 16:46:37,524 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Respond with 'test ok'"}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 10, 'stream': False}}
2025-04-16 16:46:37,760 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 16:46:37,761 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-04-16 16:46:37,803 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC12F4080>
2025-04-16 16:46:37,805 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EFC1375ED0> server_hostname='api.groq.com' timeout=5.0
2025-04-16 16:46:37,885 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC12F4620>
2025-04-16 16:46:37,886 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 16:46:37,888 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 16:46:37,889 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 16:46:37,890 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 16:46:37,890 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 16:46:38,060 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 11:16:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'931345877d36f56a-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'999'), (b'X-Ratelimit-Remaining-Tokens', b'11990'), (b'X-Ratelimit-Reset-Requests', b'1m26.4s'), (b'X-Ratelimit-Reset-Tokens', b'50ms'), (b'X-Request-Id', b'req_01jrz51c6ser1s4y3prtgfsc36'), (b'Set-Cookie', b'__cf_bm=ZX6QfMd.9mwkfFd0OwwmtoiPFjLJuuH03ualN5g9crU-1744802197-1.0.1.1-3biWMtLg3Ym5N9IpDCPP9oDmM9qYF44mWQRvmFxa414xg313M3FHa91atTPQoLuU6w5SlfcNxqzKszgzo25iotKYjyMlQBpMfyf8uXEN19I; path=/; expires=Wed, 16-Apr-25 11:46:37 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 16:46:38,065 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 16:46:38,067 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 16:46:38,070 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 16:46:38,071 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 16:46:38,072 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 16:46:38,072 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 11:16:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '931345877d36f56a-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '999', 'x-ratelimit-remaining-tokens': '11990', 'x-ratelimit-reset-requests': '1m26.4s', 'x-ratelimit-reset-tokens': '50ms', 'x-request-id': 'req_01jrz51c6ser1s4y3prtgfsc36', 'set-cookie': '__cf_bm=ZX6QfMd.9mwkfFd0OwwmtoiPFjLJuuH03ualN5g9crU-1744802197-1.0.1.1-3biWMtLg3Ym5N9IpDCPP9oDmM9qYF44mWQRvmFxa414xg313M3FHa91atTPQoLuU6w5SlfcNxqzKszgzo25iotKYjyMlQBpMfyf8uXEN19I; path=/; expires=Wed, 16-Apr-25 11:46:37 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 16:46:38,084 - ResumeServer - INFO - API test successful: test ok
2025-04-16 16:46:38,085 - ResumeServer - INFO - Creating streaming completion...
2025-04-16 16:46:38,089 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a resume assistant. Format your response with HTML tags for styling. Use <strong> for bold, <h2> for section headers, <ul> and <li> for lists. Provide ONLY the resume content, no analysis or insights. Start directly with the resume content.'}, {'role': 'user', 'content': 'Create a tailored resume based on this resume and job description. Format the response with HTML tags. Provide ONLY the resume content, no analysis or insights.\n\nResume:\n\nResults-driven Machine Learning Engineer with 4+ years of experience developing and deploying AI models for diverse applications, including computer vision, NLP, and predictive analytics. Skilled in Python, TensorFlow, and cloud platforms like GCP. Adept at translating complex data into actionable insights and thriving in collaborative, fast-paced environments.\n\nProfessional Experience\n\nMachine Learning Engineer\n\nNexGen Technologies, Austin, TX\n\nAugust 2021 – Present\n\nBuilt convolutional neural networks (CNNs) with TensorFlow for image classification, achieving 92% accuracy on a custom dataset for retail product recognition.\nDesigned and deployed NLP models using BERT and Hugging Face for automated customer support, reducing response times by 40%.\nImplemented MLOps pipelines with Kubeflow and GCP, automating model retraining and monitoring for production systems.\nPreprocessed terabyte-scale datasets with Apache Spark, optimizing data pipelines for faster model training.\nMentored junior engineers on best practices for model development and version control with Git.\nData Scientist\n\nInsight Analytics, San Francisco, CA (Remote)\n\nJune 2020 – July 2021\n\nDeveloped time-series forecasting models with PyTorch to predict inventory demand, improving supply chain efficiency by 20%.\nConducted exploratory data analysis with pandas and SQL, uncovering trends that informed marketing strategies.\nCreated interactive dashboards with Plotly and Tableau to visualize model outputs for executive stakeholders.\nCollaborated with software engineers to integrate ML models into web applications using Flask APIs.\nResearch Intern, AI Lab\n\nStanford University, Stanford, CA\n\nJanuary 2019 – May 2020\n\nContributed to research on reinforcement learning algorithms, co-authoring a paper presented at NeurIPS 2020.\nBuilt simulation environments with OpenAI Gym to test agent performance in dynamic scenarios.\nOptimized model training workflows, reducing compute costs by 15% through efficient resource allocation.\nEducation\n\nMaster of Science in Artificial Intelligence\n\nCarnegie Mellon University, Pittsburgh, PA\n\nGraduated: May 2020\n\nFocus: Deep Learning and Reinforcement Learning\nCapstone Project: “Scalable RL Models for Autonomous Navigation”\nBachelor of Science in Computer Science\n\nUniversity of Texas at Austin, Austin, TX\n\nGraduated: May 2018\n\nMinor in Applied Mathematics\nSkills\n\nProgramming: Python, C++, SQL, Bash\nML Frameworks: TensorFlow, PyTorch, scikit-learn, Hugging Face, OpenCV\nCloud Platforms: Google Cloud Platform (AI Platform, BigQuery), AWS, Azure\nTools: Docker, Jenkins, MLflow, Git, Jupyter, Tableau\nData Processing: pandas, NumPy, Spark, Dask\nDomains: Computer Vision, NLP, Reinforcement Learning, Time-Series Analysis\nProjects\n\nAutonomous Drone Navigation (GitHub: github.com/alexcarter/drone-ai)\nDeveloped a reinforcement learning model with PyTorch to train drones for obstacle avoidance, tested in simulated environments.\nText Summarization Tool\nBuilt an NLP pipeline with Hugging Face transformers to generate concise summaries of news articles, deployed as a web app with Streamlit.\nFacial Recognition System\nCreated a real-time face detection model using OpenCV and TensorFlow, achieving 95% accuracy on public datasets.\nCertifications\n\nGoogle Cloud Professional Machine Learning Engineer (2023)\nCoursera: Deep Learning Specialization by Andrew Ng (2020)\nPublications & Talks\n\nCo-author, “Advances in Scalable Reinforcement Learning for Robotics,” NeurIPS 2020.\nGuest Speaker, “MLOps for Beginners,” Austin AI Meetup, March 2023.\nAdditional Information\n\nActive contributor to PyTorch (3 pull requests merged).\nVolunteer mentor at Code2AI, teaching high school students ML basics.\nProficient in French; conversational in Japanese.\n\nJob Description:\n\nJob Title: Machine Learning Engineer\n\nCompany: InnovateAI Solutions\n\nLocation: Remote (US-based preferred)\n\nPosted: April 15, 2025\n\nEmployment Type: Full-Time\n\nAbout InnovateAI Solutions:\n\nInnovateAI Solutions is a fast-growing tech company specializing in cutting-edge AI-driven products for healthcare and finance. Our mission is to empower businesses with intelligent solutions that transform industries.\n\nJob Description:\n\nWe are seeking a talented Machine Learning Engineer to join our AI Development team. You will design, develop, and deploy machine learning models to solve complex problems in predictive analytics and natural language processing. This role offers the opportunity to work on impactful projects with a collaborative, innovative team.\n\nKey Responsibilities:\n\nDevelop and optimize machine learning models for tasks such as classification, regression, and NLP.\nCollaborate with data scientists and software engineers to integrate models into production systems.\nConduct experiments to evaluate model performance and iterate on improvements.\nPreprocess and analyze large datasets to extract meaningful insights.\nStay updated on the latest AI/ML research and apply relevant advancements to projects.\nDocument processes and communicate findings to technical and non-technical stakeholders.\nQualifications:\n\nBachelor’s or Master’s degree in Computer Science, Data Science, or a related field.\n3+ years of experience building and deploying machine learning models.\nProficiency in Python and libraries such as TensorFlow, PyTorch, or scikit-learn.\nExperience with cloud platforms (e.g., AWS, Azure, or GCP) for model deployment.\nStrong understanding of algorithms, data structures, and statistics.\nFamiliarity with NLP techniques and tools (e.g., Hugging Face, spaCy) is a plus.\nExcellent problem-solving skills and ability to work in a fast-paced environment.\nPreferred Skills:\n\nExperience with MLOps tools (e.g., Kubeflow, MLflow).\nKnowledge of big data frameworks (e.g., Spark, Hadoop).\nContributions to open-source AI/ML projects or publications in relevant fields.\nBenefits:\n\nCompetitive salary and equity options.\nComprehensive health, dental, and vision insurance.\nFlexible work-from-home policy.\nAnnual learning stipend for professional development.\nCollaborative and inclusive team culture.\nHow to Apply:\n\nPlease submit your resume and a cover letter to careers@innovateai.com. Include links to your GitHub, LinkedIn, or portfolio if applicable. Applications will be reviewed on a rolling basis.\n\nInnovateAI Solutions is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2048, 'stream': True, 'temperature': 0.1, 'top_p': 1}}
2025-04-16 16:46:38,114 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 16:46:38,116 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 16:46:38,117 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 16:46:38,118 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 16:46:38,120 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 16:46:38,120 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 16:46:38,293 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 11:16:38 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'93134588f8a3f56a-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'no-cache'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'998'), (b'X-Ratelimit-Remaining-Tokens', b'10258'), (b'X-Ratelimit-Reset-Requests', b'2m52.565s'), (b'X-Ratelimit-Reset-Tokens', b'8.706999999s'), (b'X-Request-Id', b'req_01jrz51ce3fcebr3h93eeq3c52'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 16:46:38,296 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 16:46:38,298 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 11:16:38 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '93134588f8a3f56a-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'no-cache', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '998', 'x-ratelimit-remaining-tokens': '10258', 'x-ratelimit-reset-requests': '2m52.565s', 'x-ratelimit-reset-tokens': '8.706999999s', 'x-request-id': 'req_01jrz51ce3fcebr3h93eeq3c52', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 16:46:38,299 - ResumeServer - INFO - Collecting response chunks...
2025-04-16 16:46:38,301 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 16:46:38,486 - ResumeServer - DEBUG - Received 10 chunks, response length: 44
2025-04-16 16:46:38,490 - ResumeServer - DEBUG - Received 20 chunks, response length: 95
2025-04-16 16:46:38,512 - ResumeServer - DEBUG - Received 30 chunks, response length: 146
2025-04-16 16:46:38,558 - ResumeServer - DEBUG - Received 40 chunks, response length: 208
2025-04-16 16:46:38,562 - ResumeServer - DEBUG - Received 50 chunks, response length: 255
2025-04-16 16:46:38,567 - ResumeServer - DEBUG - Received 60 chunks, response length: 298
2025-04-16 16:46:38,580 - ResumeServer - DEBUG - Received 70 chunks, response length: 361
2025-04-16 16:46:38,590 - ResumeServer - DEBUG - Received 80 chunks, response length: 418
2025-04-16 16:46:38,610 - ResumeServer - DEBUG - Received 90 chunks, response length: 473
2025-04-16 16:46:38,633 - ResumeServer - DEBUG - Received 100 chunks, response length: 507
2025-04-16 16:46:38,641 - ResumeServer - DEBUG - Received 110 chunks, response length: 537
2025-04-16 16:46:38,663 - ResumeServer - DEBUG - Received 120 chunks, response length: 568
2025-04-16 16:46:38,696 - ResumeServer - DEBUG - Received 130 chunks, response length: 617
2025-04-16 16:46:38,699 - ResumeServer - DEBUG - Received 140 chunks, response length: 668
2025-04-16 16:46:38,704 - ResumeServer - DEBUG - Received 150 chunks, response length: 717
2025-04-16 16:46:38,709 - ResumeServer - DEBUG - Received 160 chunks, response length: 760
2025-04-16 16:46:38,718 - ResumeServer - DEBUG - Received 170 chunks, response length: 812
2025-04-16 16:46:38,727 - ResumeServer - DEBUG - Received 180 chunks, response length: 850
2025-04-16 16:46:38,754 - ResumeServer - DEBUG - Received 190 chunks, response length: 888
2025-04-16 16:46:38,761 - ResumeServer - DEBUG - Received 200 chunks, response length: 923
2025-04-16 16:46:38,772 - ResumeServer - DEBUG - Received 210 chunks, response length: 979
2025-04-16 16:46:38,787 - ResumeServer - DEBUG - Received 220 chunks, response length: 1021
2025-04-16 16:46:38,795 - ResumeServer - DEBUG - Received 230 chunks, response length: 1083
2025-04-16 16:46:38,820 - ResumeServer - DEBUG - Received 240 chunks, response length: 1113
2025-04-16 16:46:38,824 - ResumeServer - DEBUG - Received 250 chunks, response length: 1182
2025-04-16 16:46:38,842 - ResumeServer - DEBUG - Received 260 chunks, response length: 1217
2025-04-16 16:46:38,860 - ResumeServer - DEBUG - Received 270 chunks, response length: 1265
2025-04-16 16:46:38,871 - ResumeServer - DEBUG - Received 280 chunks, response length: 1292
2025-04-16 16:46:38,884 - ResumeServer - DEBUG - Received 290 chunks, response length: 1312
2025-04-16 16:46:38,895 - ResumeServer - DEBUG - Received 300 chunks, response length: 1362
2025-04-16 16:46:38,912 - ResumeServer - DEBUG - Received 310 chunks, response length: 1416
2025-04-16 16:46:38,929 - ResumeServer - DEBUG - Received 320 chunks, response length: 1448
2025-04-16 16:46:38,940 - ResumeServer - DEBUG - Received 330 chunks, response length: 1493
2025-04-16 16:46:38,952 - ResumeServer - DEBUG - Received 340 chunks, response length: 1551
2025-04-16 16:46:38,967 - ResumeServer - DEBUG - Received 350 chunks, response length: 1594
2025-04-16 16:46:38,992 - ResumeServer - DEBUG - Received 360 chunks, response length: 1642
2025-04-16 16:46:38,998 - ResumeServer - DEBUG - Received 370 chunks, response length: 1693
2025-04-16 16:46:39,003 - ResumeServer - DEBUG - Received 380 chunks, response length: 1745
2025-04-16 16:46:39,035 - ResumeServer - DEBUG - Received 390 chunks, response length: 1799
2025-04-16 16:46:39,040 - ResumeServer - DEBUG - Received 400 chunks, response length: 1832
2025-04-16 16:46:39,060 - ResumeServer - DEBUG - Received 410 chunks, response length: 1871
2025-04-16 16:46:39,065 - ResumeServer - DEBUG - Received 420 chunks, response length: 1898
2025-04-16 16:46:39,074 - ResumeServer - DEBUG - Received 430 chunks, response length: 1922
2025-04-16 16:46:39,107 - ResumeServer - DEBUG - Received 440 chunks, response length: 1985
2025-04-16 16:46:39,111 - ResumeServer - DEBUG - Received 450 chunks, response length: 2019
2025-04-16 16:46:39,124 - ResumeServer - DEBUG - Received 460 chunks, response length: 2061
2025-04-16 16:46:39,139 - ResumeServer - DEBUG - Received 470 chunks, response length: 2114
2025-04-16 16:46:39,151 - ResumeServer - DEBUG - Received 480 chunks, response length: 2146
2025-04-16 16:46:39,156 - ResumeServer - DEBUG - Received 490 chunks, response length: 2201
2025-04-16 16:46:39,166 - ResumeServer - DEBUG - Received 500 chunks, response length: 2251
2025-04-16 16:46:39,193 - ResumeServer - DEBUG - Received 510 chunks, response length: 2279
2025-04-16 16:46:39,201 - ResumeServer - DEBUG - Received 520 chunks, response length: 2327
2025-04-16 16:46:39,216 - ResumeServer - DEBUG - Received 530 chunks, response length: 2371
2025-04-16 16:46:39,243 - ResumeServer - DEBUG - Received 540 chunks, response length: 2396
2025-04-16 16:46:39,248 - ResumeServer - DEBUG - Received 550 chunks, response length: 2447
2025-04-16 16:46:39,278 - ResumeServer - DEBUG - Received 560 chunks, response length: 2479
2025-04-16 16:46:39,283 - ResumeServer - DEBUG - Received 570 chunks, response length: 2538
2025-04-16 16:46:39,288 - ResumeServer - DEBUG - Received 580 chunks, response length: 2586
2025-04-16 16:46:39,310 - ResumeServer - DEBUG - Received 590 chunks, response length: 2620
2025-04-16 16:46:39,315 - ResumeServer - DEBUG - Received 600 chunks, response length: 2644
2025-04-16 16:46:39,323 - ResumeServer - DEBUG - Received 610 chunks, response length: 2680
2025-04-16 16:46:39,347 - ResumeServer - DEBUG - Received 620 chunks, response length: 2712
2025-04-16 16:46:39,365 - ResumeServer - DEBUG - Received 630 chunks, response length: 2735
2025-04-16 16:46:39,378 - ResumeServer - DEBUG - Received 640 chunks, response length: 2769
2025-04-16 16:46:39,386 - ResumeServer - DEBUG - Received 650 chunks, response length: 2797
2025-04-16 16:46:39,397 - ResumeServer - DEBUG - Received 660 chunks, response length: 2821
2025-04-16 16:46:39,429 - ResumeServer - DEBUG - Received 670 chunks, response length: 2873
2025-04-16 16:46:39,436 - ResumeServer - DEBUG - Received 680 chunks, response length: 2902
2025-04-16 16:46:39,452 - ResumeServer - DEBUG - Received 690 chunks, response length: 2931
2025-04-16 16:46:39,462 - ResumeServer - DEBUG - Received 700 chunks, response length: 2961
2025-04-16 16:46:39,486 - ResumeServer - DEBUG - Received 710 chunks, response length: 2996
2025-04-16 16:46:39,495 - ResumeServer - DEBUG - Received 720 chunks, response length: 3020
2025-04-16 16:46:39,503 - ResumeServer - DEBUG - Received 730 chunks, response length: 3053
2025-04-16 16:46:39,512 - ResumeServer - DEBUG - Received 740 chunks, response length: 3103
2025-04-16 16:46:39,528 - ResumeServer - DEBUG - Received 750 chunks, response length: 3128
2025-04-16 16:46:39,549 - ResumeServer - DEBUG - Received 760 chunks, response length: 3145
2025-04-16 16:46:39,570 - ResumeServer - DEBUG - Received 770 chunks, response length: 3193
2025-04-16 16:46:39,582 - ResumeServer - DEBUG - Received 780 chunks, response length: 3219
2025-04-16 16:46:39,589 - ResumeServer - DEBUG - Received 790 chunks, response length: 3250
2025-04-16 16:46:39,616 - ResumeServer - DEBUG - Received 800 chunks, response length: 3285
2025-04-16 16:46:39,647 - ResumeServer - DEBUG - Received 810 chunks, response length: 3306
2025-04-16 16:46:39,653 - ResumeServer - DEBUG - Received 820 chunks, response length: 3332
2025-04-16 16:46:39,663 - ResumeServer - DEBUG - Received 830 chunks, response length: 3390
2025-04-16 16:46:39,687 - ResumeServer - DEBUG - Received 840 chunks, response length: 3411
2025-04-16 16:46:39,696 - ResumeServer - DEBUG - Received 850 chunks, response length: 3459
2025-04-16 16:46:39,717 - ResumeServer - DEBUG - Received 860 chunks, response length: 3478
2025-04-16 16:46:39,735 - ResumeServer - DEBUG - Received 870 chunks, response length: 3509
2025-04-16 16:46:39,750 - ResumeServer - DEBUG - Received 880 chunks, response length: 3535
2025-04-16 16:46:39,757 - ResumeServer - DEBUG - Received 890 chunks, response length: 3588
2025-04-16 16:46:39,766 - ResumeServer - DEBUG - Received 900 chunks, response length: 3608
2025-04-16 16:46:39,787 - ResumeServer - DEBUG - Received 910 chunks, response length: 3636
2025-04-16 16:46:39,813 - ResumeServer - DEBUG - Received 920 chunks, response length: 3676
2025-04-16 16:46:39,821 - ResumeServer - DEBUG - Received 930 chunks, response length: 3695
2025-04-16 16:46:39,830 - ResumeServer - DEBUG - Received 940 chunks, response length: 3731
2025-04-16 16:46:39,845 - ResumeServer - DEBUG - Received 950 chunks, response length: 3766
2025-04-16 16:46:39,863 - ResumeServer - DEBUG - Received 960 chunks, response length: 3801
2025-04-16 16:46:39,873 - ResumeServer - DEBUG - Received 970 chunks, response length: 3843
2025-04-16 16:46:39,891 - ResumeServer - DEBUG - Received 980 chunks, response length: 3881
2025-04-16 16:46:39,904 - ResumeServer - DEBUG - Received 990 chunks, response length: 3930
2025-04-16 16:46:42,050 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 16:46:42,050 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 16:46:42,051 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 16:46:42,052 - ResumeServer - INFO - Response collection complete. Total 997 chunks, final length: 3942
2025-04-16 16:46:42,053 - ResumeServer - INFO - Response preview: <h2>Results-Driven Machine Learning Engineer</h2>
Results-driven Machine Learning Engineer with 4+ y...
2025-04-16 16:46:42,062 - ResumeServer - INFO - Building PDF document...
2025-04-16 16:46:42,093 - ResumeServer - INFO - PDF generation successful, size: 6014 bytes
2025-04-16 16:46:42,094 - ResumeServer - INFO - Resume generated successfully. PDF size: 6014 bytes
2025-04-16 16:46:42,095 - ResumeServer - DEBUG - Converting response to JSON
2025-04-16 16:46:42,096 - ResumeServer - DEBUG - Response headers set: application/json
2025-04-16 16:46:42,097 - ResumeServer - INFO - Successfully sent PDF response
2025-04-16 16:46:42,099 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp44oex9st
2025-04-16 17:09:41,565 - ResumeServer - INFO - Server stopping...
2025-04-16 17:09:41,566 - ResumeServer - INFO - Server stopped
2025-04-16 17:09:55,261 - ResumeServer - INFO - Server running on http://localhost:8000
2025-04-16 17:10:04,234 - ResumeServer - INFO - GET request for /
2025-04-16 17:10:04,237 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 17:10:04,240 - ResumeServer - INFO - Served index.html successfully
2025-04-16 17:10:14,054 - ResumeServer - INFO - GET request for /api-test
2025-04-16 17:10:14,056 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 17:10:16,414 - ResumeServer - INFO - GET request for /api-test
2025-04-16 17:10:16,415 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 17:10:17,862 - ResumeServer - INFO - GET request for /api-test
2025-04-16 17:10:17,862 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 17:10:42,736 - ResumeServer - INFO - POST request to /generate (Content-Length: 13056)
2025-04-16 17:10:42,737 - ResumeServer - INFO - Processing /generate request
2025-04-16 17:10:42,737 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpclsrb72x
2025-04-16 17:10:42,738 - ResumeServer - DEBUG - Parsing form data
2025-04-16 17:10:42,740 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 17:10:42,740 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=jobDesc.txt
2025-04-16 17:10:42,741 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 17:10:42,743 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 17:10:42,744 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmpclsrb72x\template.txt
2025-04-16 17:10:42,745 - ResumeServer - INFO - Generating resume...
2025-04-16 17:10:42,747 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 17:10:42,749 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 17:10:42,750 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 17:10:42,754 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 17:10:42,755 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 17:10:44,756 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 17:10:44,757 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 17:10:44,759 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 17:10:44,761 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 17:10:44,761 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 17:10:46,762 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 17:10:46,763 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 17:10:46,763 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 17:10:46,764 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 17:10:46,764 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 17:10:46,767 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    try:
         
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 17:10:46,768 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 17:10:46,771 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpclsrb72x
2025-04-16 17:32:58,018 - ResumeServer - INFO - POST request to /generate (Content-Length: 13056)
2025-04-16 17:32:58,020 - ResumeServer - INFO - Processing /generate request
2025-04-16 17:32:58,021 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp5xrrav6y
2025-04-16 17:32:58,022 - ResumeServer - DEBUG - Parsing form data
2025-04-16 17:32:58,026 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 17:32:58,027 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=jobDesc.txt
2025-04-16 17:32:58,028 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 17:32:58,034 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 17:32:58,035 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmp5xrrav6y\template.txt
2025-04-16 17:32:58,036 - ResumeServer - INFO - Generating resume...
2025-04-16 17:32:58,038 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 17:32:58,042 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 17:32:58,044 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 17:32:58,048 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    job_desc_extension = os.path.splitext(job_desc_file.filename)[1]
                               ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 17:32:58,051 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 17:33:00,053 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 17:33:00,054 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 17:33:00,056 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 17:33:00,057 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    job_desc_extension = os.path.splitext(job_desc_file.filename)[1]
                               ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 17:33:00,059 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 17:33:02,061 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 17:33:02,063 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 17:33:02,065 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 17:33:02,067 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    job_desc_extension = os.path.splitext(job_desc_file.filename)[1]
                               ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 17:33:02,070 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 17:33:02,072 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    logger.error(error_msg)
                            
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    job_desc_extension = os.path.splitext(job_desc_file.filename)[1]
                               ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 17:33:02,075 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 17:33:02,079 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp5xrrav6y
2025-04-16 17:40:26,475 - ResumeServer - INFO - Server stopping...
2025-04-16 17:40:26,476 - ResumeServer - INFO - Server stopped
2025-04-16 17:40:33,795 - ResumeServer - INFO - GET request for /
2025-04-16 17:40:33,796 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 17:40:33,797 - ResumeServer - INFO - Served index.html successfully
2025-04-16 17:53:25,005 - ResumeServer - INFO - GET request for /
2025-04-16 17:53:25,007 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 17:53:25,008 - ResumeServer - INFO - Served index.html successfully
2025-04-16 17:53:26,205 - ResumeServer - INFO - GET request for /
2025-04-16 17:53:26,207 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 17:53:26,208 - ResumeServer - INFO - Served index.html successfully
2025-04-16 17:53:26,961 - ResumeServer - INFO - GET request for /
2025-04-16 17:53:26,963 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 17:53:26,965 - ResumeServer - INFO - Served index.html successfully
2025-04-16 17:53:57,528 - ResumeServer - INFO - POST request to /generate (Content-Length: 14320)
2025-04-16 17:53:57,529 - ResumeServer - INFO - Processing /generate request
2025-04-16 17:53:57,530 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpkd33btky
2025-04-16 17:53:57,531 - ResumeServer - DEBUG - Parsing form data
2025-04-16 17:53:57,539 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 17:53:57,540 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=posting.txt
2025-04-16 17:53:57,540 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 17:53:57,546 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 17:53:57,549 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmpkd33btky\template.txt
2025-04-16 17:53:57,550 - ResumeServer - INFO - Generating resume...
2025-04-16 17:53:57,555 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 17:53:57,582 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 17:53:57,587 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 17:53:57,591 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    self._handle_error(500, error_msg)
                   ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 17:53:57,594 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 17:53:59,595 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 17:53:59,597 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 17:53:59,598 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 17:53:59,599 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    self._handle_error(500, error_msg)
                   ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 17:53:59,601 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 17:54:01,602 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 17:54:01,602 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 17:54:01,603 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 17:54:01,603 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    self._handle_error(500, error_msg)
                   ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 17:54:01,605 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 17:54:01,607 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    template_text = None
                         
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    self._handle_error(500, error_msg)
                   ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 17:54:01,608 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 17:54:01,610 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpkd33btky
2025-04-16 18:02:42,314 - ResumeServer - INFO - GET request for /
2025-04-16 18:02:42,315 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 18:02:42,316 - ResumeServer - INFO - Served index.html successfully
2025-04-16 18:04:36,477 - ResumeServer - INFO - GET request for /
2025-04-16 18:04:36,478 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 18:04:36,480 - ResumeServer - INFO - Served index.html successfully
2025-04-16 18:06:31,088 - ResumeServer - INFO - GET request for /
2025-04-16 18:06:31,089 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 18:06:31,090 - ResumeServer - INFO - Served index.html successfully
2025-04-16 18:07:06,901 - ResumeServer - INFO - POST request to /generate (Content-Length: 7398)
2025-04-16 18:07:06,902 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:07:06,903 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpjitwrj3c
2025-04-16 18:07:06,903 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:07:06,906 - ResumeServer - DEBUG - Form fields: ['job_desc', 'resume']
2025-04-16 18:07:06,906 - ResumeServer - INFO - Got files: resume=resume.pdf, job_desc=jobDesc.txt
2025-04-16 18:07:06,907 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:07:06,908 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:07:06,909 - ResumeServer - INFO - Generating resume...
2025-04-16 18:07:06,921 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:07:06,923 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    error_msg = f"Error in JSON conversion: {str(e)}"
         ^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:07:06,923 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:07:08,925 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:07:08,925 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    error_msg = f"Error in JSON conversion: {str(e)}"
         ^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:07:08,927 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:07:10,928 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:07:10,929 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    error_msg = f"Error in JSON conversion: {str(e)}"
         ^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:07:10,929 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:07:10,930 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    template_text = None
                         
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    error_msg = f"Error in JSON conversion: {str(e)}"
         ^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:07:10,933 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:07:10,935 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpjitwrj3c
2025-04-16 18:10:58,764 - ResumeServer - INFO - GET request for /
2025-04-16 18:10:58,765 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 18:10:58,766 - ResumeServer - INFO - Served index.html successfully
2025-04-16 18:11:18,520 - ResumeServer - INFO - POST request to /generate (Content-Length: 14320)
2025-04-16 18:11:18,521 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:11:18,522 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp6e2a_ijo
2025-04-16 18:11:18,522 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:11:18,526 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 18:11:18,527 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=posting.txt
2025-04-16 18:11:18,527 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:11:18,530 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:11:18,531 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmp6e2a_ijo\template.txt
2025-04-16 18:11:18,531 - ResumeServer - INFO - Generating resume...
2025-04-16 18:11:18,535 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:11:18,537 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 18:11:18,540 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:11:18,542 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    logger.error(f"Response content type: {type(response)}")
               ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:11:18,543 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:11:20,544 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:11:20,545 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 18:11:20,546 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:11:20,547 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    logger.error(f"Response content type: {type(response)}")
               ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:11:20,548 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:11:22,549 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:11:22,549 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 18:11:22,551 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:11:22,553 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    logger.error(f"Response content type: {type(response)}")
               ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:11:22,554 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:11:22,555 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    f.write(template_file.file.read())
                        ^^^^^^^^^^^^^^^
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    logger.error(f"Response content type: {type(response)}")
               ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:11:22,558 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:11:22,562 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp6e2a_ijo
2025-04-16 18:12:57,049 - ResumeServer - INFO - POST request to /generate (Content-Length: 14320)
2025-04-16 18:12:57,050 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:12:57,051 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp3uv4obyr
2025-04-16 18:12:57,052 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:12:57,056 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 18:12:57,057 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=posting.txt
2025-04-16 18:12:57,057 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:12:57,060 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:12:57,063 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmp3uv4obyr\template.txt
2025-04-16 18:12:57,064 - ResumeServer - INFO - Generating resume...
2025-04-16 18:12:57,067 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:12:57,071 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 18:12:57,075 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:12:57,079 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    return
           
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:12:57,081 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:12:59,083 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:12:59,084 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 18:12:59,085 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:12:59,086 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    return
           
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:12:59,088 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:13:01,089 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:13:01,094 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 18:13:01,096 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:13:01,099 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    return
           
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:13:01,100 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:13:01,102 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    resume_path = os.path.join(temp_dir, f'resume{resume_ext}')
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    return
           
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:13:01,105 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:13:01,108 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp3uv4obyr
2025-04-16 18:13:03,049 - ResumeServer - INFO - GET request for /
2025-04-16 18:13:03,050 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 18:13:03,051 - ResumeServer - INFO - Served index.html successfully
2025-04-16 18:13:39,439 - ResumeServer - INFO - POST request to /generate (Content-Length: 14806)
2025-04-16 18:13:39,439 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:13:39,440 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmphic2zd0b
2025-04-16 18:13:39,440 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:13:39,443 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 18:13:39,443 - ResumeServer - INFO - Got files: resume=resume.pdf, job_desc=jobDesc.txt
2025-04-16 18:13:39,443 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:13:39,444 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:13:39,444 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmphic2zd0b\template.txt
2025-04-16 18:13:39,445 - ResumeServer - INFO - Generating resume...
2025-04-16 18:13:39,447 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:13:39,448 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:13:39,449 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:13:41,450 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:13:41,451 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:13:41,454 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:13:43,455 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:13:43,456 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:13:43,457 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:13:43,458 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    resume_path = os.path.join(temp_dir, f'resume{resume_ext}')
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:13:43,459 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:13:43,460 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmphic2zd0b
2025-04-16 18:14:35,074 - ResumeServer - INFO - GET request for /
2025-04-16 18:14:35,075 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 18:14:35,076 - ResumeServer - INFO - Served index.html successfully
2025-04-16 18:15:07,905 - ResumeServer - INFO - POST request to /generate (Content-Length: 16070)
2025-04-16 18:15:07,906 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:15:07,907 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp1iczw3qc
2025-04-16 18:15:07,908 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:15:07,916 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 18:15:07,917 - ResumeServer - INFO - Got files: resume=resume.pdf, job_desc=posting.txt
2025-04-16 18:15:07,919 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:15:07,923 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:15:07,926 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmp1iczw3qc\template.txt
2025-04-16 18:15:07,927 - ResumeServer - INFO - Generating resume...
2025-04-16 18:15:07,931 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:15:07,937 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    except Exception as e:
             ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:15:07,940 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:15:09,941 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:15:09,943 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    except Exception as e:
             ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:15:09,944 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:15:11,946 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:15:11,948 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    except Exception as e:
             ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:15:11,949 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:15:11,951 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    resume_path = os.path.join(temp_dir, f'resume{resume_ext}')
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    except Exception as e:
             ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:15:11,953 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:15:11,956 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp1iczw3qc
2025-04-16 18:15:32,702 - ResumeServer - INFO - POST request to /generate (Content-Length: 16070)
2025-04-16 18:15:32,703 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:15:32,704 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpum17uuge
2025-04-16 18:15:32,704 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:15:32,707 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 18:15:32,708 - ResumeServer - INFO - Got files: resume=resume.pdf, job_desc=posting.txt
2025-04-16 18:15:32,708 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:15:32,710 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:15:32,711 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmpum17uuge\template.txt
2025-04-16 18:15:32,712 - ResumeServer - INFO - Generating resume...
2025-04-16 18:15:32,714 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:15:32,716 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    except Exception as e:
             ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:15:32,717 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:15:34,718 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:15:34,718 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    except Exception as e:
             ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:15:34,720 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:15:36,722 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:15:36,723 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    except Exception as e:
             ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:15:36,724 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:15:36,725 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    resume_path = os.path.join(temp_dir, f'resume{resume_ext}')
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    except Exception as e:
             ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:15:36,727 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:15:36,730 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpum17uuge
2025-04-16 18:16:37,196 - ResumeServer - INFO - GET request for /
2025-04-16 18:16:37,198 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 18:16:37,199 - ResumeServer - INFO - Served index.html successfully
2025-04-16 18:17:03,805 - ResumeServer - INFO - POST request to /generate (Content-Length: 13056)
2025-04-16 18:17:03,806 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:17:03,807 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmppqtlsx7f
2025-04-16 18:17:03,808 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:17:03,813 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 18:17:03,814 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=jobDesc.txt
2025-04-16 18:17:03,815 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:17:03,819 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:17:03,820 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmppqtlsx7f\template.txt
2025-04-16 18:17:03,822 - ResumeServer - INFO - Generating resume...
2025-04-16 18:17:03,825 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:17:03,828 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 18:17:03,833 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:17:03,836 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    'mime_type': 'application/pdf'
               ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:17:03,839 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:17:05,840 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:17:05,840 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 18:17:05,841 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:17:05,842 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    'mime_type': 'application/pdf'
               ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:17:05,843 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:17:07,844 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:17:07,846 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 18:17:07,846 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:17:07,847 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    'mime_type': 'application/pdf'
               ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:17:07,847 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:17:07,848 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    resume_path = os.path.join(temp_dir, f'resume{resume_ext}')
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    'mime_type': 'application/pdf'
               ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:17:07,849 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:17:07,851 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmppqtlsx7f
2025-04-16 18:18:56,510 - ResumeServer - INFO - POST request to /generate (Content-Length: 13056)
2025-04-16 18:18:56,511 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:18:56,511 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpquj8ykp2
2025-04-16 18:18:56,511 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:18:56,514 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 18:18:56,515 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=jobDesc.txt
2025-04-16 18:18:56,515 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:18:56,516 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:18:56,517 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmpquj8ykp2\template.txt
2025-04-16 18:18:56,517 - ResumeServer - INFO - Generating resume...
2025-04-16 18:18:56,518 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:18:56,520 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 18:18:56,522 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:18:56,523 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    'mime_type': 'application/pdf'
               ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:18:56,525 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:18:58,525 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:18:58,526 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 18:18:58,526 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:18:58,527 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    'mime_type': 'application/pdf'
               ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:18:58,529 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:19:00,530 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:19:00,531 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 18:19:00,531 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:19:00,532 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    'mime_type': 'application/pdf'
               ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:19:00,533 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:19:00,534 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    resume_path = os.path.join(temp_dir, f'resume{resume_ext}')
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    'mime_type': 'application/pdf'
               ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:19:00,535 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:19:00,537 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpquj8ykp2
2025-04-16 18:21:42,782 - ResumeServer - INFO - Server running on http://localhost:8000
2025-04-16 18:21:55,920 - ResumeServer - INFO - GET request for /
2025-04-16 18:21:55,921 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 18:21:55,921 - ResumeServer - INFO - Served index.html successfully
2025-04-16 18:22:15,123 - ResumeServer - INFO - POST request to /generate (Content-Length: 14806)
2025-04-16 18:22:15,124 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:22:15,125 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpjpsk904x
2025-04-16 18:22:15,126 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:22:15,133 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 18:22:15,134 - ResumeServer - INFO - Got files: resume=resume.pdf, job_desc=jobDesc.txt
2025-04-16 18:22:15,134 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:22:15,140 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:22:15,142 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmpjpsk904x\template.txt
2025-04-16 18:22:15,143 - ResumeServer - INFO - Generating resume...
2025-04-16 18:22:15,148 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:22:15,151 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:22:15,152 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:22:17,154 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:22:17,155 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:22:17,156 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:22:19,158 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:22:19,159 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:22:19,162 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:22:19,163 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    f.write(resume_file.file.read())
                                ^^^^^
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:22:19,164 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:22:19,166 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpjpsk904x
2025-04-16 18:22:31,800 - ResumeServer - INFO - POST request to /generate (Content-Length: 5648)
2025-04-16 18:22:31,801 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:22:31,802 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpj7164hm6
2025-04-16 18:22:31,802 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:22:31,805 - ResumeServer - DEBUG - Form fields: ['job_desc', 'resume']
2025-04-16 18:22:31,806 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=jobDesc.txt
2025-04-16 18:22:31,806 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:22:31,808 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:22:31,808 - ResumeServer - INFO - Generating resume...
2025-04-16 18:22:31,810 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:22:31,812 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 18:22:31,812 - ResumeServer - INFO - Initializing Groq client...
2025-04-16 18:22:32,362 - ResumeServer - INFO - Preparing messages for AI request...
2025-04-16 18:22:32,362 - ResumeServer - DEBUG - Using standard prompt (no template)
2025-04-16 18:22:32,362 - ResumeServer - INFO - Sending request to Groq API...
2025-04-16 18:22:32,367 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Respond with 'test ok'"}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 10, 'stream': False}}
2025-04-16 18:22:32,369 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 18:22:32,370 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-04-16 18:22:32,512 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC13F1EE0>
2025-04-16 18:22:32,514 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EFC0BC6750> server_hostname='api.groq.com' timeout=5.0
2025-04-16 18:22:32,574 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC0E40FB0>
2025-04-16 18:22:32,575 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 18:22:32,576 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 18:22:32,576 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 18:22:32,577 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 18:22:32,578 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 18:22:32,730 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 12:52:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'9313d2070f3e7f78-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'999'), (b'X-Ratelimit-Remaining-Tokens', b'11990'), (b'X-Ratelimit-Reset-Requests', b'1m26.4s'), (b'X-Ratelimit-Reset-Tokens', b'50ms'), (b'X-Request-Id', b'req_01jrzah042ffe8hk3wb5s48mt9'), (b'Set-Cookie', b'__cf_bm=woqhHLHbSUB3KDWhKNpejrlcXtgJ_SLVvY_c9sovweY-1744807952-1.0.1.1-RD992Ados1BgBGDBq6wN3sw9gk8b.cq7K2hI3vBoMHQB9NSVTNVz9n9i2PYp9ve9KZgGwfN2Q9ZxMKbYBS513i0YOrgCHVpIDQB53Gp50Aw; path=/; expires=Wed, 16-Apr-25 13:22:32 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 18:22:32,734 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 18:22:32,735 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 18:22:32,736 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 18:22:32,737 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 18:22:32,737 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 18:22:32,737 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 12:52:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9313d2070f3e7f78-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '999', 'x-ratelimit-remaining-tokens': '11990', 'x-ratelimit-reset-requests': '1m26.4s', 'x-ratelimit-reset-tokens': '50ms', 'x-request-id': 'req_01jrzah042ffe8hk3wb5s48mt9', 'set-cookie': '__cf_bm=woqhHLHbSUB3KDWhKNpejrlcXtgJ_SLVvY_c9sovweY-1744807952-1.0.1.1-RD992Ados1BgBGDBq6wN3sw9gk8b.cq7K2hI3vBoMHQB9NSVTNVz9n9i2PYp9ve9KZgGwfN2Q9ZxMKbYBS513i0YOrgCHVpIDQB53Gp50Aw; path=/; expires=Wed, 16-Apr-25 13:22:32 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 18:22:32,740 - ResumeServer - INFO - API test successful: test ok
2025-04-16 18:22:32,740 - ResumeServer - INFO - Creating streaming completion...
2025-04-16 18:22:32,742 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a resume assistant. Format your response with HTML tags for styling. Use <strong> for bold, <h2> for section headers, <ul> and <li> for lists. Provide ONLY the resume content, no analysis or insights. Start directly with the resume content.'}, {'role': 'user', 'content': "Create a tailored resume based on this resume and job description. Format the response with HTML tags. Provide ONLY the resume content, no analysis or insights.\n\nResume:\n\nResults-driven Machine Learning Engineer with 4+ years of experience developing and deploying AI models for diverse applications, including computer vision, NLP, and predictive analytics. Skilled in Python, TensorFlow, and cloud platforms like GCP. Adept at translating complex data into actionable insights and thriving in collaborative, fast-paced environments.\n\nProfessional Experience\n\nMachine Learning Engineer\n\nNexGen Technologies, Austin, TX\n\nAugust 2021 – Present\n\nBuilt convolutional neural networks (CNNs) with TensorFlow for image classification, achieving 92% accuracy on a custom dataset for retail product recognition.\nDesigned and deployed NLP models using BERT and Hugging Face for automated customer support, reducing response times by 40%.\nImplemented MLOps pipelines with Kubeflow and GCP, automating model retraining and monitoring for production systems.\nPreprocessed terabyte-scale datasets with Apache Spark, optimizing data pipelines for faster model training.\nMentored junior engineers on best practices for model development and version control with Git.\nData Scientist\n\nInsight Analytics, San Francisco, CA (Remote)\n\nJune 2020 – July 2021\n\nDeveloped time-series forecasting models with PyTorch to predict inventory demand, improving supply chain efficiency by 20%.\nConducted exploratory data analysis with pandas and SQL, uncovering trends that informed marketing strategies.\nCreated interactive dashboards with Plotly and Tableau to visualize model outputs for executive stakeholders.\nCollaborated with software engineers to integrate ML models into web applications using Flask APIs.\nResearch Intern, AI Lab\n\nStanford University, Stanford, CA\n\nJanuary 2019 – May 2020\n\nContributed to research on reinforcement learning algorithms, co-authoring a paper presented at NeurIPS 2020.\nBuilt simulation environments with OpenAI Gym to test agent performance in dynamic scenarios.\nOptimized model training workflows, reducing compute costs by 15% through efficient resource allocation.\nEducation\n\nMaster of Science in Artificial Intelligence\n\nCarnegie Mellon University, Pittsburgh, PA\n\nGraduated: May 2020\n\nFocus: Deep Learning and Reinforcement Learning\nCapstone Project: “Scalable RL Models for Autonomous Navigation”\nBachelor of Science in Computer Science\n\nUniversity of Texas at Austin, Austin, TX\n\nGraduated: May 2018\n\nMinor in Applied Mathematics\nSkills\n\nProgramming: Python, C++, SQL, Bash\nML Frameworks: TensorFlow, PyTorch, scikit-learn, Hugging Face, OpenCV\nCloud Platforms: Google Cloud Platform (AI Platform, BigQuery), AWS, Azure\nTools: Docker, Jenkins, MLflow, Git, Jupyter, Tableau\nData Processing: pandas, NumPy, Spark, Dask\nDomains: Computer Vision, NLP, Reinforcement Learning, Time-Series Analysis\nProjects\n\nAutonomous Drone Navigation (GitHub: github.com/alexcarter/drone-ai)\nDeveloped a reinforcement learning model with PyTorch to train drones for obstacle avoidance, tested in simulated environments.\nText Summarization Tool\nBuilt an NLP pipeline with Hugging Face transformers to generate concise summaries of news articles, deployed as a web app with Streamlit.\nFacial Recognition System\nCreated a real-time face detection model using OpenCV and TensorFlow, achieving 95% accuracy on public datasets.\nCertifications\n\nGoogle Cloud Professional Machine Learning Engineer (2023)\nCoursera: Deep Learning Specialization by Andrew Ng (2020)\nPublications & Talks\n\nCo-author, “Advances in Scalable Reinforcement Learning for Robotics,” NeurIPS 2020.\nGuest Speaker, “MLOps for Beginners,” Austin AI Meetup, March 2023.\nAdditional Information\n\nActive contributor to PyTorch (3 pull requests merged).\nVolunteer mentor at Code2AI, teaching high school students ML basics.\nProficient in French; conversational in Japanese.\n\nJob Description:\n\nSoftware Engineer - Full Stack Developer\n\nCompany: Tech Innovations Inc.\nLocation: Remote\nType: Full-time\n\nJob Description:\nWe are seeking a skilled Full Stack Developer to join our dynamic team. The ideal candidate will be responsible for developing and maintaining web applications using modern technologies.\n\nResponsibilities:\n- Design and implement scalable web applications\n- Develop front-end interfaces using React.js\n- Create and maintain back-end services using Node.js and Python\n- Work with databases (SQL and NoSQL)\n- Implement RESTful APIs\n- Write clean, maintainable code\n- Collaborate with cross-functional teams\n- Participate in code reviews and technical discussions\n\nRequirements:\n- Bachelor's degree in Computer Science or related field\n- 3+ years of experience in full-stack development\n- Strong proficiency in JavaScript, Python, and SQL\n- Experience with React.js and Node.js\n- Knowledge of cloud platforms (AWS, Azure, or GCP)\n- Familiarity with version control systems (Git)\n- Excellent problem-solving skills\n- Strong communication and teamwork abilities\n\nPreferred Qualifications:\n- Experience with containerization (Docker)\n- Knowledge of CI/CD pipelines\n- Understanding of microservices architecture\n- Contributions to open-source projects\n\nBenefits:\n- Competitive salary\n- Health insurance\n- 401(k) matching\n- Flexible work hours\n- Professional development opportunities\n- Remote work options "}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2048, 'stream': True, 'temperature': 0.1, 'top_p': 1}}
2025-04-16 18:22:32,751 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 18:22:32,751 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 18:22:32,752 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 18:22:32,752 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 18:22:32,752 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 18:22:32,752 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 18:22:32,967 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 12:52:32 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'9313d208282e7f78-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'no-cache'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'998'), (b'X-Ratelimit-Remaining-Tokens', b'10564'), (b'X-Ratelimit-Reset-Requests', b'2m52.601s'), (b'X-Ratelimit-Reset-Tokens', b'7.176s'), (b'X-Request-Id', b'req_01jrzah0abf8aa294gv2jjsh20'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 18:22:32,971 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 18:22:32,972 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 12:52:32 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9313d208282e7f78-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'no-cache', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '998', 'x-ratelimit-remaining-tokens': '10564', 'x-ratelimit-reset-requests': '2m52.601s', 'x-ratelimit-reset-tokens': '7.176s', 'x-request-id': 'req_01jrzah0abf8aa294gv2jjsh20', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 18:22:32,974 - ResumeServer - INFO - Collecting response chunks...
2025-04-16 18:22:32,975 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 18:22:33,072 - ResumeServer - DEBUG - Received 10 chunks, response length: 34
2025-04-16 18:22:33,076 - ResumeServer - DEBUG - Received 20 chunks, response length: 78
2025-04-16 18:22:33,081 - ResumeServer - DEBUG - Received 30 chunks, response length: 127
2025-04-16 18:22:33,132 - ResumeServer - DEBUG - Received 40 chunks, response length: 209
2025-04-16 18:22:33,136 - ResumeServer - DEBUG - Received 50 chunks, response length: 247
2025-04-16 18:22:33,179 - ResumeServer - DEBUG - Received 60 chunks, response length: 307
2025-04-16 18:22:33,191 - ResumeServer - DEBUG - Received 70 chunks, response length: 364
2025-04-16 18:22:33,214 - ResumeServer - DEBUG - Received 80 chunks, response length: 425
2025-04-16 18:22:33,241 - ResumeServer - DEBUG - Received 90 chunks, response length: 481
2025-04-16 18:22:33,256 - ResumeServer - DEBUG - Received 100 chunks, response length: 530
2025-04-16 18:22:33,279 - ResumeServer - DEBUG - Received 110 chunks, response length: 568
2025-04-16 18:22:33,316 - ResumeServer - DEBUG - Received 120 chunks, response length: 603
2025-04-16 18:22:33,319 - ResumeServer - DEBUG - Received 130 chunks, response length: 638
2025-04-16 18:22:33,337 - ResumeServer - DEBUG - Received 140 chunks, response length: 690
2025-04-16 18:22:33,349 - ResumeServer - DEBUG - Received 150 chunks, response length: 730
2025-04-16 18:22:33,359 - ResumeServer - DEBUG - Received 160 chunks, response length: 794
2025-04-16 18:22:33,378 - ResumeServer - DEBUG - Received 170 chunks, response length: 833
2025-04-16 18:22:33,393 - ResumeServer - DEBUG - Received 180 chunks, response length: 893
2025-04-16 18:22:33,408 - ResumeServer - DEBUG - Received 190 chunks, response length: 932
2025-04-16 18:22:33,423 - ResumeServer - DEBUG - Received 200 chunks, response length: 982
2025-04-16 18:22:33,455 - ResumeServer - DEBUG - Received 210 chunks, response length: 1043
2025-04-16 18:22:33,458 - ResumeServer - DEBUG - Received 220 chunks, response length: 1108
2025-04-16 18:22:33,469 - ResumeServer - DEBUG - Received 230 chunks, response length: 1152
2025-04-16 18:22:33,488 - ResumeServer - DEBUG - Received 240 chunks, response length: 1186
2025-04-16 18:22:33,503 - ResumeServer - DEBUG - Received 250 chunks, response length: 1209
2025-04-16 18:22:33,520 - ResumeServer - DEBUG - Received 260 chunks, response length: 1264
2025-04-16 18:22:33,532 - ResumeServer - DEBUG - Received 270 chunks, response length: 1330
2025-04-16 18:22:33,540 - ResumeServer - DEBUG - Received 280 chunks, response length: 1373
2025-04-16 18:22:33,557 - ResumeServer - DEBUG - Received 290 chunks, response length: 1426
2025-04-16 18:22:33,567 - ResumeServer - DEBUG - Received 300 chunks, response length: 1491
2025-04-16 18:22:33,576 - ResumeServer - DEBUG - Received 310 chunks, response length: 1546
2025-04-16 18:22:33,624 - ResumeServer - DEBUG - Received 320 chunks, response length: 1612
2025-04-16 18:22:33,627 - ResumeServer - DEBUG - Received 330 chunks, response length: 1672
2025-04-16 18:22:33,629 - ResumeServer - DEBUG - Received 340 chunks, response length: 1712
2025-04-16 18:22:33,648 - ResumeServer - DEBUG - Received 350 chunks, response length: 1743
2025-04-16 18:22:33,658 - ResumeServer - DEBUG - Received 360 chunks, response length: 1770
2025-04-16 18:22:33,683 - ResumeServer - DEBUG - Received 370 chunks, response length: 1833
2025-04-16 18:22:33,695 - ResumeServer - DEBUG - Received 380 chunks, response length: 1867
2025-04-16 18:22:33,712 - ResumeServer - DEBUG - Received 390 chunks, response length: 1919
2025-04-16 18:22:33,732 - ResumeServer - DEBUG - Received 400 chunks, response length: 1976
2025-04-16 18:22:33,735 - ResumeServer - DEBUG - Received 410 chunks, response length: 2031
2025-04-16 18:22:33,759 - ResumeServer - DEBUG - Received 420 chunks, response length: 2086
2025-04-16 18:22:33,775 - ResumeServer - DEBUG - Received 430 chunks, response length: 2137
2025-04-16 18:22:33,777 - ResumeServer - DEBUG - Received 440 chunks, response length: 2181
2025-04-16 18:22:33,782 - ResumeServer - DEBUG - Received 450 chunks, response length: 2206
2025-04-16 18:22:33,799 - ResumeServer - DEBUG - Received 460 chunks, response length: 2243
2025-04-16 18:22:33,822 - ResumeServer - DEBUG - Received 470 chunks, response length: 2285
2025-04-16 18:22:33,835 - ResumeServer - DEBUG - Received 480 chunks, response length: 2341
2025-04-16 18:22:33,840 - ResumeServer - DEBUG - Received 490 chunks, response length: 2394
2025-04-16 18:22:33,866 - ResumeServer - DEBUG - Received 500 chunks, response length: 2426
2025-04-16 18:22:33,872 - ResumeServer - DEBUG - Received 510 chunks, response length: 2453
2025-04-16 18:22:33,886 - ResumeServer - DEBUG - Received 520 chunks, response length: 2489
2025-04-16 18:22:33,901 - ResumeServer - DEBUG - Received 530 chunks, response length: 2524
2025-04-16 18:22:33,937 - ResumeServer - DEBUG - Received 540 chunks, response length: 2564
2025-04-16 18:22:33,950 - ResumeServer - DEBUG - Received 550 chunks, response length: 2595
2025-04-16 18:22:33,967 - ResumeServer - DEBUG - Received 560 chunks, response length: 2624
2025-04-16 18:22:33,983 - ResumeServer - DEBUG - Received 570 chunks, response length: 2677
2025-04-16 18:22:33,997 - ResumeServer - DEBUG - Received 580 chunks, response length: 2708
2025-04-16 18:22:34,005 - ResumeServer - DEBUG - Received 590 chunks, response length: 2740
2025-04-16 18:22:34,019 - ResumeServer - DEBUG - Received 600 chunks, response length: 2781
2025-04-16 18:22:34,038 - ResumeServer - DEBUG - Received 610 chunks, response length: 2803
2025-04-16 18:22:34,053 - ResumeServer - DEBUG - Received 620 chunks, response length: 2839
2025-04-16 18:22:34,065 - ResumeServer - DEBUG - Received 630 chunks, response length: 2885
2025-04-16 18:22:34,096 - ResumeServer - DEBUG - Received 640 chunks, response length: 2913
2025-04-16 18:22:34,108 - ResumeServer - DEBUG - Received 650 chunks, response length: 2962
2025-04-16 18:22:34,125 - ResumeServer - DEBUG - Received 660 chunks, response length: 2988
2025-04-16 18:22:34,144 - ResumeServer - DEBUG - Received 670 chunks, response length: 3040
2025-04-16 18:22:34,161 - ResumeServer - DEBUG - Received 680 chunks, response length: 3094
2025-04-16 18:22:34,169 - ResumeServer - DEBUG - Received 690 chunks, response length: 3140
2025-04-16 18:22:34,179 - ResumeServer - DEBUG - Received 700 chunks, response length: 3175
2025-04-16 18:22:34,201 - ResumeServer - DEBUG - Received 710 chunks, response length: 3237
2025-04-16 18:22:34,207 - ResumeServer - DEBUG - Received 720 chunks, response length: 3287
2025-04-16 18:22:34,238 - ResumeServer - DEBUG - Received 730 chunks, response length: 3320
2025-04-16 18:22:34,243 - ResumeServer - DEBUG - Received 740 chunks, response length: 3366
2025-04-16 18:22:34,250 - ResumeServer - DEBUG - Received 750 chunks, response length: 3421
2025-04-16 18:22:34,280 - ResumeServer - DEBUG - Received 760 chunks, response length: 3468
2025-04-16 18:22:34,288 - ResumeServer - DEBUG - Received 770 chunks, response length: 3499
2025-04-16 18:22:34,308 - ResumeServer - DEBUG - Received 780 chunks, response length: 3553
2025-04-16 18:22:34,317 - ResumeServer - DEBUG - Received 790 chunks, response length: 3602
2025-04-16 18:22:34,347 - ResumeServer - DEBUG - Received 800 chunks, response length: 3630
2025-04-16 18:22:34,355 - ResumeServer - DEBUG - Received 810 chunks, response length: 3657
2025-04-16 18:22:34,363 - ResumeServer - DEBUG - Received 820 chunks, response length: 3706
2025-04-16 18:22:34,380 - ResumeServer - DEBUG - Received 830 chunks, response length: 3733
2025-04-16 18:22:34,401 - ResumeServer - DEBUG - Received 840 chunks, response length: 3771
2025-04-16 18:22:34,404 - ResumeServer - DEBUG - Received 850 chunks, response length: 3803
2025-04-16 18:22:34,430 - ResumeServer - DEBUG - Received 860 chunks, response length: 3837
2025-04-16 18:22:34,437 - ResumeServer - DEBUG - Received 870 chunks, response length: 3884
2025-04-16 18:22:34,450 - ResumeServer - DEBUG - Received 880 chunks, response length: 3924
2025-04-16 18:22:34,458 - ResumeServer - DEBUG - Received 890 chunks, response length: 3978
2025-04-16 18:22:36,276 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 18:22:36,277 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 18:22:36,277 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 18:22:36,278 - ResumeServer - INFO - Response collection complete. Total 899 chunks, final length: 4017
2025-04-16 18:22:36,278 - ResumeServer - INFO - Response preview: <h2>Full Stack Developer Resume</h2>

<strong>Summary:</strong>
Results-driven Full Stack Developer ...
2025-04-16 18:22:36,285 - ResumeServer - INFO - Building PDF document...
2025-04-16 18:22:36,304 - ResumeServer - INFO - PDF generation successful, size: 6275 bytes
2025-04-16 18:22:36,305 - ResumeServer - INFO - Resume generated successfully. PDF size: 6275 bytes
2025-04-16 18:22:36,306 - ResumeServer - DEBUG - Converting response to JSON
2025-04-16 18:22:36,307 - ResumeServer - DEBUG - Response headers set: application/json
2025-04-16 18:22:36,307 - ResumeServer - INFO - Successfully sent PDF response
2025-04-16 18:22:36,308 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpj7164hm6
2025-04-16 18:22:53,506 - ResumeServer - INFO - POST request to /generate (Content-Length: 13056)
2025-04-16 18:22:53,507 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:22:53,507 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpignroflm
2025-04-16 18:22:53,507 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:22:53,512 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 18:22:53,512 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=jobDesc.txt
2025-04-16 18:22:53,513 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:22:53,516 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:22:53,517 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmpignroflm\template.txt
2025-04-16 18:22:53,518 - ResumeServer - INFO - Generating resume...
2025-04-16 18:22:53,520 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:22:53,523 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 18:22:53,527 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:22:53,528 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:22:53,530 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:22:55,532 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:22:55,533 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 18:22:55,534 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:22:55,536 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:22:55,536 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:22:57,538 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:22:57,539 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 18:22:57,541 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:22:57,543 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:22:57,544 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:22:57,545 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    f.write(resume_file.file.read())
                                ^^^^^
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:22:57,546 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:22:57,549 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpignroflm
2025-04-16 18:25:54,457 - ResumeServer - INFO - POST request to /generate (Content-Length: 7398)
2025-04-16 18:25:54,458 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:25:54,459 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpim417n_d
2025-04-16 18:25:54,460 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:25:54,466 - ResumeServer - DEBUG - Form fields: ['job_desc', 'resume']
2025-04-16 18:25:54,467 - ResumeServer - INFO - Got files: resume=resume.pdf, job_desc=jobDesc.txt
2025-04-16 18:25:54,468 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:25:54,470 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:25:54,471 - ResumeServer - INFO - Generating resume...
2025-04-16 18:25:54,474 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:25:54,476 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:25:54,478 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:25:56,480 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:25:56,483 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:25:56,484 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:25:58,486 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:25:58,488 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:25:58,490 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:25:58,493 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    f.write(resume_file.file.read())
                                ^^^^^
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:25:58,497 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:25:58,502 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpim417n_d
2025-04-16 18:29:54,968 - ResumeServer - INFO - GET request for /
2025-04-16 18:29:54,970 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 18:29:54,971 - ResumeServer - INFO - Served index.html successfully
2025-04-16 18:29:54,983 - ResumeServer - INFO - GET request for /history
2025-04-16 18:29:54,984 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:32:57,614 - ResumeServer - INFO - GET request for /
2025-04-16 18:32:57,615 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 18:32:57,615 - ResumeServer - INFO - Served index.html successfully
2025-04-16 18:32:57,629 - ResumeServer - INFO - GET request for /history
2025-04-16 18:32:57,630 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:34:32,375 - ResumeServer - INFO - GET request for /
2025-04-16 18:34:32,376 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 18:34:32,378 - ResumeServer - INFO - Served index.html successfully
2025-04-16 18:34:32,402 - ResumeServer - INFO - GET request for /history
2025-04-16 18:34:32,404 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:35:53,285 - ResumeServer - INFO - GET request for /
2025-04-16 18:35:53,287 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 18:35:53,288 - ResumeServer - INFO - Served index.html successfully
2025-04-16 18:35:53,309 - ResumeServer - INFO - GET request for /history
2025-04-16 18:35:53,310 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:37:08,356 - ResumeServer - INFO - GET request for /
2025-04-16 18:37:08,358 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 18:37:08,359 - ResumeServer - INFO - Served index.html successfully
2025-04-16 18:37:08,410 - ResumeServer - INFO - GET request for /history
2025-04-16 18:37:08,412 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:37:27,026 - ResumeServer - INFO - POST request to /generate (Content-Length: 5648)
2025-04-16 18:37:27,026 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:37:27,028 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpxbrex_qy
2025-04-16 18:37:27,028 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:37:27,032 - ResumeServer - DEBUG - Form fields: ['job_desc', 'resume']
2025-04-16 18:37:27,033 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=jobDesc.txt
2025-04-16 18:37:27,035 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:37:27,038 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:37:27,039 - ResumeServer - INFO - Generating resume...
2025-04-16 18:37:27,041 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:37:27,044 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 18:37:27,045 - ResumeServer - INFO - Initializing Groq client...
2025-04-16 18:37:27,836 - ResumeServer - INFO - Preparing messages for AI request...
2025-04-16 18:37:27,837 - ResumeServer - DEBUG - Using standard prompt (no template)
2025-04-16 18:37:27,838 - ResumeServer - INFO - Sending request to Groq API...
2025-04-16 18:37:27,841 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Respond with 'test ok'"}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 10, 'stream': False}}
2025-04-16 18:37:27,844 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 18:37:27,845 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-04-16 18:37:27,973 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC1401A60>
2025-04-16 18:37:27,974 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EFC13D0450> server_hostname='api.groq.com' timeout=5.0
2025-04-16 18:37:28,041 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC13C66C0>
2025-04-16 18:37:28,043 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 18:37:28,043 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 18:37:28,044 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 18:37:28,045 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 18:37:28,046 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 18:37:28,196 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 13:07:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'9313e7e3dbc90553-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'999'), (b'X-Ratelimit-Remaining-Tokens', b'11990'), (b'X-Ratelimit-Reset-Requests', b'1m26.4s'), (b'X-Ratelimit-Reset-Tokens', b'50ms'), (b'X-Request-Id', b'req_01jrzbcam3e1ta6bzvrz2d9p6j'), (b'Set-Cookie', b'__cf_bm=wwJJeAvaKkNx5ie9ZWPr3RkfxWbZV8xFsXhujmlTNCE-1744808848-1.0.1.1-Ek1i8xsizOwlO1MIFHJN3qQ_Dq5MnN.V6o4OR6EgiRylRtzdvTSjS5C7xwVoZKsqmSpYy.ujdpdJKLGR88IewS6TLUsFL7W.9I77gqnlvB4; path=/; expires=Wed, 16-Apr-25 13:37:28 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 18:37:28,200 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 18:37:28,202 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 18:37:28,205 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 18:37:28,206 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 18:37:28,206 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 18:37:28,207 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 13:07:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9313e7e3dbc90553-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '999', 'x-ratelimit-remaining-tokens': '11990', 'x-ratelimit-reset-requests': '1m26.4s', 'x-ratelimit-reset-tokens': '50ms', 'x-request-id': 'req_01jrzbcam3e1ta6bzvrz2d9p6j', 'set-cookie': '__cf_bm=wwJJeAvaKkNx5ie9ZWPr3RkfxWbZV8xFsXhujmlTNCE-1744808848-1.0.1.1-Ek1i8xsizOwlO1MIFHJN3qQ_Dq5MnN.V6o4OR6EgiRylRtzdvTSjS5C7xwVoZKsqmSpYy.ujdpdJKLGR88IewS6TLUsFL7W.9I77gqnlvB4; path=/; expires=Wed, 16-Apr-25 13:37:28 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 18:37:28,210 - ResumeServer - INFO - API test successful: test ok
2025-04-16 18:37:28,212 - ResumeServer - INFO - Creating streaming completion...
2025-04-16 18:37:28,216 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a resume assistant. Format your response with HTML tags for styling. Use <strong> for bold, <h2> for section headers, <ul> and <li> for lists. Provide ONLY the resume content, no analysis or insights. Start directly with the resume content.'}, {'role': 'user', 'content': "Create a tailored resume based on this resume and job description. Format the response with HTML tags. Provide ONLY the resume content, no analysis or insights.\n\nResume:\n\nResults-driven Machine Learning Engineer with 4+ years of experience developing and deploying AI models for diverse applications, including computer vision, NLP, and predictive analytics. Skilled in Python, TensorFlow, and cloud platforms like GCP. Adept at translating complex data into actionable insights and thriving in collaborative, fast-paced environments.\n\nProfessional Experience\n\nMachine Learning Engineer\n\nNexGen Technologies, Austin, TX\n\nAugust 2021 – Present\n\nBuilt convolutional neural networks (CNNs) with TensorFlow for image classification, achieving 92% accuracy on a custom dataset for retail product recognition.\nDesigned and deployed NLP models using BERT and Hugging Face for automated customer support, reducing response times by 40%.\nImplemented MLOps pipelines with Kubeflow and GCP, automating model retraining and monitoring for production systems.\nPreprocessed terabyte-scale datasets with Apache Spark, optimizing data pipelines for faster model training.\nMentored junior engineers on best practices for model development and version control with Git.\nData Scientist\n\nInsight Analytics, San Francisco, CA (Remote)\n\nJune 2020 – July 2021\n\nDeveloped time-series forecasting models with PyTorch to predict inventory demand, improving supply chain efficiency by 20%.\nConducted exploratory data analysis with pandas and SQL, uncovering trends that informed marketing strategies.\nCreated interactive dashboards with Plotly and Tableau to visualize model outputs for executive stakeholders.\nCollaborated with software engineers to integrate ML models into web applications using Flask APIs.\nResearch Intern, AI Lab\n\nStanford University, Stanford, CA\n\nJanuary 2019 – May 2020\n\nContributed to research on reinforcement learning algorithms, co-authoring a paper presented at NeurIPS 2020.\nBuilt simulation environments with OpenAI Gym to test agent performance in dynamic scenarios.\nOptimized model training workflows, reducing compute costs by 15% through efficient resource allocation.\nEducation\n\nMaster of Science in Artificial Intelligence\n\nCarnegie Mellon University, Pittsburgh, PA\n\nGraduated: May 2020\n\nFocus: Deep Learning and Reinforcement Learning\nCapstone Project: “Scalable RL Models for Autonomous Navigation”\nBachelor of Science in Computer Science\n\nUniversity of Texas at Austin, Austin, TX\n\nGraduated: May 2018\n\nMinor in Applied Mathematics\nSkills\n\nProgramming: Python, C++, SQL, Bash\nML Frameworks: TensorFlow, PyTorch, scikit-learn, Hugging Face, OpenCV\nCloud Platforms: Google Cloud Platform (AI Platform, BigQuery), AWS, Azure\nTools: Docker, Jenkins, MLflow, Git, Jupyter, Tableau\nData Processing: pandas, NumPy, Spark, Dask\nDomains: Computer Vision, NLP, Reinforcement Learning, Time-Series Analysis\nProjects\n\nAutonomous Drone Navigation (GitHub: github.com/alexcarter/drone-ai)\nDeveloped a reinforcement learning model with PyTorch to train drones for obstacle avoidance, tested in simulated environments.\nText Summarization Tool\nBuilt an NLP pipeline with Hugging Face transformers to generate concise summaries of news articles, deployed as a web app with Streamlit.\nFacial Recognition System\nCreated a real-time face detection model using OpenCV and TensorFlow, achieving 95% accuracy on public datasets.\nCertifications\n\nGoogle Cloud Professional Machine Learning Engineer (2023)\nCoursera: Deep Learning Specialization by Andrew Ng (2020)\nPublications & Talks\n\nCo-author, “Advances in Scalable Reinforcement Learning for Robotics,” NeurIPS 2020.\nGuest Speaker, “MLOps for Beginners,” Austin AI Meetup, March 2023.\nAdditional Information\n\nActive contributor to PyTorch (3 pull requests merged).\nVolunteer mentor at Code2AI, teaching high school students ML basics.\nProficient in French; conversational in Japanese.\n\nJob Description:\n\nSoftware Engineer - Full Stack Developer\n\nCompany: Tech Innovations Inc.\nLocation: Remote\nType: Full-time\n\nJob Description:\nWe are seeking a skilled Full Stack Developer to join our dynamic team. The ideal candidate will be responsible for developing and maintaining web applications using modern technologies.\n\nResponsibilities:\n- Design and implement scalable web applications\n- Develop front-end interfaces using React.js\n- Create and maintain back-end services using Node.js and Python\n- Work with databases (SQL and NoSQL)\n- Implement RESTful APIs\n- Write clean, maintainable code\n- Collaborate with cross-functional teams\n- Participate in code reviews and technical discussions\n\nRequirements:\n- Bachelor's degree in Computer Science or related field\n- 3+ years of experience in full-stack development\n- Strong proficiency in JavaScript, Python, and SQL\n- Experience with React.js and Node.js\n- Knowledge of cloud platforms (AWS, Azure, or GCP)\n- Familiarity with version control systems (Git)\n- Excellent problem-solving skills\n- Strong communication and teamwork abilities\n\nPreferred Qualifications:\n- Experience with containerization (Docker)\n- Knowledge of CI/CD pipelines\n- Understanding of microservices architecture\n- Contributions to open-source projects\n\nBenefits:\n- Competitive salary\n- Health insurance\n- 401(k) matching\n- Flexible work hours\n- Professional development opportunities\n- Remote work options "}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2048, 'stream': True, 'temperature': 0.1, 'top_p': 1}}
2025-04-16 18:37:28,230 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 18:37:28,230 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 18:37:28,231 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 18:37:28,232 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 18:37:28,232 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 18:37:28,233 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 18:37:48,363 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 13:07:48 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'9313e7e51e730553-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'no-cache'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'998'), (b'X-Ratelimit-Remaining-Tokens', b'10564'), (b'X-Ratelimit-Reset-Requests', b'2m52.6s'), (b'X-Ratelimit-Reset-Tokens', b'7.176s'), (b'X-Request-Id', b'req_01jrzbcat8eghaet8q5bgrygcn'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 18:37:48,364 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 18:37:48,365 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 13:07:48 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9313e7e51e730553-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'no-cache', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '998', 'x-ratelimit-remaining-tokens': '10564', 'x-ratelimit-reset-requests': '2m52.6s', 'x-ratelimit-reset-tokens': '7.176s', 'x-request-id': 'req_01jrzbcat8eghaet8q5bgrygcn', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 18:37:48,366 - ResumeServer - INFO - Collecting response chunks...
2025-04-16 18:37:48,366 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 18:37:49,005 - ResumeServer - DEBUG - Received 10 chunks, response length: 34
2025-04-16 18:37:49,007 - ResumeServer - DEBUG - Received 20 chunks, response length: 78
2025-04-16 18:37:49,008 - ResumeServer - DEBUG - Received 30 chunks, response length: 127
2025-04-16 18:37:49,010 - ResumeServer - DEBUG - Received 40 chunks, response length: 209
2025-04-16 18:37:49,012 - ResumeServer - DEBUG - Received 50 chunks, response length: 247
2025-04-16 18:37:49,013 - ResumeServer - DEBUG - Received 60 chunks, response length: 307
2025-04-16 18:37:49,035 - ResumeServer - DEBUG - Received 70 chunks, response length: 364
2025-04-16 18:37:49,059 - ResumeServer - DEBUG - Received 80 chunks, response length: 419
2025-04-16 18:37:49,074 - ResumeServer - DEBUG - Received 90 chunks, response length: 464
2025-04-16 18:37:49,089 - ResumeServer - DEBUG - Received 100 chunks, response length: 516
2025-04-16 18:37:49,109 - ResumeServer - DEBUG - Received 110 chunks, response length: 555
2025-04-16 18:37:49,131 - ResumeServer - DEBUG - Received 120 chunks, response length: 598
2025-04-16 18:37:49,138 - ResumeServer - DEBUG - Received 130 chunks, response length: 649
2025-04-16 18:37:49,161 - ResumeServer - DEBUG - Received 140 chunks, response length: 704
2025-04-16 18:37:49,190 - ResumeServer - DEBUG - Received 150 chunks, response length: 761
2025-04-16 18:37:49,205 - ResumeServer - DEBUG - Received 160 chunks, response length: 820
2025-04-16 18:37:49,236 - ResumeServer - DEBUG - Received 170 chunks, response length: 877
2025-04-16 18:37:49,264 - ResumeServer - DEBUG - Received 180 chunks, response length: 921
2025-04-16 18:37:49,326 - ResumeServer - DEBUG - Received 190 chunks, response length: 988
2025-04-16 18:37:49,342 - ResumeServer - DEBUG - Received 200 chunks, response length: 1060
2025-04-16 18:37:49,380 - ResumeServer - DEBUG - Received 210 chunks, response length: 1106
2025-04-16 18:37:49,398 - ResumeServer - DEBUG - Received 220 chunks, response length: 1174
2025-04-16 18:37:49,430 - ResumeServer - DEBUG - Received 230 chunks, response length: 1235
2025-04-16 18:37:49,438 - ResumeServer - DEBUG - Received 240 chunks, response length: 1284
2025-04-16 18:37:49,452 - ResumeServer - DEBUG - Received 250 chunks, response length: 1314
2025-04-16 18:37:49,478 - ResumeServer - DEBUG - Received 260 chunks, response length: 1360
2025-04-16 18:37:49,502 - ResumeServer - DEBUG - Received 270 chunks, response length: 1406
2025-04-16 18:37:49,518 - ResumeServer - DEBUG - Received 280 chunks, response length: 1472
2025-04-16 18:37:49,528 - ResumeServer - DEBUG - Received 290 chunks, response length: 1534
2025-04-16 18:37:49,579 - ResumeServer - DEBUG - Received 300 chunks, response length: 1578
2025-04-16 18:37:49,594 - ResumeServer - DEBUG - Received 310 chunks, response length: 1640
2025-04-16 18:37:49,603 - ResumeServer - DEBUG - Received 320 chunks, response length: 1686
2025-04-16 18:37:49,628 - ResumeServer - DEBUG - Received 330 chunks, response length: 1725
2025-04-16 18:37:49,637 - ResumeServer - DEBUG - Received 340 chunks, response length: 1754
2025-04-16 18:37:49,649 - ResumeServer - DEBUG - Received 350 chunks, response length: 1816
2025-04-16 18:37:49,661 - ResumeServer - DEBUG - Received 360 chunks, response length: 1849
2025-04-16 18:37:49,682 - ResumeServer - DEBUG - Received 370 chunks, response length: 1904
2025-04-16 18:37:49,709 - ResumeServer - DEBUG - Received 380 chunks, response length: 1961
2025-04-16 18:37:49,710 - ResumeServer - DEBUG - Received 390 chunks, response length: 2011
2025-04-16 18:37:49,717 - ResumeServer - DEBUG - Received 400 chunks, response length: 2066
2025-04-16 18:37:49,737 - ResumeServer - DEBUG - Received 410 chunks, response length: 2117
2025-04-16 18:37:49,746 - ResumeServer - DEBUG - Received 420 chunks, response length: 2161
2025-04-16 18:37:49,757 - ResumeServer - DEBUG - Received 430 chunks, response length: 2188
2025-04-16 18:37:49,782 - ResumeServer - DEBUG - Received 440 chunks, response length: 2246
2025-04-16 18:37:49,794 - ResumeServer - DEBUG - Received 450 chunks, response length: 2293
2025-04-16 18:37:49,805 - ResumeServer - DEBUG - Received 460 chunks, response length: 2350
2025-04-16 18:37:49,818 - ResumeServer - DEBUG - Received 470 chunks, response length: 2389
2025-04-16 18:37:49,836 - ResumeServer - DEBUG - Received 480 chunks, response length: 2429
2025-04-16 18:37:49,852 - ResumeServer - DEBUG - Received 490 chunks, response length: 2449
2025-04-16 18:37:49,889 - ResumeServer - DEBUG - Received 500 chunks, response length: 2492
2025-04-16 18:37:49,912 - ResumeServer - DEBUG - Received 510 chunks, response length: 2526
2025-04-16 18:37:49,928 - ResumeServer - DEBUG - Received 520 chunks, response length: 2558
2025-04-16 18:37:49,955 - ResumeServer - DEBUG - Received 530 chunks, response length: 2596
2025-04-16 18:37:49,959 - ResumeServer - DEBUG - Received 540 chunks, response length: 2642
2025-04-16 18:37:49,970 - ResumeServer - DEBUG - Received 550 chunks, response length: 2672
2025-04-16 18:37:49,982 - ResumeServer - DEBUG - Received 560 chunks, response length: 2703
2025-04-16 18:37:50,003 - ResumeServer - DEBUG - Received 570 chunks, response length: 2742
2025-04-16 18:37:50,015 - ResumeServer - DEBUG - Received 580 chunks, response length: 2767
2025-04-16 18:37:50,023 - ResumeServer - DEBUG - Received 590 chunks, response length: 2813
2025-04-16 18:37:50,044 - ResumeServer - DEBUG - Received 600 chunks, response length: 2851
2025-04-16 18:37:50,081 - ResumeServer - DEBUG - Received 610 chunks, response length: 2882
2025-04-16 18:37:50,090 - ResumeServer - DEBUG - Received 620 chunks, response length: 2923
2025-04-16 18:37:50,114 - ResumeServer - DEBUG - Received 630 chunks, response length: 2946
2025-04-16 18:37:50,117 - ResumeServer - DEBUG - Received 640 chunks, response length: 3003
2025-04-16 18:37:50,132 - ResumeServer - DEBUG - Received 650 chunks, response length: 3073
2025-04-16 18:37:50,148 - ResumeServer - DEBUG - Received 660 chunks, response length: 3107
2025-04-16 18:37:50,152 - ResumeServer - DEBUG - Received 670 chunks, response length: 3141
2025-04-16 18:37:50,175 - ResumeServer - DEBUG - Received 680 chunks, response length: 3205
2025-04-16 18:37:50,189 - ResumeServer - DEBUG - Received 690 chunks, response length: 3254
2025-04-16 18:37:50,203 - ResumeServer - DEBUG - Received 700 chunks, response length: 3293
2025-04-16 18:37:50,223 - ResumeServer - DEBUG - Received 710 chunks, response length: 3330
2025-04-16 18:37:50,228 - ResumeServer - DEBUG - Received 720 chunks, response length: 3386
2025-04-16 18:37:50,249 - ResumeServer - DEBUG - Received 730 chunks, response length: 3424
2025-04-16 18:37:50,269 - ResumeServer - DEBUG - Received 740 chunks, response length: 3471
2025-04-16 18:37:50,277 - ResumeServer - DEBUG - Received 750 chunks, response length: 3514
2025-04-16 18:37:50,296 - ResumeServer - DEBUG - Received 760 chunks, response length: 3560
2025-04-16 18:37:50,315 - ResumeServer - DEBUG - Received 770 chunks, response length: 3591
2025-04-16 18:37:50,323 - ResumeServer - DEBUG - Received 780 chunks, response length: 3615
2025-04-16 18:37:50,344 - ResumeServer - DEBUG - Received 790 chunks, response length: 3670
2025-04-16 18:37:50,355 - ResumeServer - DEBUG - Received 800 chunks, response length: 3699
2025-04-16 18:37:50,376 - ResumeServer - DEBUG - Received 810 chunks, response length: 3733
2025-04-16 18:37:50,384 - ResumeServer - DEBUG - Received 820 chunks, response length: 3757
2025-04-16 18:37:50,403 - ResumeServer - DEBUG - Received 830 chunks, response length: 3807
2025-04-16 18:37:50,407 - ResumeServer - DEBUG - Received 840 chunks, response length: 3844
2025-04-16 18:37:50,419 - ResumeServer - DEBUG - Received 850 chunks, response length: 3888
2025-04-16 18:37:50,447 - ResumeServer - DEBUG - Received 860 chunks, response length: 3937
2025-04-16 18:37:52,004 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 18:37:52,005 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 18:37:52,005 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 18:37:52,006 - ResumeServer - INFO - Response collection complete. Total 866 chunks, final length: 3965
2025-04-16 18:37:52,007 - ResumeServer - INFO - Response preview: <h2>Full Stack Developer Resume</h2>

<strong>Summary:</strong>
Results-driven Full Stack Developer ...
2025-04-16 18:37:52,011 - httpcore.connection - DEBUG - close.started
2025-04-16 18:37:52,013 - httpcore.connection - DEBUG - close.complete
2025-04-16 18:37:52,019 - ResumeServer - INFO - Building PDF document...
2025-04-16 18:37:52,041 - ResumeServer - INFO - PDF generation successful, size: 6303 bytes
2025-04-16 18:37:52,042 - ResumeServer - INFO - Resume generated successfully. PDF size: 6303 bytes
2025-04-16 18:37:52,042 - ResumeServer - DEBUG - Converting response to JSON
2025-04-16 18:37:52,044 - ResumeServer - DEBUG - Response headers set: application/json
2025-04-16 18:37:52,045 - ResumeServer - INFO - Successfully sent PDF response
2025-04-16 18:37:52,047 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpxbrex_qy
2025-04-16 18:37:52,365 - ResumeServer - INFO - GET request for /history
2025-04-16 18:37:52,367 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:39:50,090 - ResumeServer - INFO - POST request to /generate (Content-Length: 5648)
2025-04-16 18:39:50,092 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:39:50,096 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmptj5rvpkw
2025-04-16 18:39:50,098 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:39:50,112 - ResumeServer - DEBUG - Form fields: ['job_desc', 'resume']
2025-04-16 18:39:50,115 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=jobDesc.txt
2025-04-16 18:39:50,127 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:39:50,145 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:39:50,148 - ResumeServer - INFO - Generating resume...
2025-04-16 18:39:50,158 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:39:50,168 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 18:39:50,173 - ResumeServer - INFO - Initializing Groq client...
2025-04-16 18:39:54,177 - ResumeServer - INFO - Preparing messages for AI request...
2025-04-16 18:39:54,181 - ResumeServer - DEBUG - Using standard prompt (no template)
2025-04-16 18:39:54,183 - ResumeServer - INFO - Sending request to Groq API...
2025-04-16 18:39:54,243 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Respond with 'test ok'"}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 10, 'stream': False}}
2025-04-16 18:39:54,246 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 18:39:54,248 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-04-16 18:39:54,331 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC13F3AA0>
2025-04-16 18:39:54,333 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EFC0BC7950> server_hostname='api.groq.com' timeout=5.0
2025-04-16 18:39:54,407 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC1402600>
2025-04-16 18:39:54,410 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 18:39:54,413 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 18:39:54,415 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 18:39:54,417 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 18:39:54,418 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 18:39:54,567 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 13:09:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'9313eb76abb9a8f9-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'998'), (b'X-Ratelimit-Remaining-Tokens', b'11990'), (b'X-Ratelimit-Reset-Requests', b'1m53.032s'), (b'X-Ratelimit-Reset-Tokens', b'50ms'), (b'X-Request-Id', b'req_01jrzbgsj5e4eb3rafp3try2ya'), (b'Set-Cookie', b'__cf_bm=dK7TPcMz8Tx2YPeLJ8.6u38mzTdm6oijb1lvdUep5II-1744808994-1.0.1.1-0g.d1kCt.0i2qob6w1rZsrTAclqZ5Wvac1Wh80ttt2rHOb7eRMIkMyerzCDQ5Nwoi__4OvNfovVKPZm6lCYTb3wrrBaHKLPARmh5cA2RvY8; path=/; expires=Wed, 16-Apr-25 13:39:54 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 18:39:54,574 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 18:39:54,575 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 18:39:54,577 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 18:39:54,578 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 18:39:54,579 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 18:39:54,580 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 13:09:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9313eb76abb9a8f9-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '998', 'x-ratelimit-remaining-tokens': '11990', 'x-ratelimit-reset-requests': '1m53.032s', 'x-ratelimit-reset-tokens': '50ms', 'x-request-id': 'req_01jrzbgsj5e4eb3rafp3try2ya', 'set-cookie': '__cf_bm=dK7TPcMz8Tx2YPeLJ8.6u38mzTdm6oijb1lvdUep5II-1744808994-1.0.1.1-0g.d1kCt.0i2qob6w1rZsrTAclqZ5Wvac1Wh80ttt2rHOb7eRMIkMyerzCDQ5Nwoi__4OvNfovVKPZm6lCYTb3wrrBaHKLPARmh5cA2RvY8; path=/; expires=Wed, 16-Apr-25 13:39:54 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 18:39:54,586 - ResumeServer - INFO - API test successful: test ok
2025-04-16 18:39:54,587 - ResumeServer - INFO - Creating streaming completion...
2025-04-16 18:39:54,594 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a resume assistant. Format your response with HTML tags for styling. Use <strong> for bold, <h2> for section headers, <ul> and <li> for lists. Provide ONLY the resume content, no analysis or insights. Start directly with the resume content.'}, {'role': 'user', 'content': "Create a tailored resume based on this resume and job description. Format the response with HTML tags. Provide ONLY the resume content, no analysis or insights.\n\nResume:\n\nResults-driven Machine Learning Engineer with 4+ years of experience developing and deploying AI models for diverse applications, including computer vision, NLP, and predictive analytics. Skilled in Python, TensorFlow, and cloud platforms like GCP. Adept at translating complex data into actionable insights and thriving in collaborative, fast-paced environments.\n\nProfessional Experience\n\nMachine Learning Engineer\n\nNexGen Technologies, Austin, TX\n\nAugust 2021 – Present\n\nBuilt convolutional neural networks (CNNs) with TensorFlow for image classification, achieving 92% accuracy on a custom dataset for retail product recognition.\nDesigned and deployed NLP models using BERT and Hugging Face for automated customer support, reducing response times by 40%.\nImplemented MLOps pipelines with Kubeflow and GCP, automating model retraining and monitoring for production systems.\nPreprocessed terabyte-scale datasets with Apache Spark, optimizing data pipelines for faster model training.\nMentored junior engineers on best practices for model development and version control with Git.\nData Scientist\n\nInsight Analytics, San Francisco, CA (Remote)\n\nJune 2020 – July 2021\n\nDeveloped time-series forecasting models with PyTorch to predict inventory demand, improving supply chain efficiency by 20%.\nConducted exploratory data analysis with pandas and SQL, uncovering trends that informed marketing strategies.\nCreated interactive dashboards with Plotly and Tableau to visualize model outputs for executive stakeholders.\nCollaborated with software engineers to integrate ML models into web applications using Flask APIs.\nResearch Intern, AI Lab\n\nStanford University, Stanford, CA\n\nJanuary 2019 – May 2020\n\nContributed to research on reinforcement learning algorithms, co-authoring a paper presented at NeurIPS 2020.\nBuilt simulation environments with OpenAI Gym to test agent performance in dynamic scenarios.\nOptimized model training workflows, reducing compute costs by 15% through efficient resource allocation.\nEducation\n\nMaster of Science in Artificial Intelligence\n\nCarnegie Mellon University, Pittsburgh, PA\n\nGraduated: May 2020\n\nFocus: Deep Learning and Reinforcement Learning\nCapstone Project: “Scalable RL Models for Autonomous Navigation”\nBachelor of Science in Computer Science\n\nUniversity of Texas at Austin, Austin, TX\n\nGraduated: May 2018\n\nMinor in Applied Mathematics\nSkills\n\nProgramming: Python, C++, SQL, Bash\nML Frameworks: TensorFlow, PyTorch, scikit-learn, Hugging Face, OpenCV\nCloud Platforms: Google Cloud Platform (AI Platform, BigQuery), AWS, Azure\nTools: Docker, Jenkins, MLflow, Git, Jupyter, Tableau\nData Processing: pandas, NumPy, Spark, Dask\nDomains: Computer Vision, NLP, Reinforcement Learning, Time-Series Analysis\nProjects\n\nAutonomous Drone Navigation (GitHub: github.com/alexcarter/drone-ai)\nDeveloped a reinforcement learning model with PyTorch to train drones for obstacle avoidance, tested in simulated environments.\nText Summarization Tool\nBuilt an NLP pipeline with Hugging Face transformers to generate concise summaries of news articles, deployed as a web app with Streamlit.\nFacial Recognition System\nCreated a real-time face detection model using OpenCV and TensorFlow, achieving 95% accuracy on public datasets.\nCertifications\n\nGoogle Cloud Professional Machine Learning Engineer (2023)\nCoursera: Deep Learning Specialization by Andrew Ng (2020)\nPublications & Talks\n\nCo-author, “Advances in Scalable Reinforcement Learning for Robotics,” NeurIPS 2020.\nGuest Speaker, “MLOps for Beginners,” Austin AI Meetup, March 2023.\nAdditional Information\n\nActive contributor to PyTorch (3 pull requests merged).\nVolunteer mentor at Code2AI, teaching high school students ML basics.\nProficient in French; conversational in Japanese.\n\nJob Description:\n\nSoftware Engineer - Full Stack Developer\n\nCompany: Tech Innovations Inc.\nLocation: Remote\nType: Full-time\n\nJob Description:\nWe are seeking a skilled Full Stack Developer to join our dynamic team. The ideal candidate will be responsible for developing and maintaining web applications using modern technologies.\n\nResponsibilities:\n- Design and implement scalable web applications\n- Develop front-end interfaces using React.js\n- Create and maintain back-end services using Node.js and Python\n- Work with databases (SQL and NoSQL)\n- Implement RESTful APIs\n- Write clean, maintainable code\n- Collaborate with cross-functional teams\n- Participate in code reviews and technical discussions\n\nRequirements:\n- Bachelor's degree in Computer Science or related field\n- 3+ years of experience in full-stack development\n- Strong proficiency in JavaScript, Python, and SQL\n- Experience with React.js and Node.js\n- Knowledge of cloud platforms (AWS, Azure, or GCP)\n- Familiarity with version control systems (Git)\n- Excellent problem-solving skills\n- Strong communication and teamwork abilities\n\nPreferred Qualifications:\n- Experience with containerization (Docker)\n- Knowledge of CI/CD pipelines\n- Understanding of microservices architecture\n- Contributions to open-source projects\n\nBenefits:\n- Competitive salary\n- Health insurance\n- 401(k) matching\n- Flexible work hours\n- Professional development opportunities\n- Remote work options "}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2048, 'stream': True, 'temperature': 0.1, 'top_p': 1}}
2025-04-16 18:39:54,614 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 18:39:54,615 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 18:39:54,618 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 18:39:54,619 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 18:39:54,621 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 18:39:54,622 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 18:39:54,781 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 13:09:54 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'9313eb77ecaaa8f9-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'no-cache'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'997'), (b'X-Ratelimit-Remaining-Tokens', b'10568'), (b'X-Ratelimit-Reset-Requests', b'4m18.981s'), (b'X-Ratelimit-Reset-Tokens', b'7.16s'), (b'X-Request-Id', b'req_01jrzbgss0epbv5n3wpz9j51dj'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 18:39:54,786 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 18:39:54,787 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 13:09:54 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9313eb77ecaaa8f9-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'no-cache', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '997', 'x-ratelimit-remaining-tokens': '10568', 'x-ratelimit-reset-requests': '4m18.981s', 'x-ratelimit-reset-tokens': '7.16s', 'x-request-id': 'req_01jrzbgss0epbv5n3wpz9j51dj', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 18:39:54,790 - ResumeServer - INFO - Collecting response chunks...
2025-04-16 18:39:54,791 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 18:39:54,926 - ResumeServer - DEBUG - Received 10 chunks, response length: 34
2025-04-16 18:39:54,939 - ResumeServer - DEBUG - Received 20 chunks, response length: 80
2025-04-16 18:39:54,948 - ResumeServer - DEBUG - Received 30 chunks, response length: 152
2025-04-16 18:39:54,974 - ResumeServer - DEBUG - Received 40 chunks, response length: 206
2025-04-16 18:39:54,995 - ResumeServer - DEBUG - Received 50 chunks, response length: 245
2025-04-16 18:39:55,026 - ResumeServer - DEBUG - Received 60 chunks, response length: 282
2025-04-16 18:39:55,044 - ResumeServer - DEBUG - Received 70 chunks, response length: 347
2025-04-16 18:39:55,056 - ResumeServer - DEBUG - Received 80 chunks, response length: 403
2025-04-16 18:39:55,068 - ResumeServer - DEBUG - Received 90 chunks, response length: 441
2025-04-16 18:39:55,113 - ResumeServer - DEBUG - Received 100 chunks, response length: 479
2025-04-16 18:39:55,124 - ResumeServer - DEBUG - Received 110 chunks, response length: 530
2025-04-16 18:39:55,135 - ResumeServer - DEBUG - Received 120 chunks, response length: 565
2025-04-16 18:39:55,149 - ResumeServer - DEBUG - Received 130 chunks, response length: 631
2025-04-16 18:39:55,163 - ResumeServer - DEBUG - Received 140 chunks, response length: 676
2025-04-16 18:39:55,177 - ResumeServer - DEBUG - Received 150 chunks, response length: 728
2025-04-16 18:39:55,189 - ResumeServer - DEBUG - Received 160 chunks, response length: 775
2025-04-16 18:39:55,207 - ResumeServer - DEBUG - Received 170 chunks, response length: 844
2025-04-16 18:39:55,220 - ResumeServer - DEBUG - Received 180 chunks, response length: 895
2025-04-16 18:39:55,291 - ResumeServer - DEBUG - Received 190 chunks, response length: 950
2025-04-16 18:39:55,320 - ResumeServer - DEBUG - Received 200 chunks, response length: 1022
2025-04-16 18:39:55,341 - ResumeServer - DEBUG - Received 210 chunks, response length: 1073
2025-04-16 18:39:55,354 - ResumeServer - DEBUG - Received 220 chunks, response length: 1099
2025-04-16 18:39:55,372 - ResumeServer - DEBUG - Received 230 chunks, response length: 1140
2025-04-16 18:39:55,382 - ResumeServer - DEBUG - Received 240 chunks, response length: 1200
2025-04-16 18:39:55,397 - ResumeServer - DEBUG - Received 250 chunks, response length: 1251
2025-04-16 18:39:55,410 - ResumeServer - DEBUG - Received 260 chunks, response length: 1305
2025-04-16 18:39:55,429 - ResumeServer - DEBUG - Received 270 chunks, response length: 1364
2025-04-16 18:39:55,446 - ResumeServer - DEBUG - Received 280 chunks, response length: 1429
2025-04-16 18:39:55,459 - ResumeServer - DEBUG - Received 290 chunks, response length: 1479
2025-04-16 18:39:55,486 - ResumeServer - DEBUG - Received 300 chunks, response length: 1535
2025-04-16 18:39:55,501 - ResumeServer - DEBUG - Received 310 chunks, response length: 1577
2025-04-16 18:39:55,533 - ResumeServer - DEBUG - Received 320 chunks, response length: 1602
2025-04-16 18:39:55,544 - ResumeServer - DEBUG - Received 330 chunks, response length: 1666
2025-04-16 18:39:55,556 - ResumeServer - DEBUG - Received 340 chunks, response length: 1706
2025-04-16 18:39:55,575 - ResumeServer - DEBUG - Received 350 chunks, response length: 1752
2025-04-16 18:39:55,586 - ResumeServer - DEBUG - Received 360 chunks, response length: 1810
2025-04-16 18:39:55,608 - ResumeServer - DEBUG - Received 370 chunks, response length: 1866
2025-04-16 18:39:55,627 - ResumeServer - DEBUG - Received 380 chunks, response length: 1920
2025-04-16 18:39:55,649 - ResumeServer - DEBUG - Received 390 chunks, response length: 1949
2025-04-16 18:39:55,680 - ResumeServer - DEBUG - Received 400 chunks, response length: 2012
2025-04-16 18:39:55,697 - ResumeServer - DEBUG - Received 410 chunks, response length: 2045
2025-04-16 18:39:55,725 - ResumeServer - DEBUG - Received 420 chunks, response length: 2089
2025-04-16 18:39:55,734 - ResumeServer - DEBUG - Received 430 chunks, response length: 2126
2025-04-16 18:39:55,739 - ResumeServer - DEBUG - Received 440 chunks, response length: 2187
2025-04-16 18:39:55,745 - ResumeServer - DEBUG - Received 450 chunks, response length: 2243
2025-04-16 18:39:55,764 - ResumeServer - DEBUG - Received 460 chunks, response length: 2268
2025-04-16 18:39:55,791 - ResumeServer - DEBUG - Received 470 chunks, response length: 2310
2025-04-16 18:39:55,818 - ResumeServer - DEBUG - Received 480 chunks, response length: 2350
2025-04-16 18:39:55,854 - ResumeServer - DEBUG - Received 490 chunks, response length: 2386
2025-04-16 18:39:55,871 - ResumeServer - DEBUG - Received 500 chunks, response length: 2423
2025-04-16 18:39:55,913 - ResumeServer - DEBUG - Received 510 chunks, response length: 2469
2025-04-16 18:39:55,963 - ResumeServer - DEBUG - Received 520 chunks, response length: 2499
2025-04-16 18:39:55,981 - ResumeServer - DEBUG - Received 530 chunks, response length: 2531
2025-04-16 18:39:55,997 - ResumeServer - DEBUG - Received 540 chunks, response length: 2570
2025-04-16 18:39:56,025 - ResumeServer - DEBUG - Received 550 chunks, response length: 2603
2025-04-16 18:39:56,048 - ResumeServer - DEBUG - Received 560 chunks, response length: 2645
2025-04-16 18:39:56,081 - ResumeServer - DEBUG - Received 570 chunks, response length: 2675
2025-04-16 18:39:56,106 - ResumeServer - DEBUG - Received 580 chunks, response length: 2720
2025-04-16 18:39:56,132 - ResumeServer - DEBUG - Received 590 chunks, response length: 2752
2025-04-16 18:39:56,163 - ResumeServer - DEBUG - Received 600 chunks, response length: 2791
2025-04-16 18:39:56,181 - ResumeServer - DEBUG - Received 610 chunks, response length: 2839
2025-04-16 18:39:56,208 - ResumeServer - DEBUG - Received 620 chunks, response length: 2897
2025-04-16 18:39:56,224 - ResumeServer - DEBUG - Received 630 chunks, response length: 2937
2025-04-16 18:39:56,261 - ResumeServer - DEBUG - Received 640 chunks, response length: 2974
2025-04-16 18:39:56,306 - ResumeServer - DEBUG - Received 650 chunks, response length: 3040
2025-04-16 18:39:56,331 - ResumeServer - DEBUG - Received 660 chunks, response length: 3080
2025-04-16 18:39:56,344 - ResumeServer - DEBUG - Received 670 chunks, response length: 3124
2025-04-16 18:39:56,364 - ResumeServer - DEBUG - Received 680 chunks, response length: 3173
2025-04-16 18:39:56,390 - ResumeServer - DEBUG - Received 690 chunks, response length: 3219
2025-04-16 18:39:56,420 - ResumeServer - DEBUG - Received 700 chunks, response length: 3261
2025-04-16 18:39:56,460 - ResumeServer - DEBUG - Received 710 chunks, response length: 3319
2025-04-16 18:39:56,480 - ResumeServer - DEBUG - Received 720 chunks, response length: 3343
2025-04-16 18:39:56,494 - ResumeServer - DEBUG - Received 730 chunks, response length: 3389
2025-04-16 18:39:56,508 - ResumeServer - DEBUG - Received 740 chunks, response length: 3417
2025-04-16 18:39:56,574 - ResumeServer - DEBUG - Received 750 chunks, response length: 3450
2025-04-16 18:39:56,586 - ResumeServer - DEBUG - Received 760 chunks, response length: 3500
2025-04-16 18:39:56,601 - ResumeServer - DEBUG - Received 770 chunks, response length: 3526
2025-04-16 18:39:56,631 - ResumeServer - DEBUG - Received 780 chunks, response length: 3564
2025-04-16 18:39:56,649 - ResumeServer - DEBUG - Received 790 chunks, response length: 3604
2025-04-16 18:39:56,666 - ResumeServer - DEBUG - Received 800 chunks, response length: 3638
2025-04-16 18:39:56,697 - ResumeServer - DEBUG - Received 810 chunks, response length: 3687
2025-04-16 18:39:56,709 - ResumeServer - DEBUG - Received 820 chunks, response length: 3732
2025-04-16 18:39:56,729 - ResumeServer - DEBUG - Received 830 chunks, response length: 3779
2025-04-16 18:39:57,883 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 18:39:57,885 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 18:39:57,886 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 18:39:57,888 - ResumeServer - INFO - Response collection complete. Total 834 chunks, final length: 3792
2025-04-16 18:39:57,889 - ResumeServer - INFO - Response preview: <h2>Full Stack Developer Resume</h2>

Results-driven Full Stack Developer with 4+ years of experienc...
2025-04-16 18:39:57,900 - ResumeServer - INFO - Building PDF document...
2025-04-16 18:39:57,960 - ResumeServer - INFO - PDF generation successful, size: 6222 bytes
2025-04-16 18:39:57,964 - ResumeServer - INFO - Resume generated successfully. PDF size: 6222 bytes
2025-04-16 18:39:57,967 - ResumeServer - DEBUG - Converting response to JSON
2025-04-16 18:39:57,978 - ResumeServer - DEBUG - Response headers set: application/json
2025-04-16 18:39:57,994 - ResumeServer - INFO - Successfully sent PDF response
2025-04-16 18:39:58,001 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmptj5rvpkw
2025-04-16 18:39:58,010 - ResumeServer - INFO - GET request for /
2025-04-16 18:39:58,017 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 18:39:58,025 - ResumeServer - ERROR - Error serving HTML: [WinError 10053] An established connection was aborted by the software in your host machine
2025-04-16 18:39:58,039 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 240, in do_GET
    completion = client.chat.completions.create(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Rohith\AppData\Local\Programs\Python\Python312\Lib\socketserver.py", line 840, in write
    self._sock.sendall(b)
ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine

2025-04-16 18:39:58,098 - ResumeServer - INFO - GET request for /
2025-04-16 18:39:58,105 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 18:39:58,115 - ResumeServer - INFO - Served index.html successfully
2025-04-16 18:39:58,349 - ResumeServer - INFO - GET request for /history
2025-04-16 18:39:58,351 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:40:44,593 - ResumeServer - INFO - POST request to /generate (Content-Length: 6912)
2025-04-16 18:40:44,594 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:40:44,595 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpzpwt45rh
2025-04-16 18:40:44,595 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:40:44,600 - ResumeServer - DEBUG - Form fields: ['job_desc', 'resume']
2025-04-16 18:40:44,601 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=posting.txt
2025-04-16 18:40:44,601 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:40:44,603 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:40:44,604 - ResumeServer - INFO - Generating resume...
2025-04-16 18:40:44,607 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:40:44,609 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 18:40:44,609 - ResumeServer - INFO - Initializing Groq client...
2025-04-16 18:40:45,292 - ResumeServer - INFO - Preparing messages for AI request...
2025-04-16 18:40:45,293 - ResumeServer - DEBUG - Using standard prompt (no template)
2025-04-16 18:40:45,293 - ResumeServer - INFO - Sending request to Groq API...
2025-04-16 18:40:45,295 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Respond with 'test ok'"}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 10, 'stream': False}}
2025-04-16 18:40:45,296 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 18:40:45,297 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-04-16 18:40:45,352 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC1397FB0>
2025-04-16 18:40:45,353 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EFC13EB950> server_hostname='api.groq.com' timeout=5.0
2025-04-16 18:40:45,412 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC1410440>
2025-04-16 18:40:45,414 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 18:40:45,415 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 18:40:45,416 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 18:40:45,417 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 18:40:45,417 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 18:40:45,568 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 13:10:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'9313ecb56db9e14a-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'996'), (b'X-Ratelimit-Remaining-Tokens', b'11990'), (b'X-Ratelimit-Reset-Requests', b'4m54.819s'), (b'X-Ratelimit-Reset-Tokens', b'50ms'), (b'X-Request-Id', b'req_01jrzbjbbxe5f8h7awb7td4rwp'), (b'Set-Cookie', b'__cf_bm=YorRJcka7IKbVvH0c0uVEn1xGxltGmhbpgSgzxOolOU-1744809045-1.0.1.1-RMUJ9O.6Nriuu3m35NOb1.8IGSRncCFmS4q37N79NRqA1SJNXzCRtafg06PkQf4xX_n2m.._96jrL3PUledyN7698V4YbEgVNHpGXIYqaac; path=/; expires=Wed, 16-Apr-25 13:40:45 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 18:40:45,571 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 18:40:45,572 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 18:40:45,572 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 18:40:45,573 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 18:40:45,574 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 18:40:45,574 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 13:10:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9313ecb56db9e14a-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '996', 'x-ratelimit-remaining-tokens': '11990', 'x-ratelimit-reset-requests': '4m54.819s', 'x-ratelimit-reset-tokens': '50ms', 'x-request-id': 'req_01jrzbjbbxe5f8h7awb7td4rwp', 'set-cookie': '__cf_bm=YorRJcka7IKbVvH0c0uVEn1xGxltGmhbpgSgzxOolOU-1744809045-1.0.1.1-RMUJ9O.6Nriuu3m35NOb1.8IGSRncCFmS4q37N79NRqA1SJNXzCRtafg06PkQf4xX_n2m.._96jrL3PUledyN7698V4YbEgVNHpGXIYqaac; path=/; expires=Wed, 16-Apr-25 13:40:45 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 18:40:45,576 - ResumeServer - INFO - API test successful: test ok
2025-04-16 18:40:45,576 - ResumeServer - INFO - Creating streaming completion...
2025-04-16 18:40:45,578 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a resume assistant. Format your response with HTML tags for styling. Use <strong> for bold, <h2> for section headers, <ul> and <li> for lists. Provide ONLY the resume content, no analysis or insights. Start directly with the resume content.'}, {'role': 'user', 'content': 'Create a tailored resume based on this resume and job description. Format the response with HTML tags. Provide ONLY the resume content, no analysis or insights.\n\nResume:\n\nResults-driven Machine Learning Engineer with 4+ years of experience developing and deploying AI models for diverse applications, including computer vision, NLP, and predictive analytics. Skilled in Python, TensorFlow, and cloud platforms like GCP. Adept at translating complex data into actionable insights and thriving in collaborative, fast-paced environments.\n\nProfessional Experience\n\nMachine Learning Engineer\n\nNexGen Technologies, Austin, TX\n\nAugust 2021 – Present\n\nBuilt convolutional neural networks (CNNs) with TensorFlow for image classification, achieving 92% accuracy on a custom dataset for retail product recognition.\nDesigned and deployed NLP models using BERT and Hugging Face for automated customer support, reducing response times by 40%.\nImplemented MLOps pipelines with Kubeflow and GCP, automating model retraining and monitoring for production systems.\nPreprocessed terabyte-scale datasets with Apache Spark, optimizing data pipelines for faster model training.\nMentored junior engineers on best practices for model development and version control with Git.\nData Scientist\n\nInsight Analytics, San Francisco, CA (Remote)\n\nJune 2020 – July 2021\n\nDeveloped time-series forecasting models with PyTorch to predict inventory demand, improving supply chain efficiency by 20%.\nConducted exploratory data analysis with pandas and SQL, uncovering trends that informed marketing strategies.\nCreated interactive dashboards with Plotly and Tableau to visualize model outputs for executive stakeholders.\nCollaborated with software engineers to integrate ML models into web applications using Flask APIs.\nResearch Intern, AI Lab\n\nStanford University, Stanford, CA\n\nJanuary 2019 – May 2020\n\nContributed to research on reinforcement learning algorithms, co-authoring a paper presented at NeurIPS 2020.\nBuilt simulation environments with OpenAI Gym to test agent performance in dynamic scenarios.\nOptimized model training workflows, reducing compute costs by 15% through efficient resource allocation.\nEducation\n\nMaster of Science in Artificial Intelligence\n\nCarnegie Mellon University, Pittsburgh, PA\n\nGraduated: May 2020\n\nFocus: Deep Learning and Reinforcement Learning\nCapstone Project: “Scalable RL Models for Autonomous Navigation”\nBachelor of Science in Computer Science\n\nUniversity of Texas at Austin, Austin, TX\n\nGraduated: May 2018\n\nMinor in Applied Mathematics\nSkills\n\nProgramming: Python, C++, SQL, Bash\nML Frameworks: TensorFlow, PyTorch, scikit-learn, Hugging Face, OpenCV\nCloud Platforms: Google Cloud Platform (AI Platform, BigQuery), AWS, Azure\nTools: Docker, Jenkins, MLflow, Git, Jupyter, Tableau\nData Processing: pandas, NumPy, Spark, Dask\nDomains: Computer Vision, NLP, Reinforcement Learning, Time-Series Analysis\nProjects\n\nAutonomous Drone Navigation (GitHub: github.com/alexcarter/drone-ai)\nDeveloped a reinforcement learning model with PyTorch to train drones for obstacle avoidance, tested in simulated environments.\nText Summarization Tool\nBuilt an NLP pipeline with Hugging Face transformers to generate concise summaries of news articles, deployed as a web app with Streamlit.\nFacial Recognition System\nCreated a real-time face detection model using OpenCV and TensorFlow, achieving 95% accuracy on public datasets.\nCertifications\n\nGoogle Cloud Professional Machine Learning Engineer (2023)\nCoursera: Deep Learning Specialization by Andrew Ng (2020)\nPublications & Talks\n\nCo-author, “Advances in Scalable Reinforcement Learning for Robotics,” NeurIPS 2020.\nGuest Speaker, “MLOps for Beginners,” Austin AI Meetup, March 2023.\nAdditional Information\n\nActive contributor to PyTorch (3 pull requests merged).\nVolunteer mentor at Code2AI, teaching high school students ML basics.\nProficient in French; conversational in Japanese.\n\nJob Description:\n\nJob Title: Machine Learning Engineer\n\nCompany: InnovateAI Solutions\n\nLocation: Remote (US-based preferred)\n\nPosted: April 15, 2025\n\nEmployment Type: Full-Time\n\nAbout InnovateAI Solutions:\n\nInnovateAI Solutions is a fast-growing tech company specializing in cutting-edge AI-driven products for healthcare and finance. Our mission is to empower businesses with intelligent solutions that transform industries.\n\nJob Description:\n\nWe are seeking a talented Machine Learning Engineer to join our AI Development team. You will design, develop, and deploy machine learning models to solve complex problems in predictive analytics and natural language processing. This role offers the opportunity to work on impactful projects with a collaborative, innovative team.\n\nKey Responsibilities:\n\nDevelop and optimize machine learning models for tasks such as classification, regression, and NLP.\nCollaborate with data scientists and software engineers to integrate models into production systems.\nConduct experiments to evaluate model performance and iterate on improvements.\nPreprocess and analyze large datasets to extract meaningful insights.\nStay updated on the latest AI/ML research and apply relevant advancements to projects.\nDocument processes and communicate findings to technical and non-technical stakeholders.\nQualifications:\n\nBachelor’s or Master’s degree in Computer Science, Data Science, or a related field.\n3+ years of experience building and deploying machine learning models.\nProficiency in Python and libraries such as TensorFlow, PyTorch, or scikit-learn.\nExperience with cloud platforms (e.g., AWS, Azure, or GCP) for model deployment.\nStrong understanding of algorithms, data structures, and statistics.\nFamiliarity with NLP techniques and tools (e.g., Hugging Face, spaCy) is a plus.\nExcellent problem-solving skills and ability to work in a fast-paced environment.\nPreferred Skills:\n\nExperience with MLOps tools (e.g., Kubeflow, MLflow).\nKnowledge of big data frameworks (e.g., Spark, Hadoop).\nContributions to open-source AI/ML projects or publications in relevant fields.\nBenefits:\n\nCompetitive salary and equity options.\nComprehensive health, dental, and vision insurance.\nFlexible work-from-home policy.\nAnnual learning stipend for professional development.\nCollaborative and inclusive team culture.\nHow to Apply:\n\nPlease submit your resume and a cover letter to careers@innovateai.com. Include links to your GitHub, LinkedIn, or portfolio if applicable. Applications will be reviewed on a rolling basis.\n\nInnovateAI Solutions is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2048, 'stream': True, 'temperature': 0.1, 'top_p': 1}}
2025-04-16 18:40:45,585 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 18:40:45,585 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 18:40:45,586 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 18:40:45,587 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 18:40:45,588 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 18:40:45,588 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 18:40:45,754 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 13:10:45 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'9313ecb6984ce14a-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'no-cache'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'995'), (b'X-Ratelimit-Remaining-Tokens', b'10250'), (b'X-Ratelimit-Reset-Requests', b'7m11.802999999s'), (b'X-Ratelimit-Reset-Tokens', b'8.748999999s'), (b'X-Request-Id', b'req_01jrzbjbj1er2ay0e7566j533s'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 18:40:45,758 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 18:40:45,758 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 13:10:45 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9313ecb6984ce14a-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'no-cache', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '995', 'x-ratelimit-remaining-tokens': '10250', 'x-ratelimit-reset-requests': '7m11.802999999s', 'x-ratelimit-reset-tokens': '8.748999999s', 'x-request-id': 'req_01jrzbjbj1er2ay0e7566j533s', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 18:40:45,761 - ResumeServer - INFO - Collecting response chunks...
2025-04-16 18:40:45,762 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 18:40:45,916 - ResumeServer - DEBUG - Received 10 chunks, response length: 44
2025-04-16 18:40:45,930 - ResumeServer - DEBUG - Received 20 chunks, response length: 73
2025-04-16 18:40:45,959 - ResumeServer - DEBUG - Received 30 chunks, response length: 128
2025-04-16 18:40:45,963 - ResumeServer - DEBUG - Received 40 chunks, response length: 200
2025-04-16 18:40:45,966 - ResumeServer - DEBUG - Received 50 chunks, response length: 257
2025-04-16 18:40:46,006 - ResumeServer - DEBUG - Received 60 chunks, response length: 299
2025-04-16 18:40:46,009 - ResumeServer - DEBUG - Received 70 chunks, response length: 345
2025-04-16 18:40:46,033 - ResumeServer - DEBUG - Received 80 chunks, response length: 425
2025-04-16 18:40:46,036 - ResumeServer - DEBUG - Received 90 chunks, response length: 461
2025-04-16 18:40:46,055 - ResumeServer - DEBUG - Received 100 chunks, response length: 501
2025-04-16 18:40:46,067 - ResumeServer - DEBUG - Received 110 chunks, response length: 556
2025-04-16 18:40:46,081 - ResumeServer - DEBUG - Received 120 chunks, response length: 591
2025-04-16 18:40:46,085 - ResumeServer - DEBUG - Received 130 chunks, response length: 618
2025-04-16 18:40:46,108 - ResumeServer - DEBUG - Received 140 chunks, response length: 669
2025-04-16 18:40:46,128 - ResumeServer - DEBUG - Received 150 chunks, response length: 725
2025-04-16 18:40:46,135 - ResumeServer - DEBUG - Received 160 chunks, response length: 788
2025-04-16 18:40:46,155 - ResumeServer - DEBUG - Received 170 chunks, response length: 822
2025-04-16 18:40:46,173 - ResumeServer - DEBUG - Received 180 chunks, response length: 873
2025-04-16 18:40:46,180 - ResumeServer - DEBUG - Received 190 chunks, response length: 916
2025-04-16 18:40:46,197 - ResumeServer - DEBUG - Received 200 chunks, response length: 940
2025-04-16 18:40:46,215 - ResumeServer - DEBUG - Received 210 chunks, response length: 975
2025-04-16 18:40:46,218 - ResumeServer - DEBUG - Received 220 chunks, response length: 1041
2025-04-16 18:40:46,231 - ResumeServer - DEBUG - Received 230 chunks, response length: 1072
2025-04-16 18:40:46,253 - ResumeServer - DEBUG - Received 240 chunks, response length: 1137
2025-04-16 18:40:46,261 - ResumeServer - DEBUG - Received 250 chunks, response length: 1177
2025-04-16 18:40:46,273 - ResumeServer - DEBUG - Received 260 chunks, response length: 1231
2025-04-16 18:40:46,283 - ResumeServer - DEBUG - Received 270 chunks, response length: 1281
2025-04-16 18:40:46,302 - ResumeServer - DEBUG - Received 280 chunks, response length: 1330
2025-04-16 18:40:46,331 - ResumeServer - DEBUG - Received 290 chunks, response length: 1364
2025-04-16 18:40:46,356 - ResumeServer - DEBUG - Received 300 chunks, response length: 1390
2025-04-16 18:40:46,365 - ResumeServer - DEBUG - Received 310 chunks, response length: 1416
2025-04-16 18:40:46,371 - ResumeServer - DEBUG - Received 320 chunks, response length: 1465
2025-04-16 18:40:46,390 - ResumeServer - DEBUG - Received 330 chunks, response length: 1529
2025-04-16 18:40:46,413 - ResumeServer - DEBUG - Received 340 chunks, response length: 1550
2025-04-16 18:40:46,416 - ResumeServer - DEBUG - Received 350 chunks, response length: 1603
2025-04-16 18:40:46,424 - ResumeServer - DEBUG - Received 360 chunks, response length: 1663
2025-04-16 18:40:46,441 - ResumeServer - DEBUG - Received 370 chunks, response length: 1711
2025-04-16 18:40:46,470 - ResumeServer - DEBUG - Received 380 chunks, response length: 1766
2025-04-16 18:40:46,473 - ResumeServer - DEBUG - Received 390 chunks, response length: 1802
2025-04-16 18:40:46,494 - ResumeServer - DEBUG - Received 400 chunks, response length: 1862
2025-04-16 18:40:46,501 - ResumeServer - DEBUG - Received 410 chunks, response length: 1906
2025-04-16 18:40:46,521 - ResumeServer - DEBUG - Received 420 chunks, response length: 1941
2025-04-16 18:40:46,526 - ResumeServer - DEBUG - Received 430 chunks, response length: 1988
2025-04-16 18:40:46,537 - ResumeServer - DEBUG - Received 440 chunks, response length: 2013
2025-04-16 18:40:46,558 - ResumeServer - DEBUG - Received 450 chunks, response length: 2042
2025-04-16 18:40:46,567 - ResumeServer - DEBUG - Received 460 chunks, response length: 2104
2025-04-16 18:40:46,579 - ResumeServer - DEBUG - Received 470 chunks, response length: 2139
2025-04-16 18:40:46,589 - ResumeServer - DEBUG - Received 480 chunks, response length: 2185
2025-04-16 18:40:46,608 - ResumeServer - DEBUG - Received 490 chunks, response length: 2243
2025-04-16 18:40:46,644 - ResumeServer - DEBUG - Received 500 chunks, response length: 2273
2025-04-16 18:40:46,646 - ResumeServer - DEBUG - Received 510 chunks, response length: 2323
2025-04-16 18:40:46,649 - ResumeServer - DEBUG - Received 520 chunks, response length: 2375
2025-04-16 18:40:46,674 - ResumeServer - DEBUG - Received 530 chunks, response length: 2398
2025-04-16 18:40:46,678 - ResumeServer - DEBUG - Received 540 chunks, response length: 2459
2025-04-16 18:40:46,688 - ResumeServer - DEBUG - Received 550 chunks, response length: 2505
2025-04-16 18:40:46,693 - ResumeServer - DEBUG - Received 560 chunks, response length: 2531
2025-04-16 18:40:46,719 - ResumeServer - DEBUG - Received 570 chunks, response length: 2581
2025-04-16 18:40:46,735 - ResumeServer - DEBUG - Received 580 chunks, response length: 2608
2025-04-16 18:40:46,746 - ResumeServer - DEBUG - Received 590 chunks, response length: 2654
2025-04-16 18:40:46,797 - ResumeServer - DEBUG - Received 600 chunks, response length: 2699
2025-04-16 18:40:46,801 - ResumeServer - DEBUG - Received 610 chunks, response length: 2747
2025-04-16 18:40:46,805 - ResumeServer - DEBUG - Received 620 chunks, response length: 2774
2025-04-16 18:40:46,809 - ResumeServer - DEBUG - Received 630 chunks, response length: 2817
2025-04-16 18:40:46,820 - ResumeServer - DEBUG - Received 640 chunks, response length: 2837
2025-04-16 18:40:46,834 - ResumeServer - DEBUG - Received 650 chunks, response length: 2871
2025-04-16 18:40:46,856 - ResumeServer - DEBUG - Received 660 chunks, response length: 2896
2025-04-16 18:40:46,864 - ResumeServer - DEBUG - Received 670 chunks, response length: 2930
2025-04-16 18:40:46,875 - ResumeServer - DEBUG - Received 680 chunks, response length: 2958
2025-04-16 18:40:46,886 - ResumeServer - DEBUG - Received 690 chunks, response length: 2984
2025-04-16 18:40:46,908 - ResumeServer - DEBUG - Received 700 chunks, response length: 3036
2025-04-16 18:40:46,914 - ResumeServer - DEBUG - Received 710 chunks, response length: 3065
2025-04-16 18:40:46,926 - ResumeServer - DEBUG - Received 720 chunks, response length: 3096
2025-04-16 18:40:46,944 - ResumeServer - DEBUG - Received 730 chunks, response length: 3126
2025-04-16 18:40:46,964 - ResumeServer - DEBUG - Received 740 chunks, response length: 3163
2025-04-16 18:40:46,967 - ResumeServer - DEBUG - Received 750 chunks, response length: 3187
2025-04-16 18:40:47,006 - ResumeServer - DEBUG - Received 760 chunks, response length: 3222
2025-04-16 18:40:47,010 - ResumeServer - DEBUG - Received 770 chunks, response length: 3272
2025-04-16 18:40:47,015 - ResumeServer - DEBUG - Received 780 chunks, response length: 3297
2025-04-16 18:40:47,020 - ResumeServer - DEBUG - Received 790 chunks, response length: 3317
2025-04-16 18:40:47,047 - ResumeServer - DEBUG - Received 800 chunks, response length: 3367
2025-04-16 18:40:47,060 - ResumeServer - DEBUG - Received 810 chunks, response length: 3394
2025-04-16 18:40:47,072 - ResumeServer - DEBUG - Received 820 chunks, response length: 3452
2025-04-16 18:40:47,089 - ResumeServer - DEBUG - Received 830 chunks, response length: 3506
2025-04-16 18:40:47,100 - ResumeServer - DEBUG - Received 840 chunks, response length: 3551
2025-04-16 18:40:47,113 - ResumeServer - DEBUG - Received 850 chunks, response length: 3591
2025-04-16 18:40:47,124 - ResumeServer - DEBUG - Received 860 chunks, response length: 3641
2025-04-16 18:40:47,142 - ResumeServer - DEBUG - Received 870 chunks, response length: 3700
2025-04-16 18:40:47,162 - ResumeServer - DEBUG - Received 880 chunks, response length: 3735
2025-04-16 18:40:47,195 - ResumeServer - DEBUG - Received 890 chunks, response length: 3779
2025-04-16 18:40:47,239 - ResumeServer - DEBUG - Received 900 chunks, response length: 3833
2025-04-16 18:40:47,264 - ResumeServer - DEBUG - Received 910 chunks, response length: 3877
2025-04-16 18:40:47,285 - ResumeServer - DEBUG - Received 920 chunks, response length: 3910
2025-04-16 18:40:47,313 - ResumeServer - DEBUG - Received 930 chunks, response length: 3939
2025-04-16 18:40:47,345 - ResumeServer - DEBUG - Received 940 chunks, response length: 3997
2025-04-16 18:40:47,387 - ResumeServer - DEBUG - Received 950 chunks, response length: 4020
2025-04-16 18:40:47,437 - ResumeServer - DEBUG - Received 960 chunks, response length: 4067
2025-04-16 18:40:47,457 - ResumeServer - DEBUG - Received 970 chunks, response length: 4089
2025-04-16 18:40:47,480 - ResumeServer - DEBUG - Received 980 chunks, response length: 4117
2025-04-16 18:40:47,496 - ResumeServer - DEBUG - Received 990 chunks, response length: 4142
2025-04-16 18:40:47,529 - ResumeServer - DEBUG - Received 1000 chunks, response length: 4198
2025-04-16 18:40:47,568 - ResumeServer - DEBUG - Received 1010 chunks, response length: 4220
2025-04-16 18:40:47,604 - ResumeServer - DEBUG - Received 1020 chunks, response length: 4247
2025-04-16 18:40:47,653 - ResumeServer - DEBUG - Received 1030 chunks, response length: 4289
2025-04-16 18:40:47,673 - ResumeServer - DEBUG - Received 1040 chunks, response length: 4310
2025-04-16 18:40:47,693 - ResumeServer - DEBUG - Received 1050 chunks, response length: 4345
2025-04-16 18:40:47,719 - ResumeServer - DEBUG - Received 1060 chunks, response length: 4382
2025-04-16 18:40:47,764 - ResumeServer - DEBUG - Received 1070 chunks, response length: 4419
2025-04-16 18:40:47,841 - ResumeServer - DEBUG - Received 1080 chunks, response length: 4450
2025-04-16 18:40:47,876 - ResumeServer - DEBUG - Received 1090 chunks, response length: 4500
2025-04-16 18:40:47,911 - ResumeServer - DEBUG - Received 1100 chunks, response length: 4541
2025-04-16 18:40:49,870 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 18:40:49,871 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 18:40:49,871 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 18:40:49,872 - ResumeServer - INFO - Response collection complete. Total 1109 chunks, final length: 4565
2025-04-16 18:40:49,872 - ResumeServer - INFO - Response preview: <h2>Results-Driven Machine Learning Engineer</h2>
<p>Highly motivated and experienced Machine Learni...
2025-04-16 18:40:49,878 - ResumeServer - INFO - Building PDF document...
2025-04-16 18:40:49,896 - ResumeServer - INFO - PDF generation successful, size: 6228 bytes
2025-04-16 18:40:49,897 - ResumeServer - INFO - Resume generated successfully. PDF size: 6228 bytes
2025-04-16 18:40:49,897 - ResumeServer - DEBUG - Converting response to JSON
2025-04-16 18:40:49,898 - ResumeServer - DEBUG - Response headers set: application/json
2025-04-16 18:40:49,899 - ResumeServer - INFO - Successfully sent PDF response
2025-04-16 18:40:49,900 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpzpwt45rh
2025-04-16 18:40:50,220 - ResumeServer - INFO - GET request for /history
2025-04-16 18:40:50,221 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:44:51,190 - ResumeServer - INFO - GET request for /
2025-04-16 18:44:51,191 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 18:44:51,192 - ResumeServer - INFO - Served index.html successfully
2025-04-16 18:44:51,206 - ResumeServer - INFO - GET request for /history
2025-04-16 18:44:51,208 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:45:17,393 - ResumeServer - INFO - POST request to /generate (Content-Length: 19381)
2025-04-16 18:45:17,394 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:45:17,395 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp9r8n0k8x
2025-04-16 18:45:17,396 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:45:17,402 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 18:45:17,403 - ResumeServer - INFO - Got files: resume=resume.pdf, job_desc=tailored_resume_2025-04-16.pdf
2025-04-16 18:45:17,403 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:45:17,409 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:45:17,412 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmp9r8n0k8x\template.txt
2025-04-16 18:45:17,413 - ResumeServer - INFO - Generating resume...
2025-04-16 18:45:17,436 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:45:17,438 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    logger.info('Server stopping...')
                     ^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:45:17,440 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:45:19,442 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:45:19,444 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    logger.info('Server stopping...')
                     ^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:45:19,445 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:45:21,447 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:45:21,448 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    logger.info('Server stopping...')
                     ^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:45:21,449 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:45:21,451 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    logger.info('Server stopping...')
                     ^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:45:21,451 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:45:21,453 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp9r8n0k8x
2025-04-16 18:45:27,252 - ResumeServer - INFO - POST request to /generate (Content-Length: 19381)
2025-04-16 18:45:27,253 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:45:27,253 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp38qi2wfe
2025-04-16 18:45:27,254 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:45:27,256 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 18:45:27,257 - ResumeServer - INFO - Got files: resume=resume.pdf, job_desc=tailored_resume_2025-04-16.pdf
2025-04-16 18:45:27,257 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:45:27,259 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:45:27,259 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmp38qi2wfe\template.txt
2025-04-16 18:45:27,260 - ResumeServer - INFO - Generating resume...
2025-04-16 18:45:27,261 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:45:27,262 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    logger.info('Server stopping...')
                     ^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:45:27,262 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:45:29,263 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:45:29,265 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    logger.info('Server stopping...')
                     ^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:45:29,265 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:45:31,266 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:45:31,268 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    logger.info('Server stopping...')
                     ^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:45:31,270 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:45:31,272 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
    logger.info('Server stopping...')
                     ^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 18:45:31,274 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 18:45:31,275 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp38qi2wfe
2025-04-16 18:45:48,011 - ResumeServer - INFO - POST request to /generate (Content-Length: 10666)
2025-04-16 18:45:48,012 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:45:48,013 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpwjzq1yit
2025-04-16 18:45:48,014 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:45:48,020 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 18:45:48,021 - ResumeServer - INFO - Got files: resume=jobDesc.txt, job_desc=jobDesc.txt
2025-04-16 18:45:48,021 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:45:48,024 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:45:48,025 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmpwjzq1yit\template.txt
2025-04-16 18:45:48,026 - ResumeServer - INFO - Generating resume...
2025-04-16 18:45:48,028 - ResumeServer - DEBUG - Resume content length: 1422 chars
2025-04-16 18:45:48,031 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 18:45:48,042 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:45:48,043 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:45:48,044 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:45:50,046 - ResumeServer - DEBUG - Resume content length: 1422 chars
2025-04-16 18:45:50,047 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 18:45:50,048 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:45:50,049 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:45:50,050 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 18:45:52,051 - ResumeServer - DEBUG - Resume content length: 1422 chars
2025-04-16 18:45:52,052 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 18:45:52,053 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:45:52,053 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:45:52,054 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:45:52,055 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 18:45:52,056 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 18:45:52,057 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpwjzq1yit
2025-04-16 18:45:59,620 - ResumeServer - INFO - POST request to /generate (Content-Length: 3258)
2025-04-16 18:45:59,621 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:45:59,622 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpy4mi06nc
2025-04-16 18:45:59,622 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:45:59,624 - ResumeServer - DEBUG - Form fields: ['job_desc', 'resume']
2025-04-16 18:45:59,625 - ResumeServer - INFO - Got files: resume=jobDesc.txt, job_desc=jobDesc.txt
2025-04-16 18:45:59,625 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:45:59,626 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:45:59,626 - ResumeServer - INFO - Generating resume...
2025-04-16 18:45:59,627 - ResumeServer - DEBUG - Resume content length: 1422 chars
2025-04-16 18:45:59,629 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 18:45:59,629 - ResumeServer - INFO - Initializing Groq client...
2025-04-16 18:45:59,974 - ResumeServer - INFO - Preparing messages for AI request...
2025-04-16 18:45:59,975 - ResumeServer - DEBUG - Using standard prompt (no template)
2025-04-16 18:45:59,975 - ResumeServer - INFO - Sending request to Groq API...
2025-04-16 18:45:59,976 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Respond with 'test ok'"}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 10, 'stream': False}}
2025-04-16 18:45:59,977 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 18:45:59,978 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-04-16 18:46:00,138 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC1594710>
2025-04-16 18:46:00,138 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EFC0BC6A50> server_hostname='api.groq.com' timeout=5.0
2025-04-16 18:46:00,202 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC1594440>
2025-04-16 18:46:00,203 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 18:46:00,203 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 18:46:00,204 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 18:46:00,204 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 18:46:00,205 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 18:46:00,384 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 13:16:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'9313f464ed977fa1-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'997'), (b'X-Ratelimit-Remaining-Tokens', b'11990'), (b'X-Ratelimit-Reset-Requests', b'3m23.79s'), (b'X-Ratelimit-Reset-Tokens', b'50ms'), (b'X-Request-Id', b'req_01jrzbvysme9grena564fvjjwb'), (b'Set-Cookie', b'__cf_bm=1yBnNEi4_CjGM7JaP2Qb8PVLEIUXpO3zeRQPhx_7F8A-1744809360-1.0.1.1-fJot1_TdXY5_h_StzCNmSMOCLr_ltlx0uoHSl_lW0jyPDnFFJ3jep0Qgfiouw0ejqQkR4WLFImaIRfeyqWqu620SKX47X6St98w3EoRTlxA; path=/; expires=Wed, 16-Apr-25 13:46:00 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 18:46:00,386 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 18:46:00,386 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 18:46:00,387 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 18:46:00,388 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 18:46:00,388 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 18:46:00,389 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 13:16:00 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9313f464ed977fa1-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '997', 'x-ratelimit-remaining-tokens': '11990', 'x-ratelimit-reset-requests': '3m23.79s', 'x-ratelimit-reset-tokens': '50ms', 'x-request-id': 'req_01jrzbvysme9grena564fvjjwb', 'set-cookie': '__cf_bm=1yBnNEi4_CjGM7JaP2Qb8PVLEIUXpO3zeRQPhx_7F8A-1744809360-1.0.1.1-fJot1_TdXY5_h_StzCNmSMOCLr_ltlx0uoHSl_lW0jyPDnFFJ3jep0Qgfiouw0ejqQkR4WLFImaIRfeyqWqu620SKX47X6St98w3EoRTlxA; path=/; expires=Wed, 16-Apr-25 13:46:00 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 18:46:00,390 - ResumeServer - INFO - API test successful: test ok
2025-04-16 18:46:00,390 - ResumeServer - INFO - Creating streaming completion...
2025-04-16 18:46:00,392 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a resume assistant. Format your response with HTML tags for styling. Use <strong> for bold, <h2> for section headers, <ul> and <li> for lists. Provide ONLY the resume content, no analysis or insights. Start directly with the resume content.'}, {'role': 'user', 'content': "Create a tailored resume based on this resume and job description. Format the response with HTML tags. Provide ONLY the resume content, no analysis or insights.\n\nResume:\n\nSoftware Engineer - Full Stack Developer\n\nCompany: Tech Innovations Inc.\nLocation: Remote\nType: Full-time\n\nJob Description:\nWe are seeking a skilled Full Stack Developer to join our dynamic team. The ideal candidate will be responsible for developing and maintaining web applications using modern technologies.\n\nResponsibilities:\n- Design and implement scalable web applications\n- Develop front-end interfaces using React.js\n- Create and maintain back-end services using Node.js and Python\n- Work with databases (SQL and NoSQL)\n- Implement RESTful APIs\n- Write clean, maintainable code\n- Collaborate with cross-functional teams\n- Participate in code reviews and technical discussions\n\nRequirements:\n- Bachelor's degree in Computer Science or related field\n- 3+ years of experience in full-stack development\n- Strong proficiency in JavaScript, Python, and SQL\n- Experience with React.js and Node.js\n- Knowledge of cloud platforms (AWS, Azure, or GCP)\n- Familiarity with version control systems (Git)\n- Excellent problem-solving skills\n- Strong communication and teamwork abilities\n\nPreferred Qualifications:\n- Experience with containerization (Docker)\n- Knowledge of CI/CD pipelines\n- Understanding of microservices architecture\n- Contributions to open-source projects\n\nBenefits:\n- Competitive salary\n- Health insurance\n- 401(k) matching\n- Flexible work hours\n- Professional development opportunities\n- Remote work options \n\nJob Description:\n\nSoftware Engineer - Full Stack Developer\n\nCompany: Tech Innovations Inc.\nLocation: Remote\nType: Full-time\n\nJob Description:\nWe are seeking a skilled Full Stack Developer to join our dynamic team. The ideal candidate will be responsible for developing and maintaining web applications using modern technologies.\n\nResponsibilities:\n- Design and implement scalable web applications\n- Develop front-end interfaces using React.js\n- Create and maintain back-end services using Node.js and Python\n- Work with databases (SQL and NoSQL)\n- Implement RESTful APIs\n- Write clean, maintainable code\n- Collaborate with cross-functional teams\n- Participate in code reviews and technical discussions\n\nRequirements:\n- Bachelor's degree in Computer Science or related field\n- 3+ years of experience in full-stack development\n- Strong proficiency in JavaScript, Python, and SQL\n- Experience with React.js and Node.js\n- Knowledge of cloud platforms (AWS, Azure, or GCP)\n- Familiarity with version control systems (Git)\n- Excellent problem-solving skills\n- Strong communication and teamwork abilities\n\nPreferred Qualifications:\n- Experience with containerization (Docker)\n- Knowledge of CI/CD pipelines\n- Understanding of microservices architecture\n- Contributions to open-source projects\n\nBenefits:\n- Competitive salary\n- Health insurance\n- 401(k) matching\n- Flexible work hours\n- Professional development opportunities\n- Remote work options "}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2048, 'stream': True, 'temperature': 0.1, 'top_p': 1}}
2025-04-16 18:46:00,394 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 18:46:00,395 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 18:46:00,396 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 18:46:00,396 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 18:46:00,397 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 18:46:00,397 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 18:46:00,564 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 13:16:00 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'9313f4662eb97fa1-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'no-cache'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'996'), (b'X-Ratelimit-Remaining-Tokens', b'11153'), (b'X-Ratelimit-Reset-Requests', b'5m45.395s'), (b'X-Ratelimit-Reset-Tokens', b'4.231s'), (b'X-Request-Id', b'req_01jrzbvz00ecwrtyz6eb0v5z0h'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 18:46:00,565 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 18:46:00,566 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 13:16:00 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9313f4662eb97fa1-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'no-cache', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '996', 'x-ratelimit-remaining-tokens': '11153', 'x-ratelimit-reset-requests': '5m45.395s', 'x-ratelimit-reset-tokens': '4.231s', 'x-request-id': 'req_01jrzbvz00ecwrtyz6eb0v5z0h', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 18:46:00,567 - ResumeServer - INFO - Collecting response chunks...
2025-04-16 18:46:00,567 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 18:46:00,650 - ResumeServer - DEBUG - Received 10 chunks, response length: 34
2025-04-16 18:46:00,673 - ResumeServer - DEBUG - Received 20 chunks, response length: 80
2025-04-16 18:46:00,723 - ResumeServer - DEBUG - Received 30 chunks, response length: 113
2025-04-16 18:46:00,749 - ResumeServer - DEBUG - Received 40 chunks, response length: 147
2025-04-16 18:46:00,754 - ResumeServer - DEBUG - Received 50 chunks, response length: 168
2025-04-16 18:46:00,763 - ResumeServer - DEBUG - Received 60 chunks, response length: 190
2025-04-16 18:46:00,782 - ResumeServer - DEBUG - Received 70 chunks, response length: 224
2025-04-16 18:46:00,790 - ResumeServer - DEBUG - Received 80 chunks, response length: 248
2025-04-16 18:46:00,816 - ResumeServer - DEBUG - Received 90 chunks, response length: 304
2025-04-16 18:46:00,851 - ResumeServer - DEBUG - Received 100 chunks, response length: 371
2025-04-16 18:46:00,879 - ResumeServer - DEBUG - Received 110 chunks, response length: 426
2025-04-16 18:46:00,881 - ResumeServer - DEBUG - Received 120 chunks, response length: 472
2025-04-16 18:46:00,897 - ResumeServer - DEBUG - Received 130 chunks, response length: 508
2025-04-16 18:46:00,906 - ResumeServer - DEBUG - Received 140 chunks, response length: 537
2025-04-16 18:46:00,931 - ResumeServer - DEBUG - Received 150 chunks, response length: 584
2025-04-16 18:46:00,955 - ResumeServer - DEBUG - Received 160 chunks, response length: 609
2025-04-16 18:46:00,957 - ResumeServer - DEBUG - Received 170 chunks, response length: 639
2025-04-16 18:46:00,959 - ResumeServer - DEBUG - Received 180 chunks, response length: 672
2025-04-16 18:46:00,974 - ResumeServer - DEBUG - Received 190 chunks, response length: 697
2025-04-16 18:46:00,988 - ResumeServer - DEBUG - Received 200 chunks, response length: 720
2025-04-16 18:46:01,011 - ResumeServer - DEBUG - Received 210 chunks, response length: 751
2025-04-16 18:46:01,014 - ResumeServer - DEBUG - Received 220 chunks, response length: 781
2025-04-16 18:46:01,031 - ResumeServer - DEBUG - Received 230 chunks, response length: 815
2025-04-16 18:46:01,048 - ResumeServer - DEBUG - Received 240 chunks, response length: 832
2025-04-16 18:46:01,050 - ResumeServer - DEBUG - Received 250 chunks, response length: 867
2025-04-16 18:46:01,080 - ResumeServer - DEBUG - Received 260 chunks, response length: 904
2025-04-16 18:46:01,116 - ResumeServer - DEBUG - Received 270 chunks, response length: 947
2025-04-16 18:46:01,137 - ResumeServer - DEBUG - Received 280 chunks, response length: 982
2025-04-16 18:46:01,160 - ResumeServer - DEBUG - Received 290 chunks, response length: 1038
2025-04-16 18:46:01,178 - ResumeServer - DEBUG - Received 300 chunks, response length: 1076
2025-04-16 18:46:01,192 - ResumeServer - DEBUG - Received 310 chunks, response length: 1105
2025-04-16 18:46:01,224 - ResumeServer - DEBUG - Received 320 chunks, response length: 1162
2025-04-16 18:46:01,238 - ResumeServer - DEBUG - Received 330 chunks, response length: 1199
2025-04-16 18:46:01,250 - ResumeServer - DEBUG - Received 340 chunks, response length: 1243
2025-04-16 18:46:01,267 - ResumeServer - DEBUG - Received 350 chunks, response length: 1275
2025-04-16 18:46:01,309 - ResumeServer - DEBUG - Received 360 chunks, response length: 1327
2025-04-16 18:46:01,314 - ResumeServer - DEBUG - Received 370 chunks, response length: 1354
2025-04-16 18:46:01,323 - ResumeServer - DEBUG - Received 380 chunks, response length: 1419
2025-04-16 18:46:01,336 - ResumeServer - DEBUG - Received 390 chunks, response length: 1460
2025-04-16 18:46:01,360 - ResumeServer - DEBUG - Received 400 chunks, response length: 1493
2025-04-16 18:46:01,374 - ResumeServer - DEBUG - Received 410 chunks, response length: 1541
2025-04-16 18:46:01,399 - ResumeServer - DEBUG - Received 420 chunks, response length: 1566
2025-04-16 18:46:01,430 - ResumeServer - DEBUG - Received 430 chunks, response length: 1601
2025-04-16 18:46:01,472 - ResumeServer - DEBUG - Received 440 chunks, response length: 1627
2025-04-16 18:46:01,474 - ResumeServer - DEBUG - Received 450 chunks, response length: 1651
2025-04-16 18:46:01,499 - ResumeServer - DEBUG - Received 460 chunks, response length: 1699
2025-04-16 18:46:01,538 - ResumeServer - DEBUG - Received 470 chunks, response length: 1729
2025-04-16 18:46:01,565 - ResumeServer - DEBUG - Received 480 chunks, response length: 1761
2025-04-16 18:46:02,435 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 18:46:02,436 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 18:46:02,437 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 18:46:02,437 - ResumeServer - INFO - Response collection complete. Total 487 chunks, final length: 1773
2025-04-16 18:46:02,437 - ResumeServer - INFO - Response preview: <h2>Full Stack Developer Resume</h2>
<strong>Contact Information:</strong>
<ul>
  <li>Email: [exampl...
2025-04-16 18:46:02,440 - ResumeServer - INFO - Building PDF document...
2025-04-16 18:46:02,444 - ResumeServer - INFO - PDF generation successful, size: 3516 bytes
2025-04-16 18:46:02,444 - ResumeServer - INFO - Resume generated successfully. PDF size: 3516 bytes
2025-04-16 18:46:02,445 - ResumeServer - DEBUG - Converting response to JSON
2025-04-16 18:46:02,446 - ResumeServer - DEBUG - Response headers set: application/json
2025-04-16 18:46:02,446 - ResumeServer - INFO - Successfully sent PDF response
2025-04-16 18:46:02,447 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpy4mi06nc
2025-04-16 18:46:02,453 - ResumeServer - INFO - GET request for /history
2025-04-16 18:46:02,454 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:49:40,724 - ResumeServer - INFO - GET request for /
2025-04-16 18:49:40,726 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 18:49:40,726 - ResumeServer - INFO - Served index.html successfully
2025-04-16 18:49:40,741 - ResumeServer - INFO - GET request for /history
2025-04-16 18:49:40,742 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:49:58,754 - ResumeServer - INFO - POST request to /generate (Content-Length: 6912)
2025-04-16 18:49:58,755 - ResumeServer - INFO - Processing /generate request
2025-04-16 18:49:58,757 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpkf1ifyz6
2025-04-16 18:49:58,758 - ResumeServer - DEBUG - Parsing form data
2025-04-16 18:49:58,764 - ResumeServer - DEBUG - Form fields: ['job_desc', 'resume']
2025-04-16 18:49:58,765 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=posting.txt
2025-04-16 18:49:58,766 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 18:49:58,771 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 18:49:58,772 - ResumeServer - INFO - Generating resume...
2025-04-16 18:49:58,777 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 18:49:58,781 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 18:49:58,782 - ResumeServer - INFO - Initializing Groq client...
2025-04-16 18:49:59,756 - ResumeServer - INFO - Preparing messages for AI request...
2025-04-16 18:49:59,757 - ResumeServer - DEBUG - Using standard prompt (no template)
2025-04-16 18:49:59,758 - ResumeServer - INFO - Sending request to Groq API...
2025-04-16 18:49:59,762 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Respond with 'test ok'"}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 10, 'stream': False}}
2025-04-16 18:49:59,765 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 18:49:59,766 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-04-16 18:49:59,885 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC15AC170>
2025-04-16 18:49:59,886 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EFC13D01D0> server_hostname='api.groq.com' timeout=5.0
2025-04-16 18:49:59,945 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC1597E60>
2025-04-16 18:49:59,946 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 18:49:59,947 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 18:49:59,948 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 18:49:59,950 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 18:49:59,952 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 18:50:00,093 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 13:19:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'9313fa3f492d7fa5-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'997'), (b'X-Ratelimit-Remaining-Tokens', b'11990'), (b'X-Ratelimit-Reset-Requests', b'3m12.473s'), (b'X-Ratelimit-Reset-Tokens', b'50ms'), (b'X-Request-Id', b'req_01jrzc38xafj0t550bvx6p93p0'), (b'Set-Cookie', b'__cf_bm=_qR6ncUEWovXgx0ccjqz1WzNpprNodbupcZiH85Mi5M-1744809599-1.0.1.1-zLBjUlBBDMHIj4rJJjMs9Y1nIVfy4FID6653LHebIf4leKgLjtR4OFUC1P1sTNAKWZuIT8hscGM1N.miV_4dKvBhWIrmVyj4vupM59gc4Kk; path=/; expires=Wed, 16-Apr-25 13:49:59 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 18:50:00,097 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 18:50:00,098 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 18:50:00,100 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 18:50:00,101 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 18:50:00,102 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 18:50:00,103 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 13:19:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9313fa3f492d7fa5-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '997', 'x-ratelimit-remaining-tokens': '11990', 'x-ratelimit-reset-requests': '3m12.473s', 'x-ratelimit-reset-tokens': '50ms', 'x-request-id': 'req_01jrzc38xafj0t550bvx6p93p0', 'set-cookie': '__cf_bm=_qR6ncUEWovXgx0ccjqz1WzNpprNodbupcZiH85Mi5M-1744809599-1.0.1.1-zLBjUlBBDMHIj4rJJjMs9Y1nIVfy4FID6653LHebIf4leKgLjtR4OFUC1P1sTNAKWZuIT8hscGM1N.miV_4dKvBhWIrmVyj4vupM59gc4Kk; path=/; expires=Wed, 16-Apr-25 13:49:59 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 18:50:00,106 - ResumeServer - INFO - API test successful: test ok
2025-04-16 18:50:00,108 - ResumeServer - INFO - Creating streaming completion...
2025-04-16 18:50:00,113 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a resume assistant. Format your response with HTML tags for styling. Use <strong> for bold, <h2> for section headers, <ul> and <li> for lists. Provide ONLY the resume content, no analysis or insights. Start directly with the resume content.'}, {'role': 'user', 'content': 'Create a tailored resume based on this resume and job description. Format the response with HTML tags. Provide ONLY the resume content, no analysis or insights.\n\nResume:\n\nResults-driven Machine Learning Engineer with 4+ years of experience developing and deploying AI models for diverse applications, including computer vision, NLP, and predictive analytics. Skilled in Python, TensorFlow, and cloud platforms like GCP. Adept at translating complex data into actionable insights and thriving in collaborative, fast-paced environments.\n\nProfessional Experience\n\nMachine Learning Engineer\n\nNexGen Technologies, Austin, TX\n\nAugust 2021 – Present\n\nBuilt convolutional neural networks (CNNs) with TensorFlow for image classification, achieving 92% accuracy on a custom dataset for retail product recognition.\nDesigned and deployed NLP models using BERT and Hugging Face for automated customer support, reducing response times by 40%.\nImplemented MLOps pipelines with Kubeflow and GCP, automating model retraining and monitoring for production systems.\nPreprocessed terabyte-scale datasets with Apache Spark, optimizing data pipelines for faster model training.\nMentored junior engineers on best practices for model development and version control with Git.\nData Scientist\n\nInsight Analytics, San Francisco, CA (Remote)\n\nJune 2020 – July 2021\n\nDeveloped time-series forecasting models with PyTorch to predict inventory demand, improving supply chain efficiency by 20%.\nConducted exploratory data analysis with pandas and SQL, uncovering trends that informed marketing strategies.\nCreated interactive dashboards with Plotly and Tableau to visualize model outputs for executive stakeholders.\nCollaborated with software engineers to integrate ML models into web applications using Flask APIs.\nResearch Intern, AI Lab\n\nStanford University, Stanford, CA\n\nJanuary 2019 – May 2020\n\nContributed to research on reinforcement learning algorithms, co-authoring a paper presented at NeurIPS 2020.\nBuilt simulation environments with OpenAI Gym to test agent performance in dynamic scenarios.\nOptimized model training workflows, reducing compute costs by 15% through efficient resource allocation.\nEducation\n\nMaster of Science in Artificial Intelligence\n\nCarnegie Mellon University, Pittsburgh, PA\n\nGraduated: May 2020\n\nFocus: Deep Learning and Reinforcement Learning\nCapstone Project: “Scalable RL Models for Autonomous Navigation”\nBachelor of Science in Computer Science\n\nUniversity of Texas at Austin, Austin, TX\n\nGraduated: May 2018\n\nMinor in Applied Mathematics\nSkills\n\nProgramming: Python, C++, SQL, Bash\nML Frameworks: TensorFlow, PyTorch, scikit-learn, Hugging Face, OpenCV\nCloud Platforms: Google Cloud Platform (AI Platform, BigQuery), AWS, Azure\nTools: Docker, Jenkins, MLflow, Git, Jupyter, Tableau\nData Processing: pandas, NumPy, Spark, Dask\nDomains: Computer Vision, NLP, Reinforcement Learning, Time-Series Analysis\nProjects\n\nAutonomous Drone Navigation (GitHub: github.com/alexcarter/drone-ai)\nDeveloped a reinforcement learning model with PyTorch to train drones for obstacle avoidance, tested in simulated environments.\nText Summarization Tool\nBuilt an NLP pipeline with Hugging Face transformers to generate concise summaries of news articles, deployed as a web app with Streamlit.\nFacial Recognition System\nCreated a real-time face detection model using OpenCV and TensorFlow, achieving 95% accuracy on public datasets.\nCertifications\n\nGoogle Cloud Professional Machine Learning Engineer (2023)\nCoursera: Deep Learning Specialization by Andrew Ng (2020)\nPublications & Talks\n\nCo-author, “Advances in Scalable Reinforcement Learning for Robotics,” NeurIPS 2020.\nGuest Speaker, “MLOps for Beginners,” Austin AI Meetup, March 2023.\nAdditional Information\n\nActive contributor to PyTorch (3 pull requests merged).\nVolunteer mentor at Code2AI, teaching high school students ML basics.\nProficient in French; conversational in Japanese.\n\nJob Description:\n\nJob Title: Machine Learning Engineer\n\nCompany: InnovateAI Solutions\n\nLocation: Remote (US-based preferred)\n\nPosted: April 15, 2025\n\nEmployment Type: Full-Time\n\nAbout InnovateAI Solutions:\n\nInnovateAI Solutions is a fast-growing tech company specializing in cutting-edge AI-driven products for healthcare and finance. Our mission is to empower businesses with intelligent solutions that transform industries.\n\nJob Description:\n\nWe are seeking a talented Machine Learning Engineer to join our AI Development team. You will design, develop, and deploy machine learning models to solve complex problems in predictive analytics and natural language processing. This role offers the opportunity to work on impactful projects with a collaborative, innovative team.\n\nKey Responsibilities:\n\nDevelop and optimize machine learning models for tasks such as classification, regression, and NLP.\nCollaborate with data scientists and software engineers to integrate models into production systems.\nConduct experiments to evaluate model performance and iterate on improvements.\nPreprocess and analyze large datasets to extract meaningful insights.\nStay updated on the latest AI/ML research and apply relevant advancements to projects.\nDocument processes and communicate findings to technical and non-technical stakeholders.\nQualifications:\n\nBachelor’s or Master’s degree in Computer Science, Data Science, or a related field.\n3+ years of experience building and deploying machine learning models.\nProficiency in Python and libraries such as TensorFlow, PyTorch, or scikit-learn.\nExperience with cloud platforms (e.g., AWS, Azure, or GCP) for model deployment.\nStrong understanding of algorithms, data structures, and statistics.\nFamiliarity with NLP techniques and tools (e.g., Hugging Face, spaCy) is a plus.\nExcellent problem-solving skills and ability to work in a fast-paced environment.\nPreferred Skills:\n\nExperience with MLOps tools (e.g., Kubeflow, MLflow).\nKnowledge of big data frameworks (e.g., Spark, Hadoop).\nContributions to open-source AI/ML projects or publications in relevant fields.\nBenefits:\n\nCompetitive salary and equity options.\nComprehensive health, dental, and vision insurance.\nFlexible work-from-home policy.\nAnnual learning stipend for professional development.\nCollaborative and inclusive team culture.\nHow to Apply:\n\nPlease submit your resume and a cover letter to careers@innovateai.com. Include links to your GitHub, LinkedIn, or portfolio if applicable. Applications will be reviewed on a rolling basis.\n\nInnovateAI Solutions is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2048, 'stream': True, 'temperature': 0.1, 'top_p': 1}}
2025-04-16 18:50:00,125 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 18:50:00,126 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 18:50:00,127 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 18:50:00,128 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 18:50:00,129 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 18:50:00,129 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 18:50:00,337 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 13:20:00 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'9313fa407a2e7fa5-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'no-cache'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'996'), (b'X-Ratelimit-Remaining-Tokens', b'10260'), (b'X-Ratelimit-Reset-Requests', b'5m45.355s'), (b'X-Ratelimit-Reset-Tokens', b'8.696s'), (b'X-Request-Id', b'req_01jrzc394zfj1858tsk0a0nfzb'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 18:50:00,339 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 18:50:00,340 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 13:20:00 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9313fa407a2e7fa5-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'no-cache', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '996', 'x-ratelimit-remaining-tokens': '10260', 'x-ratelimit-reset-requests': '5m45.355s', 'x-ratelimit-reset-tokens': '8.696s', 'x-request-id': 'req_01jrzc394zfj1858tsk0a0nfzb', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 18:50:00,344 - ResumeServer - INFO - Collecting response chunks...
2025-04-16 18:50:00,345 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 18:50:00,494 - ResumeServer - DEBUG - Received 10 chunks, response length: 44
2025-04-16 18:50:00,502 - ResumeServer - DEBUG - Received 20 chunks, response length: 73
2025-04-16 18:50:00,506 - ResumeServer - DEBUG - Received 30 chunks, response length: 128
2025-04-16 18:50:00,538 - ResumeServer - DEBUG - Received 40 chunks, response length: 200
2025-04-16 18:50:00,544 - ResumeServer - DEBUG - Received 50 chunks, response length: 257
2025-04-16 18:50:00,584 - ResumeServer - DEBUG - Received 60 chunks, response length: 299
2025-04-16 18:50:00,588 - ResumeServer - DEBUG - Received 70 chunks, response length: 348
2025-04-16 18:50:00,593 - ResumeServer - DEBUG - Received 80 chunks, response length: 414
2025-04-16 18:50:00,598 - ResumeServer - DEBUG - Received 90 chunks, response length: 467
2025-04-16 18:50:00,620 - ResumeServer - DEBUG - Received 100 chunks, response length: 500
2025-04-16 18:50:00,640 - ResumeServer - DEBUG - Received 110 chunks, response length: 544
2025-04-16 18:50:00,664 - ResumeServer - DEBUG - Received 120 chunks, response length: 578
2025-04-16 18:50:00,679 - ResumeServer - DEBUG - Received 130 chunks, response length: 612
2025-04-16 18:50:00,699 - ResumeServer - DEBUG - Received 140 chunks, response length: 661
2025-04-16 18:50:00,709 - ResumeServer - DEBUG - Received 150 chunks, response length: 712
2025-04-16 18:50:00,719 - ResumeServer - DEBUG - Received 160 chunks, response length: 763
2025-04-16 18:50:00,741 - ResumeServer - DEBUG - Received 170 chunks, response length: 806
2025-04-16 18:50:00,747 - ResumeServer - DEBUG - Received 180 chunks, response length: 858
2025-04-16 18:50:00,764 - ResumeServer - DEBUG - Received 190 chunks, response length: 896
2025-04-16 18:50:00,778 - ResumeServer - DEBUG - Received 200 chunks, response length: 936
2025-04-16 18:50:00,787 - ResumeServer - DEBUG - Received 210 chunks, response length: 971
2025-04-16 18:50:00,797 - ResumeServer - DEBUG - Received 220 chunks, response length: 1027
2025-04-16 18:50:00,811 - ResumeServer - DEBUG - Received 230 chunks, response length: 1071
2025-04-16 18:50:00,829 - ResumeServer - DEBUG - Received 240 chunks, response length: 1133
2025-04-16 18:50:00,850 - ResumeServer - DEBUG - Received 250 chunks, response length: 1165
2025-04-16 18:50:00,859 - ResumeServer - DEBUG - Received 260 chunks, response length: 1234
2025-04-16 18:50:00,882 - ResumeServer - DEBUG - Received 270 chunks, response length: 1267
2025-04-16 18:50:00,885 - ResumeServer - DEBUG - Received 280 chunks, response length: 1324
2025-04-16 18:50:00,901 - ResumeServer - DEBUG - Received 290 chunks, response length: 1348
2025-04-16 18:50:00,922 - ResumeServer - DEBUG - Received 300 chunks, response length: 1375
2025-04-16 18:50:00,935 - ResumeServer - DEBUG - Received 310 chunks, response length: 1409
2025-04-16 18:50:00,952 - ResumeServer - DEBUG - Received 320 chunks, response length: 1469
2025-04-16 18:50:00,960 - ResumeServer - DEBUG - Received 330 chunks, response length: 1514
2025-04-16 18:50:00,974 - ResumeServer - DEBUG - Received 340 chunks, response length: 1547
2025-04-16 18:50:00,982 - ResumeServer - DEBUG - Received 350 chunks, response length: 1600
2025-04-16 18:50:01,005 - ResumeServer - DEBUG - Received 360 chunks, response length: 1649
2025-04-16 18:50:01,013 - ResumeServer - DEBUG - Received 370 chunks, response length: 1702
2025-04-16 18:50:01,024 - ResumeServer - DEBUG - Received 380 chunks, response length: 1763
2025-04-16 18:50:01,035 - ResumeServer - DEBUG - Received 390 chunks, response length: 1799
2025-04-16 18:50:01,053 - ResumeServer - DEBUG - Received 400 chunks, response length: 1866
2025-04-16 18:50:01,071 - ResumeServer - DEBUG - Received 410 chunks, response length: 1895
2025-04-16 18:50:01,079 - ResumeServer - DEBUG - Received 420 chunks, response length: 1941
2025-04-16 18:50:01,096 - ResumeServer - DEBUG - Received 430 chunks, response length: 1974
2025-04-16 18:50:01,120 - ResumeServer - DEBUG - Received 440 chunks, response length: 1999
2025-04-16 18:50:01,122 - ResumeServer - DEBUG - Received 450 chunks, response length: 2047
2025-04-16 18:50:01,129 - ResumeServer - DEBUG - Received 460 chunks, response length: 2102
2025-04-16 18:50:01,148 - ResumeServer - DEBUG - Received 470 chunks, response length: 2125
2025-04-16 18:50:01,162 - ResumeServer - DEBUG - Received 480 chunks, response length: 2175
2025-04-16 18:50:01,176 - ResumeServer - DEBUG - Received 490 chunks, response length: 2229
2025-04-16 18:50:01,187 - ResumeServer - DEBUG - Received 500 chunks, response length: 2272
2025-04-16 18:50:01,195 - ResumeServer - DEBUG - Received 510 chunks, response length: 2329
2025-04-16 18:50:01,222 - ResumeServer - DEBUG - Received 520 chunks, response length: 2358
2025-04-16 18:50:01,227 - ResumeServer - DEBUG - Received 530 chunks, response length: 2390
2025-04-16 18:50:01,236 - ResumeServer - DEBUG - Received 540 chunks, response length: 2457
2025-04-16 18:50:01,248 - ResumeServer - DEBUG - Received 550 chunks, response length: 2492
2025-04-16 18:50:01,274 - ResumeServer - DEBUG - Received 560 chunks, response length: 2517
2025-04-16 18:50:01,304 - ResumeServer - DEBUG - Received 570 chunks, response length: 2565
2025-04-16 18:50:01,310 - ResumeServer - DEBUG - Received 580 chunks, response length: 2596
2025-04-16 18:50:01,332 - ResumeServer - DEBUG - Received 590 chunks, response length: 2640
2025-04-16 18:50:01,351 - ResumeServer - DEBUG - Received 600 chunks, response length: 2698
2025-04-16 18:50:01,355 - ResumeServer - DEBUG - Received 610 chunks, response length: 2735
2025-04-16 18:50:01,374 - ResumeServer - DEBUG - Received 620 chunks, response length: 2763
2025-04-16 18:50:01,378 - ResumeServer - DEBUG - Received 630 chunks, response length: 2802
2025-04-16 18:50:01,395 - ResumeServer - DEBUG - Received 640 chunks, response length: 2823
2025-04-16 18:50:01,408 - ResumeServer - DEBUG - Received 650 chunks, response length: 2856
2025-04-16 18:50:01,420 - ResumeServer - DEBUG - Received 660 chunks, response length: 2880
2025-04-16 18:50:01,437 - ResumeServer - DEBUG - Received 670 chunks, response length: 2915
2025-04-16 18:50:01,464 - ResumeServer - DEBUG - Received 680 chunks, response length: 2948
2025-04-16 18:50:01,475 - ResumeServer - DEBUG - Received 690 chunks, response length: 2979
2025-04-16 18:50:01,484 - ResumeServer - DEBUG - Received 700 chunks, response length: 3025
2025-04-16 18:50:01,488 - ResumeServer - DEBUG - Received 710 chunks, response length: 3051
2025-04-16 18:50:01,506 - ResumeServer - DEBUG - Received 720 chunks, response length: 3083
2025-04-16 18:50:01,520 - ResumeServer - DEBUG - Received 730 chunks, response length: 3111
2025-04-16 18:50:01,534 - ResumeServer - DEBUG - Received 740 chunks, response length: 3149
2025-04-16 18:50:01,546 - ResumeServer - DEBUG - Received 750 chunks, response length: 3173
2025-04-16 18:50:01,569 - ResumeServer - DEBUG - Received 760 chunks, response length: 3206
2025-04-16 18:50:01,578 - ResumeServer - DEBUG - Received 770 chunks, response length: 3257
2025-04-16 18:50:01,616 - ResumeServer - DEBUG - Received 780 chunks, response length: 3280
2025-04-16 18:50:01,621 - ResumeServer - DEBUG - Received 790 chunks, response length: 3306
2025-04-16 18:50:01,625 - ResumeServer - DEBUG - Received 800 chunks, response length: 3354
2025-04-16 18:50:01,648 - ResumeServer - DEBUG - Received 810 chunks, response length: 3391
2025-04-16 18:50:01,659 - ResumeServer - DEBUG - Received 820 chunks, response length: 3444
2025-04-16 18:50:01,670 - ResumeServer - DEBUG - Received 830 chunks, response length: 3511
2025-04-16 18:50:01,678 - ResumeServer - DEBUG - Received 840 chunks, response length: 3539
2025-04-16 18:50:01,688 - ResumeServer - DEBUG - Received 850 chunks, response length: 3577
2025-04-16 18:50:01,710 - ResumeServer - DEBUG - Received 860 chunks, response length: 3647
2025-04-16 18:50:01,720 - ResumeServer - DEBUG - Received 870 chunks, response length: 3692
2025-04-16 18:50:01,743 - ResumeServer - DEBUG - Received 880 chunks, response length: 3724
2025-04-16 18:50:01,776 - ResumeServer - DEBUG - Received 890 chunks, response length: 3770
2025-04-16 18:50:01,817 - ResumeServer - DEBUG - Received 900 chunks, response length: 3829
2025-04-16 18:50:01,852 - ResumeServer - DEBUG - Received 910 chunks, response length: 3875
2025-04-16 18:50:01,866 - ResumeServer - DEBUG - Received 920 chunks, response length: 3904
2025-04-16 18:50:01,892 - ResumeServer - DEBUG - Received 930 chunks, response length: 3923
2025-04-16 18:50:01,944 - ResumeServer - DEBUG - Received 940 chunks, response length: 3983
2025-04-16 18:50:01,962 - ResumeServer - DEBUG - Received 950 chunks, response length: 4004
2025-04-16 18:50:02,002 - ResumeServer - DEBUG - Received 960 chunks, response length: 4052
2025-04-16 18:50:02,021 - ResumeServer - DEBUG - Received 970 chunks, response length: 4076
2025-04-16 18:50:02,046 - ResumeServer - DEBUG - Received 980 chunks, response length: 4104
2025-04-16 18:50:02,086 - ResumeServer - DEBUG - Received 990 chunks, response length: 4132
2025-04-16 18:50:02,120 - ResumeServer - DEBUG - Received 1000 chunks, response length: 4184
2025-04-16 18:50:02,144 - ResumeServer - DEBUG - Received 1010 chunks, response length: 4206
2025-04-16 18:50:02,177 - ResumeServer - DEBUG - Received 1020 chunks, response length: 4242
2025-04-16 18:50:02,236 - ResumeServer - DEBUG - Received 1030 chunks, response length: 4273
2025-04-16 18:50:02,250 - ResumeServer - DEBUG - Received 1040 chunks, response length: 4301
2025-04-16 18:50:02,284 - ResumeServer - DEBUG - Received 1050 chunks, response length: 4331
2025-04-16 18:50:02,310 - ResumeServer - DEBUG - Received 1060 chunks, response length: 4369
2025-04-16 18:50:02,359 - ResumeServer - DEBUG - Received 1070 chunks, response length: 4404
2025-04-16 18:50:02,423 - ResumeServer - DEBUG - Received 1080 chunks, response length: 4450
2025-04-16 18:50:02,441 - ResumeServer - DEBUG - Received 1090 chunks, response length: 4484
2025-04-16 18:50:02,502 - ResumeServer - DEBUG - Received 1100 chunks, response length: 4535
2025-04-16 18:50:04,669 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 18:50:04,670 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 18:50:04,670 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 18:50:04,671 - ResumeServer - INFO - Response collection complete. Total 1106 chunks, final length: 4544
2025-04-16 18:50:04,671 - ResumeServer - INFO - Response preview: <h2>Results-Driven Machine Learning Engineer</h2>
<p>Highly motivated and experienced Machine Learni...
2025-04-16 18:50:04,675 - ResumeServer - INFO - Building PDF document...
2025-04-16 18:50:04,688 - ResumeServer - INFO - PDF generation successful, size: 6225 bytes
2025-04-16 18:50:04,688 - ResumeServer - INFO - Resume generated successfully. PDF size: 6225 bytes
2025-04-16 18:50:04,689 - ResumeServer - DEBUG - Converting response to JSON
2025-04-16 18:50:04,690 - ResumeServer - DEBUG - Response headers set: application/json
2025-04-16 18:50:04,691 - ResumeServer - INFO - Successfully sent PDF response
2025-04-16 18:50:04,694 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpkf1ifyz6
2025-04-16 18:50:05,013 - ResumeServer - INFO - GET request for /history
2025-04-16 18:50:05,014 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:50:06,020 - ResumeServer - INFO - GET request for /history
2025-04-16 18:50:06,020 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:50:12,790 - ResumeServer - INFO - GET request for /history
2025-04-16 18:50:12,792 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:50:16,266 - ResumeServer - INFO - GET request for /history
2025-04-16 18:50:16,266 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:50:16,993 - ResumeServer - INFO - GET request for /history
2025-04-16 18:50:16,993 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:50:17,261 - ResumeServer - INFO - GET request for /history
2025-04-16 18:50:17,262 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:50:17,308 - ResumeServer - INFO - GET request for /history
2025-04-16 18:50:17,309 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:50:17,577 - ResumeServer - INFO - GET request for /history
2025-04-16 18:50:17,578 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:50:17,624 - ResumeServer - INFO - GET request for /history
2025-04-16 18:50:17,625 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:50:17,889 - ResumeServer - INFO - GET request for /history
2025-04-16 18:50:17,890 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:50:17,937 - ResumeServer - INFO - GET request for /history
2025-04-16 18:50:17,938 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:50:18,202 - ResumeServer - INFO - GET request for /history
2025-04-16 18:50:18,203 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:50:18,248 - ResumeServer - INFO - GET request for /history
2025-04-16 18:50:18,249 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:50:18,515 - ResumeServer - INFO - GET request for /history
2025-04-16 18:50:18,516 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:50:18,553 - ResumeServer - INFO - GET request for /history
2025-04-16 18:50:18,556 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:50:18,825 - ResumeServer - INFO - GET request for /history
2025-04-16 18:50:18,827 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:50:18,869 - ResumeServer - INFO - GET request for /history
2025-04-16 18:50:18,871 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:50:19,136 - ResumeServer - INFO - GET request for /history
2025-04-16 18:50:19,138 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 18:50:19,244 - ResumeServer - INFO - GET request for /history
2025-04-16 18:50:19,246 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 19:14:32,733 - ResumeServer - INFO - GET request for /
2025-04-16 19:14:32,734 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 19:14:32,736 - ResumeServer - INFO - Served index.html successfully
2025-04-16 19:14:32,748 - ResumeServer - INFO - GET request for /history
2025-04-16 19:14:32,748 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 19:14:53,187 - ResumeServer - INFO - POST request to /generate (Content-Length: 19385)
2025-04-16 19:14:53,188 - ResumeServer - INFO - Processing /generate request
2025-04-16 19:14:53,189 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpfttgw6w7
2025-04-16 19:14:53,190 - ResumeServer - DEBUG - Parsing form data
2025-04-16 19:14:53,195 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 19:14:53,196 - ResumeServer - INFO - Got files: resume=resume.pdf, job_desc=tailored_resume_2025-04-16 (2).pdf
2025-04-16 19:14:53,197 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 19:14:53,201 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 19:14:53,204 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmpfttgw6w7\template.txt
2025-04-16 19:14:53,205 - ResumeServer - INFO - Generating resume...
2025-04-16 19:14:53,209 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 19:14:53,212 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 19:14:53,214 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 19:14:55,215 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 19:14:55,215 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 19:14:55,217 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 19:14:57,217 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 19:14:57,218 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 19:14:57,219 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 19:14:57,220 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    )
      
  File "D:\resume\resumeBuilder.py", line 444, in generate_resume
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte

2025-04-16 19:14:57,223 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0x93 in position 10: invalid start byte
2025-04-16 19:14:57,225 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpfttgw6w7
2025-04-16 19:41:48,431 - ResumeServer - INFO - GET request for /
2025-04-16 19:41:48,432 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 19:41:48,432 - ResumeServer - INFO - Served index.html successfully
2025-04-16 19:41:48,446 - ResumeServer - INFO - GET request for /history
2025-04-16 19:41:48,447 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 19:42:12,888 - ResumeServer - INFO - POST request to /generate (Content-Length: 13056)
2025-04-16 19:42:12,889 - ResumeServer - INFO - Processing /generate request
2025-04-16 19:42:12,892 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp82d8koek
2025-04-16 19:42:12,894 - ResumeServer - DEBUG - Parsing form data
2025-04-16 19:42:12,905 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 19:42:12,906 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=jobDesc.txt
2025-04-16 19:42:12,907 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 19:42:12,913 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 19:42:12,919 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmp82d8koek\template.txt
2025-04-16 19:42:12,921 - ResumeServer - INFO - Generating resume...
2025-04-16 19:42:12,927 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 19:42:12,933 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 19:42:12,940 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 19:42:12,946 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    environ = {
                
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 19:42:12,950 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 19:42:14,952 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 19:42:14,952 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 19:42:14,953 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 19:42:14,954 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    environ = {
                
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 19:42:14,956 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 19:42:16,957 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 19:42:16,958 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 19:42:16,959 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 19:42:16,960 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    environ = {
                
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 19:42:16,961 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 19:42:16,962 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    stream=True
                
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    environ = {
                
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 19:42:16,964 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 19:42:16,965 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp82d8koek
2025-04-16 19:42:22,241 - ResumeServer - INFO - POST request to /generate (Content-Length: 5648)
2025-04-16 19:42:22,242 - ResumeServer - INFO - Processing /generate request
2025-04-16 19:42:22,243 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpl_v8xg92
2025-04-16 19:42:22,244 - ResumeServer - DEBUG - Parsing form data
2025-04-16 19:42:22,246 - ResumeServer - DEBUG - Form fields: ['job_desc', 'resume']
2025-04-16 19:42:22,247 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=jobDesc.txt
2025-04-16 19:42:22,248 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 19:42:22,250 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 19:42:22,250 - ResumeServer - INFO - Generating resume...
2025-04-16 19:42:22,253 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 19:42:22,256 - ResumeServer - DEBUG - Job description content length: 1422 chars
2025-04-16 19:42:22,256 - ResumeServer - INFO - Initializing Groq client...
2025-04-16 19:42:22,953 - ResumeServer - INFO - Preparing messages for AI request...
2025-04-16 19:42:22,954 - ResumeServer - DEBUG - Using standard prompt (no template)
2025-04-16 19:42:22,954 - ResumeServer - INFO - Sending request to Groq API...
2025-04-16 19:42:22,957 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Respond with 'test ok'"}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 10, 'stream': False}}
2025-04-16 19:42:22,958 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 19:42:22,959 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-04-16 19:42:23,150 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC15C4320>
2025-04-16 19:42:23,150 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EFC15B4950> server_hostname='api.groq.com' timeout=5.0
2025-04-16 19:42:23,211 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC15AFE60>
2025-04-16 19:42:23,212 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 19:42:23,213 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 19:42:23,213 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 19:42:23,214 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 19:42:23,215 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 19:42:23,385 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 14:12:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'931446fd1aac0690-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'999'), (b'X-Ratelimit-Remaining-Tokens', b'11990'), (b'X-Ratelimit-Reset-Requests', b'1m26.4s'), (b'X-Ratelimit-Reset-Tokens', b'50ms'), (b'X-Request-Id', b'req_01jrzf36jdfkk8zyr9x6ghmndz'), (b'Set-Cookie', b'__cf_bm=6Z8R4f0k0rHIK38RdykEdmr0WaANXKAlgXep7K6Jkew-1744812743-1.0.1.1-MeuM3EZEO52HsnweowZkTzkLWLOuEH3E58Y50nhs1i0goMIQolPPx.s0mVNXiviej_LTx4Bm5TaaVaZkJTlep5AVytOw2vaEdCYa97PhmFM; path=/; expires=Wed, 16-Apr-25 14:42:23 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 19:42:23,388 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 19:42:23,389 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 19:42:23,390 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 19:42:23,390 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 19:42:23,391 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 19:42:23,392 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 14:12:23 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '931446fd1aac0690-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '999', 'x-ratelimit-remaining-tokens': '11990', 'x-ratelimit-reset-requests': '1m26.4s', 'x-ratelimit-reset-tokens': '50ms', 'x-request-id': 'req_01jrzf36jdfkk8zyr9x6ghmndz', 'set-cookie': '__cf_bm=6Z8R4f0k0rHIK38RdykEdmr0WaANXKAlgXep7K6Jkew-1744812743-1.0.1.1-MeuM3EZEO52HsnweowZkTzkLWLOuEH3E58Y50nhs1i0goMIQolPPx.s0mVNXiviej_LTx4Bm5TaaVaZkJTlep5AVytOw2vaEdCYa97PhmFM; path=/; expires=Wed, 16-Apr-25 14:42:23 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 19:42:23,396 - ResumeServer - INFO - API test successful: test ok
2025-04-16 19:42:23,397 - ResumeServer - INFO - Creating streaming completion...
2025-04-16 19:42:23,399 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a resume assistant. Format your response with HTML tags for styling. Use <strong> for bold, <h2> for section headers, <ul> and <li> for lists. Provide ONLY the resume content, no analysis or insights. Start directly with the resume content.'}, {'role': 'user', 'content': "Create a tailored resume based on this resume and job description. Format the response with HTML tags. Provide ONLY the resume content, no analysis or insights.\n\nResume:\n\nResults-driven Machine Learning Engineer with 4+ years of experience developing and deploying AI models for diverse applications, including computer vision, NLP, and predictive analytics. Skilled in Python, TensorFlow, and cloud platforms like GCP. Adept at translating complex data into actionable insights and thriving in collaborative, fast-paced environments.\n\nProfessional Experience\n\nMachine Learning Engineer\n\nNexGen Technologies, Austin, TX\n\nAugust 2021 – Present\n\nBuilt convolutional neural networks (CNNs) with TensorFlow for image classification, achieving 92% accuracy on a custom dataset for retail product recognition.\nDesigned and deployed NLP models using BERT and Hugging Face for automated customer support, reducing response times by 40%.\nImplemented MLOps pipelines with Kubeflow and GCP, automating model retraining and monitoring for production systems.\nPreprocessed terabyte-scale datasets with Apache Spark, optimizing data pipelines for faster model training.\nMentored junior engineers on best practices for model development and version control with Git.\nData Scientist\n\nInsight Analytics, San Francisco, CA (Remote)\n\nJune 2020 – July 2021\n\nDeveloped time-series forecasting models with PyTorch to predict inventory demand, improving supply chain efficiency by 20%.\nConducted exploratory data analysis with pandas and SQL, uncovering trends that informed marketing strategies.\nCreated interactive dashboards with Plotly and Tableau to visualize model outputs for executive stakeholders.\nCollaborated with software engineers to integrate ML models into web applications using Flask APIs.\nResearch Intern, AI Lab\n\nStanford University, Stanford, CA\n\nJanuary 2019 – May 2020\n\nContributed to research on reinforcement learning algorithms, co-authoring a paper presented at NeurIPS 2020.\nBuilt simulation environments with OpenAI Gym to test agent performance in dynamic scenarios.\nOptimized model training workflows, reducing compute costs by 15% through efficient resource allocation.\nEducation\n\nMaster of Science in Artificial Intelligence\n\nCarnegie Mellon University, Pittsburgh, PA\n\nGraduated: May 2020\n\nFocus: Deep Learning and Reinforcement Learning\nCapstone Project: “Scalable RL Models for Autonomous Navigation”\nBachelor of Science in Computer Science\n\nUniversity of Texas at Austin, Austin, TX\n\nGraduated: May 2018\n\nMinor in Applied Mathematics\nSkills\n\nProgramming: Python, C++, SQL, Bash\nML Frameworks: TensorFlow, PyTorch, scikit-learn, Hugging Face, OpenCV\nCloud Platforms: Google Cloud Platform (AI Platform, BigQuery), AWS, Azure\nTools: Docker, Jenkins, MLflow, Git, Jupyter, Tableau\nData Processing: pandas, NumPy, Spark, Dask\nDomains: Computer Vision, NLP, Reinforcement Learning, Time-Series Analysis\nProjects\n\nAutonomous Drone Navigation (GitHub: github.com/alexcarter/drone-ai)\nDeveloped a reinforcement learning model with PyTorch to train drones for obstacle avoidance, tested in simulated environments.\nText Summarization Tool\nBuilt an NLP pipeline with Hugging Face transformers to generate concise summaries of news articles, deployed as a web app with Streamlit.\nFacial Recognition System\nCreated a real-time face detection model using OpenCV and TensorFlow, achieving 95% accuracy on public datasets.\nCertifications\n\nGoogle Cloud Professional Machine Learning Engineer (2023)\nCoursera: Deep Learning Specialization by Andrew Ng (2020)\nPublications & Talks\n\nCo-author, “Advances in Scalable Reinforcement Learning for Robotics,” NeurIPS 2020.\nGuest Speaker, “MLOps for Beginners,” Austin AI Meetup, March 2023.\nAdditional Information\n\nActive contributor to PyTorch (3 pull requests merged).\nVolunteer mentor at Code2AI, teaching high school students ML basics.\nProficient in French; conversational in Japanese.\n\nJob Description:\n\nSoftware Engineer - Full Stack Developer\n\nCompany: Tech Innovations Inc.\nLocation: Remote\nType: Full-time\n\nJob Description:\nWe are seeking a skilled Full Stack Developer to join our dynamic team. The ideal candidate will be responsible for developing and maintaining web applications using modern technologies.\n\nResponsibilities:\n- Design and implement scalable web applications\n- Develop front-end interfaces using React.js\n- Create and maintain back-end services using Node.js and Python\n- Work with databases (SQL and NoSQL)\n- Implement RESTful APIs\n- Write clean, maintainable code\n- Collaborate with cross-functional teams\n- Participate in code reviews and technical discussions\n\nRequirements:\n- Bachelor's degree in Computer Science or related field\n- 3+ years of experience in full-stack development\n- Strong proficiency in JavaScript, Python, and SQL\n- Experience with React.js and Node.js\n- Knowledge of cloud platforms (AWS, Azure, or GCP)\n- Familiarity with version control systems (Git)\n- Excellent problem-solving skills\n- Strong communication and teamwork abilities\n\nPreferred Qualifications:\n- Experience with containerization (Docker)\n- Knowledge of CI/CD pipelines\n- Understanding of microservices architecture\n- Contributions to open-source projects\n\nBenefits:\n- Competitive salary\n- Health insurance\n- 401(k) matching\n- Flexible work hours\n- Professional development opportunities\n- Remote work options "}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2048, 'stream': True, 'temperature': 0.1, 'top_p': 1}}
2025-04-16 19:42:23,412 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 19:42:23,413 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 19:42:23,413 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 19:42:23,414 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 19:42:23,415 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 19:42:23,415 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 19:42:23,581 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 14:12:23 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'931446fe7b8f0690-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'no-cache'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'998'), (b'X-Ratelimit-Remaining-Tokens', b'10567'), (b'X-Ratelimit-Reset-Requests', b'2m52.583999999s'), (b'X-Ratelimit-Reset-Tokens', b'7.161s'), (b'X-Request-Id', b'req_01jrzf36s9fkk9jwt1n0cw4e5z'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 19:42:23,583 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 19:42:23,583 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 14:12:23 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '931446fe7b8f0690-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'no-cache', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '998', 'x-ratelimit-remaining-tokens': '10567', 'x-ratelimit-reset-requests': '2m52.583999999s', 'x-ratelimit-reset-tokens': '7.161s', 'x-request-id': 'req_01jrzf36s9fkk9jwt1n0cw4e5z', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 19:42:23,584 - ResumeServer - INFO - Collecting response chunks...
2025-04-16 19:42:23,585 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 19:42:23,726 - ResumeServer - DEBUG - Received 10 chunks, response length: 34
2025-04-16 19:42:23,748 - ResumeServer - DEBUG - Received 20 chunks, response length: 78
2025-04-16 19:42:23,753 - ResumeServer - DEBUG - Received 30 chunks, response length: 127
2025-04-16 19:42:23,787 - ResumeServer - DEBUG - Received 40 chunks, response length: 209
2025-04-16 19:42:23,796 - ResumeServer - DEBUG - Received 50 chunks, response length: 247
2025-04-16 19:42:23,831 - ResumeServer - DEBUG - Received 60 chunks, response length: 287
2025-04-16 19:42:23,856 - ResumeServer - DEBUG - Received 70 chunks, response length: 341
2025-04-16 19:42:23,883 - ResumeServer - DEBUG - Received 80 chunks, response length: 386
2025-04-16 19:42:23,893 - ResumeServer - DEBUG - Received 90 chunks, response length: 438
2025-04-16 19:42:23,912 - ResumeServer - DEBUG - Received 100 chunks, response length: 477
2025-04-16 19:42:23,927 - ResumeServer - DEBUG - Received 110 chunks, response length: 520
2025-04-16 19:42:23,972 - ResumeServer - DEBUG - Received 120 chunks, response length: 571
2025-04-16 19:42:23,976 - ResumeServer - DEBUG - Received 130 chunks, response length: 626
2025-04-16 19:42:24,005 - ResumeServer - DEBUG - Received 140 chunks, response length: 683
2025-04-16 19:42:24,022 - ResumeServer - DEBUG - Received 150 chunks, response length: 742
2025-04-16 19:42:24,063 - ResumeServer - DEBUG - Received 160 chunks, response length: 799
2025-04-16 19:42:24,096 - ResumeServer - DEBUG - Received 170 chunks, response length: 843
2025-04-16 19:42:24,154 - ResumeServer - DEBUG - Received 180 chunks, response length: 910
2025-04-16 19:42:24,171 - ResumeServer - DEBUG - Received 190 chunks, response length: 982
2025-04-16 19:42:24,182 - ResumeServer - DEBUG - Received 200 chunks, response length: 1030
2025-04-16 19:42:24,203 - ResumeServer - DEBUG - Received 210 chunks, response length: 1098
2025-04-16 19:42:24,235 - ResumeServer - DEBUG - Received 220 chunks, response length: 1159
2025-04-16 19:42:24,250 - ResumeServer - DEBUG - Received 230 chunks, response length: 1208
2025-04-16 19:42:24,268 - ResumeServer - DEBUG - Received 240 chunks, response length: 1238
2025-04-16 19:42:24,291 - ResumeServer - DEBUG - Received 250 chunks, response length: 1285
2025-04-16 19:42:24,314 - ResumeServer - DEBUG - Received 260 chunks, response length: 1337
2025-04-16 19:42:24,325 - ResumeServer - DEBUG - Received 270 chunks, response length: 1392
2025-04-16 19:42:24,345 - ResumeServer - DEBUG - Received 280 chunks, response length: 1448
2025-04-16 19:42:24,371 - ResumeServer - DEBUG - Received 290 chunks, response length: 1504
2025-04-16 19:42:24,374 - ResumeServer - DEBUG - Received 300 chunks, response length: 1560
2025-04-16 19:42:24,380 - ResumeServer - DEBUG - Received 310 chunks, response length: 1625
2025-04-16 19:42:24,397 - ResumeServer - DEBUG - Received 320 chunks, response length: 1661
2025-04-16 19:42:24,410 - ResumeServer - DEBUG - Received 330 chunks, response length: 1714
2025-04-16 19:42:24,428 - ResumeServer - DEBUG - Received 340 chunks, response length: 1763
2025-04-16 19:42:24,441 - ResumeServer - DEBUG - Received 350 chunks, response length: 1795
2025-04-16 19:42:24,489 - ResumeServer - DEBUG - Received 360 chunks, response length: 1842
2025-04-16 19:42:24,491 - ResumeServer - DEBUG - Received 370 chunks, response length: 1897
2025-04-16 19:42:24,498 - ResumeServer - DEBUG - Received 380 chunks, response length: 1952
2025-04-16 19:42:24,505 - ResumeServer - DEBUG - Received 390 chunks, response length: 1987
2025-04-16 19:42:24,516 - ResumeServer - DEBUG - Received 400 chunks, response length: 2026
2025-04-16 19:42:24,544 - ResumeServer - DEBUG - Received 410 chunks, response length: 2055
2025-04-16 19:42:24,567 - ResumeServer - DEBUG - Received 420 chunks, response length: 2091
2025-04-16 19:42:24,592 - ResumeServer - DEBUG - Received 430 chunks, response length: 2123
2025-04-16 19:42:24,608 - ResumeServer - DEBUG - Received 440 chunks, response length: 2157
2025-04-16 19:42:24,622 - ResumeServer - DEBUG - Received 450 chunks, response length: 2197
2025-04-16 19:42:24,635 - ResumeServer - DEBUG - Received 460 chunks, response length: 2241
2025-04-16 19:42:24,645 - ResumeServer - DEBUG - Received 470 chunks, response length: 2274
2025-04-16 19:42:24,665 - ResumeServer - DEBUG - Received 480 chunks, response length: 2304
2025-04-16 19:42:24,685 - ResumeServer - DEBUG - Received 490 chunks, response length: 2338
2025-04-16 19:42:24,690 - ResumeServer - DEBUG - Received 500 chunks, response length: 2370
2025-04-16 19:42:24,699 - ResumeServer - DEBUG - Received 510 chunks, response length: 2412
2025-04-16 19:42:24,726 - ResumeServer - DEBUG - Received 520 chunks, response length: 2446
2025-04-16 19:42:24,740 - ResumeServer - DEBUG - Received 530 chunks, response length: 2488
2025-04-16 19:42:24,758 - ResumeServer - DEBUG - Received 540 chunks, response length: 2521
2025-04-16 19:42:24,777 - ResumeServer - DEBUG - Received 550 chunks, response length: 2551
2025-04-16 19:42:24,788 - ResumeServer - DEBUG - Received 560 chunks, response length: 2609
2025-04-16 19:42:24,796 - ResumeServer - DEBUG - Received 570 chunks, response length: 2668
2025-04-16 19:42:24,815 - ResumeServer - DEBUG - Received 580 chunks, response length: 2702
2025-04-16 19:42:24,835 - ResumeServer - DEBUG - Received 590 chunks, response length: 2736
2025-04-16 19:42:24,841 - ResumeServer - DEBUG - Received 600 chunks, response length: 2800
2025-04-16 19:42:24,854 - ResumeServer - DEBUG - Received 610 chunks, response length: 2835
2025-04-16 19:42:24,869 - ResumeServer - DEBUG - Received 620 chunks, response length: 2868
2025-04-16 19:42:24,881 - ResumeServer - DEBUG - Received 630 chunks, response length: 2912
2025-04-16 19:42:24,892 - ResumeServer - DEBUG - Received 640 chunks, response length: 2971
2025-04-16 19:42:24,914 - ResumeServer - DEBUG - Received 650 chunks, response length: 2999
2025-04-16 19:42:24,936 - ResumeServer - DEBUG - Received 660 chunks, response length: 3038
2025-04-16 19:42:24,944 - ResumeServer - DEBUG - Received 670 chunks, response length: 3097
2025-04-16 19:42:24,958 - ResumeServer - DEBUG - Received 680 chunks, response length: 3128
2025-04-16 19:42:25,001 - ResumeServer - DEBUG - Received 690 chunks, response length: 3167
2025-04-16 19:42:25,006 - ResumeServer - DEBUG - Received 700 chunks, response length: 3196
2025-04-16 19:42:25,014 - ResumeServer - DEBUG - Received 710 chunks, response length: 3230
2025-04-16 19:42:25,030 - ResumeServer - DEBUG - Received 720 chunks, response length: 3277
2025-04-16 19:42:25,034 - ResumeServer - DEBUG - Received 730 chunks, response length: 3303
2025-04-16 19:42:25,061 - ResumeServer - DEBUG - Received 740 chunks, response length: 3345
2025-04-16 19:42:25,093 - ResumeServer - DEBUG - Received 750 chunks, response length: 3380
2025-04-16 19:42:25,098 - ResumeServer - DEBUG - Received 760 chunks, response length: 3416
2025-04-16 19:42:25,104 - ResumeServer - DEBUG - Received 770 chunks, response length: 3463
2025-04-16 19:42:25,112 - ResumeServer - DEBUG - Received 780 chunks, response length: 3512
2025-04-16 19:42:25,122 - ResumeServer - DEBUG - Received 790 chunks, response length: 3554
2025-04-16 19:42:26,695 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 19:42:26,696 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 19:42:26,696 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 19:42:26,697 - ResumeServer - INFO - Response collection complete. Total 792 chunks, final length: 3563
2025-04-16 19:42:26,697 - ResumeServer - INFO - Response preview: <h2>Full Stack Developer Resume</h2>

<strong>Summary:</strong>
Results-driven Full Stack Developer ...
2025-04-16 19:42:26,704 - ResumeServer - INFO - Building PDF document...
2025-04-16 19:42:26,726 - ResumeServer - INFO - PDF generation successful, size: 5878 bytes
2025-04-16 19:42:26,726 - ResumeServer - INFO - Resume generated successfully. PDF size: 5878 bytes
2025-04-16 19:42:26,727 - ResumeServer - DEBUG - Converting response to JSON
2025-04-16 19:42:26,728 - ResumeServer - DEBUG - Response headers set: application/json
2025-04-16 19:42:26,729 - ResumeServer - INFO - Successfully sent PDF response
2025-04-16 19:42:26,729 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpl_v8xg92
2025-04-16 19:42:27,770 - ResumeServer - INFO - GET request for /download/undefined
2025-04-16 19:42:27,771 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 19:42:33,090 - ResumeServer - INFO - GET request for /download/undefined
2025-04-16 19:42:33,091 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 19:45:01,005 - ResumeServer - INFO - GET request for /
2025-04-16 19:45:01,007 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 19:45:01,008 - ResumeServer - INFO - Served index.html successfully
2025-04-16 19:45:01,035 - ResumeServer - INFO - GET request for /history
2025-04-16 19:45:01,036 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 19:45:20,484 - ResumeServer - INFO - POST request to /generate (Content-Length: 14320)
2025-04-16 19:45:20,485 - ResumeServer - INFO - Processing /generate request
2025-04-16 19:45:20,486 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpkinwhpcn
2025-04-16 19:45:20,488 - ResumeServer - DEBUG - Parsing form data
2025-04-16 19:45:20,494 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 19:45:20,495 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=posting.txt
2025-04-16 19:45:20,496 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 19:45:20,501 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 19:45:20,503 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmpkinwhpcn\template.txt
2025-04-16 19:45:20,504 - ResumeServer - INFO - Generating resume...
2025-04-16 19:45:20,507 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 19:45:20,511 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 19:45:20,514 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 19:45:20,518 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    with open('resume_history.json', 'r') as f:
                   ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 19:45:20,521 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 19:45:22,524 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 19:45:22,525 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 19:45:22,526 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 19:45:22,528 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    with open('resume_history.json', 'r') as f:
                   ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 19:45:22,531 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 19:45:24,532 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 19:45:24,533 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 19:45:24,533 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 19:45:24,535 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    with open('resume_history.json', 'r') as f:
                   ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 19:45:24,536 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 19:45:24,539 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    logger.info("Successfully received non-streaming response")
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    with open('resume_history.json', 'r') as f:
                   ^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-04-16 19:45:24,541 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-04-16 19:45:24,543 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpkinwhpcn
2025-04-16 19:45:29,873 - ResumeServer - INFO - POST request to /generate (Content-Length: 6912)
2025-04-16 19:45:29,874 - ResumeServer - INFO - Processing /generate request
2025-04-16 19:45:29,875 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmprkwhruxw
2025-04-16 19:45:29,875 - ResumeServer - DEBUG - Parsing form data
2025-04-16 19:45:29,877 - ResumeServer - DEBUG - Form fields: ['job_desc', 'resume']
2025-04-16 19:45:29,877 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=posting.txt
2025-04-16 19:45:29,878 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 19:45:29,879 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 19:45:29,879 - ResumeServer - INFO - Generating resume...
2025-04-16 19:45:29,881 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 19:45:29,884 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 19:45:29,884 - ResumeServer - INFO - Initializing Groq client...
2025-04-16 19:45:30,514 - ResumeServer - INFO - Preparing messages for AI request...
2025-04-16 19:45:30,515 - ResumeServer - DEBUG - Using standard prompt (no template)
2025-04-16 19:45:30,516 - ResumeServer - INFO - Sending request to Groq API...
2025-04-16 19:45:30,517 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Respond with 'test ok'"}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 10, 'stream': False}}
2025-04-16 19:45:30,519 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 19:45:30,519 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-04-16 19:45:30,574 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC15D0200>
2025-04-16 19:45:30,574 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EFC15B5AD0> server_hostname='api.groq.com' timeout=5.0
2025-04-16 19:45:30,639 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC15C7EF0>
2025-04-16 19:45:30,640 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 19:45:30,642 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 19:45:30,643 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 19:45:30,644 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 19:45:30,645 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 19:45:30,813 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 14:15:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'93144b90ac8b06a4-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'999'), (b'X-Ratelimit-Remaining-Tokens', b'11990'), (b'X-Ratelimit-Reset-Requests', b'1m26.4s'), (b'X-Ratelimit-Reset-Tokens', b'50ms'), (b'X-Request-Id', b'req_01jrzf8xm9frwst4sfccgkj42w'), (b'Set-Cookie', b'__cf_bm=ma_X2cmOBuZYDjPNnaJ3N544bx7vi3uDFHSPZG220gU-1744812930-1.0.1.1-uijv0u0_2qtVL01TLpTjcQwQqoI.JGApMkQaxgwrxeBAp5.VWGaZLQ5rQj226X8BQkWjbh7ROKZkLxJH1N_0kDweuckJLPzwscZqNRIL5NI; path=/; expires=Wed, 16-Apr-25 14:45:30 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 19:45:30,816 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 19:45:30,817 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 19:45:30,817 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 19:45:30,818 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 19:45:30,818 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 19:45:30,819 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 14:15:30 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '93144b90ac8b06a4-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '999', 'x-ratelimit-remaining-tokens': '11990', 'x-ratelimit-reset-requests': '1m26.4s', 'x-ratelimit-reset-tokens': '50ms', 'x-request-id': 'req_01jrzf8xm9frwst4sfccgkj42w', 'set-cookie': '__cf_bm=ma_X2cmOBuZYDjPNnaJ3N544bx7vi3uDFHSPZG220gU-1744812930-1.0.1.1-uijv0u0_2qtVL01TLpTjcQwQqoI.JGApMkQaxgwrxeBAp5.VWGaZLQ5rQj226X8BQkWjbh7ROKZkLxJH1N_0kDweuckJLPzwscZqNRIL5NI; path=/; expires=Wed, 16-Apr-25 14:45:30 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 19:45:30,821 - ResumeServer - INFO - API test successful: test ok
2025-04-16 19:45:30,822 - ResumeServer - INFO - Creating streaming completion...
2025-04-16 19:45:30,825 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a resume assistant. Format your response with HTML tags for styling. Use <strong> for bold, <h2> for section headers, <ul> and <li> for lists. Provide ONLY the resume content, no analysis or insights. Start directly with the resume content.'}, {'role': 'user', 'content': 'Create a tailored resume based on this resume and job description. Format the response with HTML tags. Provide ONLY the resume content, no analysis or insights.\n\nResume:\n\nResults-driven Machine Learning Engineer with 4+ years of experience developing and deploying AI models for diverse applications, including computer vision, NLP, and predictive analytics. Skilled in Python, TensorFlow, and cloud platforms like GCP. Adept at translating complex data into actionable insights and thriving in collaborative, fast-paced environments.\n\nProfessional Experience\n\nMachine Learning Engineer\n\nNexGen Technologies, Austin, TX\n\nAugust 2021 – Present\n\nBuilt convolutional neural networks (CNNs) with TensorFlow for image classification, achieving 92% accuracy on a custom dataset for retail product recognition.\nDesigned and deployed NLP models using BERT and Hugging Face for automated customer support, reducing response times by 40%.\nImplemented MLOps pipelines with Kubeflow and GCP, automating model retraining and monitoring for production systems.\nPreprocessed terabyte-scale datasets with Apache Spark, optimizing data pipelines for faster model training.\nMentored junior engineers on best practices for model development and version control with Git.\nData Scientist\n\nInsight Analytics, San Francisco, CA (Remote)\n\nJune 2020 – July 2021\n\nDeveloped time-series forecasting models with PyTorch to predict inventory demand, improving supply chain efficiency by 20%.\nConducted exploratory data analysis with pandas and SQL, uncovering trends that informed marketing strategies.\nCreated interactive dashboards with Plotly and Tableau to visualize model outputs for executive stakeholders.\nCollaborated with software engineers to integrate ML models into web applications using Flask APIs.\nResearch Intern, AI Lab\n\nStanford University, Stanford, CA\n\nJanuary 2019 – May 2020\n\nContributed to research on reinforcement learning algorithms, co-authoring a paper presented at NeurIPS 2020.\nBuilt simulation environments with OpenAI Gym to test agent performance in dynamic scenarios.\nOptimized model training workflows, reducing compute costs by 15% through efficient resource allocation.\nEducation\n\nMaster of Science in Artificial Intelligence\n\nCarnegie Mellon University, Pittsburgh, PA\n\nGraduated: May 2020\n\nFocus: Deep Learning and Reinforcement Learning\nCapstone Project: “Scalable RL Models for Autonomous Navigation”\nBachelor of Science in Computer Science\n\nUniversity of Texas at Austin, Austin, TX\n\nGraduated: May 2018\n\nMinor in Applied Mathematics\nSkills\n\nProgramming: Python, C++, SQL, Bash\nML Frameworks: TensorFlow, PyTorch, scikit-learn, Hugging Face, OpenCV\nCloud Platforms: Google Cloud Platform (AI Platform, BigQuery), AWS, Azure\nTools: Docker, Jenkins, MLflow, Git, Jupyter, Tableau\nData Processing: pandas, NumPy, Spark, Dask\nDomains: Computer Vision, NLP, Reinforcement Learning, Time-Series Analysis\nProjects\n\nAutonomous Drone Navigation (GitHub: github.com/alexcarter/drone-ai)\nDeveloped a reinforcement learning model with PyTorch to train drones for obstacle avoidance, tested in simulated environments.\nText Summarization Tool\nBuilt an NLP pipeline with Hugging Face transformers to generate concise summaries of news articles, deployed as a web app with Streamlit.\nFacial Recognition System\nCreated a real-time face detection model using OpenCV and TensorFlow, achieving 95% accuracy on public datasets.\nCertifications\n\nGoogle Cloud Professional Machine Learning Engineer (2023)\nCoursera: Deep Learning Specialization by Andrew Ng (2020)\nPublications & Talks\n\nCo-author, “Advances in Scalable Reinforcement Learning for Robotics,” NeurIPS 2020.\nGuest Speaker, “MLOps for Beginners,” Austin AI Meetup, March 2023.\nAdditional Information\n\nActive contributor to PyTorch (3 pull requests merged).\nVolunteer mentor at Code2AI, teaching high school students ML basics.\nProficient in French; conversational in Japanese.\n\nJob Description:\n\nJob Title: Machine Learning Engineer\n\nCompany: InnovateAI Solutions\n\nLocation: Remote (US-based preferred)\n\nPosted: April 15, 2025\n\nEmployment Type: Full-Time\n\nAbout InnovateAI Solutions:\n\nInnovateAI Solutions is a fast-growing tech company specializing in cutting-edge AI-driven products for healthcare and finance. Our mission is to empower businesses with intelligent solutions that transform industries.\n\nJob Description:\n\nWe are seeking a talented Machine Learning Engineer to join our AI Development team. You will design, develop, and deploy machine learning models to solve complex problems in predictive analytics and natural language processing. This role offers the opportunity to work on impactful projects with a collaborative, innovative team.\n\nKey Responsibilities:\n\nDevelop and optimize machine learning models for tasks such as classification, regression, and NLP.\nCollaborate with data scientists and software engineers to integrate models into production systems.\nConduct experiments to evaluate model performance and iterate on improvements.\nPreprocess and analyze large datasets to extract meaningful insights.\nStay updated on the latest AI/ML research and apply relevant advancements to projects.\nDocument processes and communicate findings to technical and non-technical stakeholders.\nQualifications:\n\nBachelor’s or Master’s degree in Computer Science, Data Science, or a related field.\n3+ years of experience building and deploying machine learning models.\nProficiency in Python and libraries such as TensorFlow, PyTorch, or scikit-learn.\nExperience with cloud platforms (e.g., AWS, Azure, or GCP) for model deployment.\nStrong understanding of algorithms, data structures, and statistics.\nFamiliarity with NLP techniques and tools (e.g., Hugging Face, spaCy) is a plus.\nExcellent problem-solving skills and ability to work in a fast-paced environment.\nPreferred Skills:\n\nExperience with MLOps tools (e.g., Kubeflow, MLflow).\nKnowledge of big data frameworks (e.g., Spark, Hadoop).\nContributions to open-source AI/ML projects or publications in relevant fields.\nBenefits:\n\nCompetitive salary and equity options.\nComprehensive health, dental, and vision insurance.\nFlexible work-from-home policy.\nAnnual learning stipend for professional development.\nCollaborative and inclusive team culture.\nHow to Apply:\n\nPlease submit your resume and a cover letter to careers@innovateai.com. Include links to your GitHub, LinkedIn, or portfolio if applicable. Applications will be reviewed on a rolling basis.\n\nInnovateAI Solutions is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2048, 'stream': True, 'temperature': 0.1, 'top_p': 1}}
2025-04-16 19:45:30,831 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 19:45:30,832 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 19:45:30,833 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 19:45:30,833 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 19:45:30,833 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 19:45:30,834 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 19:45:31,006 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 14:15:30 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'93144b91cd6906a4-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'no-cache'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'998'), (b'X-Ratelimit-Remaining-Tokens', b'10251'), (b'X-Ratelimit-Reset-Requests', b'2m52.595s'), (b'X-Ratelimit-Reset-Tokens', b'8.741999999s'), (b'X-Request-Id', b'req_01jrzf8xt1f2r99pp64y2f9qg3'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 19:45:31,008 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 19:45:31,009 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 14:15:30 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '93144b91cd6906a4-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'no-cache', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '998', 'x-ratelimit-remaining-tokens': '10251', 'x-ratelimit-reset-requests': '2m52.595s', 'x-ratelimit-reset-tokens': '8.741999999s', 'x-request-id': 'req_01jrzf8xt1f2r99pp64y2f9qg3', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 19:45:31,011 - ResumeServer - INFO - Collecting response chunks...
2025-04-16 19:45:31,012 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 19:45:31,159 - ResumeServer - DEBUG - Received 10 chunks, response length: 44
2025-04-16 19:45:31,176 - ResumeServer - DEBUG - Received 20 chunks, response length: 95
2025-04-16 19:45:31,182 - ResumeServer - DEBUG - Received 30 chunks, response length: 146
2025-04-16 19:45:31,224 - ResumeServer - DEBUG - Received 40 chunks, response length: 208
2025-04-16 19:45:31,227 - ResumeServer - DEBUG - Received 50 chunks, response length: 255
2025-04-16 19:45:31,231 - ResumeServer - DEBUG - Received 60 chunks, response length: 298
2025-04-16 19:45:31,274 - ResumeServer - DEBUG - Received 70 chunks, response length: 361
2025-04-16 19:45:31,277 - ResumeServer - DEBUG - Received 80 chunks, response length: 418
2025-04-16 19:45:31,280 - ResumeServer - DEBUG - Received 90 chunks, response length: 473
2025-04-16 19:45:31,305 - ResumeServer - DEBUG - Received 100 chunks, response length: 507
2025-04-16 19:45:31,318 - ResumeServer - DEBUG - Received 110 chunks, response length: 537
2025-04-16 19:45:31,345 - ResumeServer - DEBUG - Received 120 chunks, response length: 568
2025-04-16 19:45:31,374 - ResumeServer - DEBUG - Received 130 chunks, response length: 617
2025-04-16 19:45:31,379 - ResumeServer - DEBUG - Received 140 chunks, response length: 668
2025-04-16 19:45:31,407 - ResumeServer - DEBUG - Received 150 chunks, response length: 717
2025-04-16 19:45:31,411 - ResumeServer - DEBUG - Received 160 chunks, response length: 760
2025-04-16 19:45:31,415 - ResumeServer - DEBUG - Received 170 chunks, response length: 812
2025-04-16 19:45:31,423 - ResumeServer - DEBUG - Received 180 chunks, response length: 850
2025-04-16 19:45:31,436 - ResumeServer - DEBUG - Received 190 chunks, response length: 888
2025-04-16 19:45:31,451 - ResumeServer - DEBUG - Received 200 chunks, response length: 923
2025-04-16 19:45:31,464 - ResumeServer - DEBUG - Received 210 chunks, response length: 979
2025-04-16 19:45:31,482 - ResumeServer - DEBUG - Received 220 chunks, response length: 1021
2025-04-16 19:45:31,490 - ResumeServer - DEBUG - Received 230 chunks, response length: 1083
2025-04-16 19:45:31,507 - ResumeServer - DEBUG - Received 240 chunks, response length: 1113
2025-04-16 19:45:31,526 - ResumeServer - DEBUG - Received 250 chunks, response length: 1182
2025-04-16 19:45:31,531 - ResumeServer - DEBUG - Received 260 chunks, response length: 1217
2025-04-16 19:45:31,550 - ResumeServer - DEBUG - Received 270 chunks, response length: 1265
2025-04-16 19:45:31,562 - ResumeServer - DEBUG - Received 280 chunks, response length: 1292
2025-04-16 19:45:31,572 - ResumeServer - DEBUG - Received 290 chunks, response length: 1312
2025-04-16 19:45:31,585 - ResumeServer - DEBUG - Received 300 chunks, response length: 1362
2025-04-16 19:45:31,604 - ResumeServer - DEBUG - Received 310 chunks, response length: 1416
2025-04-16 19:45:31,616 - ResumeServer - DEBUG - Received 320 chunks, response length: 1448
2025-04-16 19:45:31,633 - ResumeServer - DEBUG - Received 330 chunks, response length: 1493
2025-04-16 19:45:31,638 - ResumeServer - DEBUG - Received 340 chunks, response length: 1551
2025-04-16 19:45:31,657 - ResumeServer - DEBUG - Received 350 chunks, response length: 1594
2025-04-16 19:45:31,674 - ResumeServer - DEBUG - Received 360 chunks, response length: 1642
2025-04-16 19:45:31,682 - ResumeServer - DEBUG - Received 370 chunks, response length: 1693
2025-04-16 19:45:31,692 - ResumeServer - DEBUG - Received 380 chunks, response length: 1745
2025-04-16 19:45:31,714 - ResumeServer - DEBUG - Received 390 chunks, response length: 1799
2025-04-16 19:45:31,723 - ResumeServer - DEBUG - Received 400 chunks, response length: 1832
2025-04-16 19:45:31,733 - ResumeServer - DEBUG - Received 410 chunks, response length: 1871
2025-04-16 19:45:31,752 - ResumeServer - DEBUG - Received 420 chunks, response length: 1898
2025-04-16 19:45:31,803 - ResumeServer - DEBUG - Received 430 chunks, response length: 1922
2025-04-16 19:45:31,805 - ResumeServer - DEBUG - Received 440 chunks, response length: 1985
2025-04-16 19:45:31,808 - ResumeServer - DEBUG - Received 450 chunks, response length: 2019
2025-04-16 19:45:31,810 - ResumeServer - DEBUG - Received 460 chunks, response length: 2061
2025-04-16 19:45:31,831 - ResumeServer - DEBUG - Received 470 chunks, response length: 2114
2025-04-16 19:45:31,842 - ResumeServer - DEBUG - Received 480 chunks, response length: 2146
2025-04-16 19:45:31,848 - ResumeServer - DEBUG - Received 490 chunks, response length: 2201
2025-04-16 19:45:31,861 - ResumeServer - DEBUG - Received 500 chunks, response length: 2251
2025-04-16 19:45:31,872 - ResumeServer - DEBUG - Received 510 chunks, response length: 2279
2025-04-16 19:45:31,885 - ResumeServer - DEBUG - Received 520 chunks, response length: 2327
2025-04-16 19:45:31,907 - ResumeServer - DEBUG - Received 530 chunks, response length: 2371
2025-04-16 19:45:31,914 - ResumeServer - DEBUG - Received 540 chunks, response length: 2396
2025-04-16 19:45:31,928 - ResumeServer - DEBUG - Received 550 chunks, response length: 2447
2025-04-16 19:45:31,937 - ResumeServer - DEBUG - Received 560 chunks, response length: 2479
2025-04-16 19:45:31,958 - ResumeServer - DEBUG - Received 570 chunks, response length: 2546
2025-04-16 19:45:31,978 - ResumeServer - DEBUG - Received 580 chunks, response length: 2590
2025-04-16 19:45:31,984 - ResumeServer - DEBUG - Received 590 chunks, response length: 2621
2025-04-16 19:45:31,999 - ResumeServer - DEBUG - Received 600 chunks, response length: 2660
2025-04-16 19:45:32,008 - ResumeServer - DEBUG - Received 610 chunks, response length: 2681
2025-04-16 19:45:32,040 - ResumeServer - DEBUG - Received 620 chunks, response length: 2711
2025-04-16 19:45:32,052 - ResumeServer - DEBUG - Received 630 chunks, response length: 2735
2025-04-16 19:45:32,059 - ResumeServer - DEBUG - Received 640 chunks, response length: 2770
2025-04-16 19:45:32,067 - ResumeServer - DEBUG - Received 650 chunks, response length: 2799
2025-04-16 19:45:32,089 - ResumeServer - DEBUG - Received 660 chunks, response length: 2823
2025-04-16 19:45:32,099 - ResumeServer - DEBUG - Received 670 chunks, response length: 2874
2025-04-16 19:45:32,125 - ResumeServer - DEBUG - Received 680 chunks, response length: 2901
2025-04-16 19:45:32,148 - ResumeServer - DEBUG - Received 690 chunks, response length: 2934
2025-04-16 19:45:32,153 - ResumeServer - DEBUG - Received 700 chunks, response length: 2961
2025-04-16 19:45:32,157 - ResumeServer - DEBUG - Received 710 chunks, response length: 2997
2025-04-16 19:45:32,176 - ResumeServer - DEBUG - Received 720 chunks, response length: 3019
2025-04-16 19:45:32,179 - ResumeServer - DEBUG - Received 730 chunks, response length: 3053
2025-04-16 19:45:32,199 - ResumeServer - DEBUG - Received 740 chunks, response length: 3103
2025-04-16 19:45:32,225 - ResumeServer - DEBUG - Received 750 chunks, response length: 3127
2025-04-16 19:45:32,238 - ResumeServer - DEBUG - Received 760 chunks, response length: 3151
2025-04-16 19:45:32,248 - ResumeServer - DEBUG - Received 770 chunks, response length: 3194
2025-04-16 19:45:32,254 - ResumeServer - DEBUG - Received 780 chunks, response length: 3218
2025-04-16 19:45:32,278 - ResumeServer - DEBUG - Received 790 chunks, response length: 3250
2025-04-16 19:45:32,290 - ResumeServer - DEBUG - Received 800 chunks, response length: 3285
2025-04-16 19:45:32,303 - ResumeServer - DEBUG - Received 810 chunks, response length: 3314
2025-04-16 19:45:32,407 - ResumeServer - DEBUG - Received 820 chunks, response length: 3335
2025-04-16 19:45:32,410 - ResumeServer - DEBUG - Received 830 chunks, response length: 3391
2025-04-16 19:45:32,415 - ResumeServer - DEBUG - Received 840 chunks, response length: 3413
2025-04-16 19:45:32,417 - ResumeServer - DEBUG - Received 850 chunks, response length: 3459
2025-04-16 19:45:32,422 - ResumeServer - DEBUG - Received 860 chunks, response length: 3486
2025-04-16 19:45:32,425 - ResumeServer - DEBUG - Received 870 chunks, response length: 3508
2025-04-16 19:45:32,430 - ResumeServer - DEBUG - Received 880 chunks, response length: 3539
2025-04-16 19:45:32,434 - ResumeServer - DEBUG - Received 890 chunks, response length: 3589
2025-04-16 19:45:32,450 - ResumeServer - DEBUG - Received 900 chunks, response length: 3607
2025-04-16 19:45:32,481 - ResumeServer - DEBUG - Received 910 chunks, response length: 3644
2025-04-16 19:45:32,485 - ResumeServer - DEBUG - Received 920 chunks, response length: 3676
2025-04-16 19:45:32,488 - ResumeServer - DEBUG - Received 930 chunks, response length: 3713
2025-04-16 19:45:32,507 - ResumeServer - DEBUG - Received 940 chunks, response length: 3730
2025-04-16 19:45:32,537 - ResumeServer - DEBUG - Received 950 chunks, response length: 3776
2025-04-16 19:45:32,543 - ResumeServer - DEBUG - Received 960 chunks, response length: 3806
2025-04-16 19:45:32,550 - ResumeServer - DEBUG - Received 970 chunks, response length: 3855
2025-04-16 19:45:32,574 - ResumeServer - DEBUG - Received 980 chunks, response length: 3882
2025-04-16 19:45:32,617 - ResumeServer - DEBUG - Received 990 chunks, response length: 3931
2025-04-16 19:45:34,854 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 19:45:34,855 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 19:45:34,857 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 19:45:34,857 - ResumeServer - INFO - Response collection complete. Total 995 chunks, final length: 3938
2025-04-16 19:45:34,858 - ResumeServer - INFO - Response preview: <h2>Results-Driven Machine Learning Engineer</h2>
Results-driven Machine Learning Engineer with 4+ y...
2025-04-16 19:45:34,861 - ResumeServer - INFO - Building PDF document...
2025-04-16 19:45:34,877 - ResumeServer - INFO - PDF generation successful, size: 6020 bytes
2025-04-16 19:45:34,878 - ResumeServer - INFO - Resume generated successfully. PDF size: 6020 bytes
2025-04-16 19:45:34,878 - ResumeServer - DEBUG - Converting response to JSON
2025-04-16 19:45:34,879 - ResumeServer - DEBUG - Response headers set: application/json
2025-04-16 19:45:34,880 - ResumeServer - INFO - Successfully sent PDF response
2025-04-16 19:45:34,881 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmprkwhruxw
2025-04-16 19:45:34,886 - ResumeServer - INFO - GET request for /history
2025-04-16 19:45:34,887 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 19:45:40,915 - ResumeServer - INFO - GET request for /download/undefined
2025-04-16 19:45:40,916 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 19:48:46,875 - ResumeServer - INFO - GET request for /
2025-04-16 19:48:46,876 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 19:48:46,877 - ResumeServer - INFO - Served index.html successfully
2025-04-16 19:48:46,891 - ResumeServer - INFO - GET request for /history
2025-04-16 19:48:46,892 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 19:59:50,358 - ResumeServer - INFO - GET request for /
2025-04-16 19:59:50,359 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 19:59:50,360 - ResumeServer - INFO - Served index.html successfully
2025-04-16 19:59:50,374 - ResumeServer - INFO - GET request for /history
2025-04-16 19:59:50,375 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:00:09,575 - ResumeServer - INFO - POST request to /generate (Content-Length: 56870)
2025-04-16 20:00:09,577 - ResumeServer - INFO - Processing /generate request
2025-04-16 20:00:09,579 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp6j4_tqbm
2025-04-16 20:00:09,580 - ResumeServer - DEBUG - Parsing form data
2025-04-16 20:00:09,600 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 20:00:09,602 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=posting.txt
2025-04-16 20:00:09,603 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 20:00:09,609 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 20:00:09,620 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmp6j4_tqbm\template.txt
2025-04-16 20:00:09,622 - ResumeServer - INFO - Generating resume...
2025-04-16 20:00:09,688 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:00:09,769 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:00:09,793 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:00:09,802 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    max_tokens=2048,
               ^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:00:09,806 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 20:00:11,810 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:00:11,812 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:00:11,814 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:00:11,817 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    max_tokens=2048,
               ^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:00:11,819 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 20:00:13,822 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:00:13,823 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:00:13,824 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:00:13,827 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    max_tokens=2048,
               ^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:00:13,832 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:00:13,834 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    format_info += f" and {len(structure['headings']) - 5} more.\n"
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    max_tokens=2048,
               ^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:00:13,838 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:00:13,841 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp6j4_tqbm
2025-04-16 20:00:19,896 - ResumeServer - INFO - POST request to /generate (Content-Length: 56870)
2025-04-16 20:00:19,897 - ResumeServer - INFO - Processing /generate request
2025-04-16 20:00:19,897 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp6q2o_y5q
2025-04-16 20:00:19,898 - ResumeServer - DEBUG - Parsing form data
2025-04-16 20:00:19,901 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 20:00:19,902 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=posting.txt
2025-04-16 20:00:19,902 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 20:00:19,904 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 20:00:19,905 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmp6q2o_y5q\template.txt
2025-04-16 20:00:19,906 - ResumeServer - INFO - Generating resume...
2025-04-16 20:00:19,908 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:00:19,909 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:00:19,913 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:00:19,914 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    max_tokens=2048,
               ^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:00:19,915 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 20:00:21,916 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:00:21,917 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:00:21,918 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:00:21,920 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    max_tokens=2048,
               ^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:00:21,921 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 20:00:23,924 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:00:23,925 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:00:23,926 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:00:23,928 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    max_tokens=2048,
               ^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:00:23,930 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:00:23,932 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    format_info += f" and {len(structure['headings']) - 5} more.\n"
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    max_tokens=2048,
               ^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:00:23,935 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:00:23,938 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp6q2o_y5q
2025-04-16 20:00:28,694 - ResumeServer - INFO - POST request to /generate (Content-Length: 10618)
2025-04-16 20:00:28,695 - ResumeServer - INFO - Processing /generate request
2025-04-16 20:00:28,696 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpu7rcm5jz
2025-04-16 20:00:28,697 - ResumeServer - DEBUG - Parsing form data
2025-04-16 20:00:28,702 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 20:00:28,703 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=posting.txt
2025-04-16 20:00:28,704 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 20:00:28,708 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 20:00:28,709 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmpu7rcm5jz\template.txt
2025-04-16 20:00:28,711 - ResumeServer - INFO - Generating resume...
2025-04-16 20:00:28,715 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:00:28,718 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:00:28,721 - ResumeServer - DEBUG - Template content length: 3529 chars
2025-04-16 20:00:28,722 - ResumeServer - INFO - Initializing Groq client...
2025-04-16 20:00:29,728 - ResumeServer - INFO - Preparing messages for AI request...
2025-04-16 20:00:29,729 - ResumeServer - DEBUG - Using template in prompt
2025-04-16 20:00:29,730 - ResumeServer - INFO - Sending request to Groq API...
2025-04-16 20:00:29,734 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Respond with 'test ok'"}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 10, 'stream': False}}
2025-04-16 20:00:29,736 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 20:00:29,737 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-04-16 20:00:29,884 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC15EC200>
2025-04-16 20:00:29,885 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EFC15B68D0> server_hostname='api.groq.com' timeout=5.0
2025-04-16 20:00:29,952 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC15D3EF0>
2025-04-16 20:00:29,954 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 20:00:29,955 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 20:00:29,956 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 20:00:29,957 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 20:00:29,957 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 20:00:30,124 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 14:30:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'931461857fe47eb0-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'999'), (b'X-Ratelimit-Remaining-Tokens', b'11990'), (b'X-Ratelimit-Reset-Requests', b'1m26.4s'), (b'X-Ratelimit-Reset-Tokens', b'50ms'), (b'X-Request-Id', b'req_01jrzg4bwdfbbrvcqvpeak2b8j'), (b'Set-Cookie', b'__cf_bm=jJD9nxP1HyUe7LbCMJtHiRRXOkLHKf0uzn9f9SLVXeA-1744813830-1.0.1.1-mbDlYF9fWeVK0tdpdFZhoeT1IIijuyztSyi5fvfxncZru8MI5DKbTCjVetT.OVo2Ou7stGBsbmW65ZLRDOmJXtmuByEcPqRhkuVs6NT8oVc; path=/; expires=Wed, 16-Apr-25 15:00:30 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 20:00:30,128 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 20:00:30,130 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 20:00:30,130 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 20:00:30,132 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 20:00:30,133 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 20:00:30,133 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 14:30:30 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '931461857fe47eb0-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '999', 'x-ratelimit-remaining-tokens': '11990', 'x-ratelimit-reset-requests': '1m26.4s', 'x-ratelimit-reset-tokens': '50ms', 'x-request-id': 'req_01jrzg4bwdfbbrvcqvpeak2b8j', 'set-cookie': '__cf_bm=jJD9nxP1HyUe7LbCMJtHiRRXOkLHKf0uzn9f9SLVXeA-1744813830-1.0.1.1-mbDlYF9fWeVK0tdpdFZhoeT1IIijuyztSyi5fvfxncZru8MI5DKbTCjVetT.OVo2Ou7stGBsbmW65ZLRDOmJXtmuByEcPqRhkuVs6NT8oVc; path=/; expires=Wed, 16-Apr-25 15:00:30 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 20:00:30,139 - ResumeServer - INFO - API test successful: test ok
2025-04-16 20:00:30,139 - ResumeServer - INFO - Creating streaming completion...
2025-04-16 20:00:30,141 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a resume assistant. Format your response with HTML tags for styling. Use <strong> for bold, <h2> for section headers, <ul> and <li> for lists. Provide ONLY the resume content, no analysis or insights. Start directly with the resume content.'}, {'role': 'user', 'content': "Create a tailored resume based on this resume and job description, following this template structure. Format the response with HTML tags. Provide ONLY the resume content, no analysis or insights.\n\nResume:\n\nResults-driven Machine Learning Engineer with 4+ years of experience developing and deploying AI models for diverse applications, including computer vision, NLP, and predictive analytics. Skilled in Python, TensorFlow, and cloud platforms like GCP. Adept at translating complex data into actionable insights and thriving in collaborative, fast-paced environments.\n\nProfessional Experience\n\nMachine Learning Engineer\n\nNexGen Technologies, Austin, TX\n\nAugust 2021 – Present\n\nBuilt convolutional neural networks (CNNs) with TensorFlow for image classification, achieving 92% accuracy on a custom dataset for retail product recognition.\nDesigned and deployed NLP models using BERT and Hugging Face for automated customer support, reducing response times by 40%.\nImplemented MLOps pipelines with Kubeflow and GCP, automating model retraining and monitoring for production systems.\nPreprocessed terabyte-scale datasets with Apache Spark, optimizing data pipelines for faster model training.\nMentored junior engineers on best practices for model development and version control with Git.\nData Scientist\n\nInsight Analytics, San Francisco, CA (Remote)\n\nJune 2020 – July 2021\n\nDeveloped time-series forecasting models with PyTorch to predict inventory demand, improving supply chain efficiency by 20%.\nConducted exploratory data analysis with pandas and SQL, uncovering trends that informed marketing strategies.\nCreated interactive dashboards with Plotly and Tableau to visualize model outputs for executive stakeholders.\nCollaborated with software engineers to integrate ML models into web applications using Flask APIs.\nResearch Intern, AI Lab\n\nStanford University, Stanford, CA\n\nJanuary 2019 – May 2020\n\nContributed to research on reinforcement learning algorithms, co-authoring a paper presented at NeurIPS 2020.\nBuilt simulation environments with OpenAI Gym to test agent performance in dynamic scenarios.\nOptimized model training workflows, reducing compute costs by 15% through efficient resource allocation.\nEducation\n\nMaster of Science in Artificial Intelligence\n\nCarnegie Mellon University, Pittsburgh, PA\n\nGraduated: May 2020\n\nFocus: Deep Learning and Reinforcement Learning\nCapstone Project: “Scalable RL Models for Autonomous Navigation”\nBachelor of Science in Computer Science\n\nUniversity of Texas at Austin, Austin, TX\n\nGraduated: May 2018\n\nMinor in Applied Mathematics\nSkills\n\nProgramming: Python, C++, SQL, Bash\nML Frameworks: TensorFlow, PyTorch, scikit-learn, Hugging Face, OpenCV\nCloud Platforms: Google Cloud Platform (AI Platform, BigQuery), AWS, Azure\nTools: Docker, Jenkins, MLflow, Git, Jupyter, Tableau\nData Processing: pandas, NumPy, Spark, Dask\nDomains: Computer Vision, NLP, Reinforcement Learning, Time-Series Analysis\nProjects\n\nAutonomous Drone Navigation (GitHub: github.com/alexcarter/drone-ai)\nDeveloped a reinforcement learning model with PyTorch to train drones for obstacle avoidance, tested in simulated environments.\nText Summarization Tool\nBuilt an NLP pipeline with Hugging Face transformers to generate concise summaries of news articles, deployed as a web app with Streamlit.\nFacial Recognition System\nCreated a real-time face detection model using OpenCV and TensorFlow, achieving 95% accuracy on public datasets.\nCertifications\n\nGoogle Cloud Professional Machine Learning Engineer (2023)\nCoursera: Deep Learning Specialization by Andrew Ng (2020)\nPublications & Talks\n\nCo-author, “Advances in Scalable Reinforcement Learning for Robotics,” NeurIPS 2020.\nGuest Speaker, “MLOps for Beginners,” Austin AI Meetup, March 2023.\nAdditional Information\n\nActive contributor to PyTorch (3 pull requests merged).\nVolunteer mentor at Code2AI, teaching high school students ML basics.\nProficient in French; conversational in Japanese.\n\nJob Description:\n\nJob Title: Machine Learning Engineer\n\nCompany: InnovateAI Solutions\n\nLocation: Remote (US-based preferred)\n\nPosted: April 15, 2025\n\nEmployment Type: Full-Time\n\nAbout InnovateAI Solutions:\n\nInnovateAI Solutions is a fast-growing tech company specializing in cutting-edge AI-driven products for healthcare and finance. Our mission is to empower businesses with intelligent solutions that transform industries.\n\nJob Description:\n\nWe are seeking a talented Machine Learning Engineer to join our AI Development team. You will design, develop, and deploy machine learning models to solve complex problems in predictive analytics and natural language processing. This role offers the opportunity to work on impactful projects with a collaborative, innovative team.\n\nKey Responsibilities:\n\nDevelop and optimize machine learning models for tasks such as classification, regression, and NLP.\nCollaborate with data scientists and software engineers to integrate models into production systems.\nConduct experiments to evaluate model performance and iterate on improvements.\nPreprocess and analyze large datasets to extract meaningful insights.\nStay updated on the latest AI/ML research and apply relevant advancements to projects.\nDocument processes and communicate findings to technical and non-technical stakeholders.\nQualifications:\n\nBachelor’s or Master’s degree in Computer Science, Data Science, or a related field.\n3+ years of experience building and deploying machine learning models.\nProficiency in Python and libraries such as TensorFlow, PyTorch, or scikit-learn.\nExperience with cloud platforms (e.g., AWS, Azure, or GCP) for model deployment.\nStrong understanding of algorithms, data structures, and statistics.\nFamiliarity with NLP techniques and tools (e.g., Hugging Face, spaCy) is a plus.\nExcellent problem-solving skills and ability to work in a fast-paced environment.\nPreferred Skills:\n\nExperience with MLOps tools (e.g., Kubeflow, MLflow).\nKnowledge of big data frameworks (e.g., Spark, Hadoop).\nContributions to open-source AI/ML projects or publications in relevant fields.\nBenefits:\n\nCompetitive salary and equity options.\nComprehensive health, dental, and vision insurance.\nFlexible work-from-home policy.\nAnnual learning stipend for professional development.\nCollaborative and inclusive team culture.\nHow to Apply:\n\nPlease submit your resume and a cover letter to careers@innovateai.com. Include links to your GitHub, LinkedIn, or portfolio if applicable. Applications will be reviewed on a rolling basis.\n\nInnovateAI Solutions is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.\n\nTemplate:\n\nBased on the provided resume and job description, here is a tailored resume and analysis:\n\nTailored Resume:\n\nResults-driven Machine Learning Engineer with 4+ years of experience developing and deploying AI models for diverse applications, including predictive analytics and NLP. Skilled in Python, TensorFlow, and cloud platforms like GCP. Proven track record of designing, developing, and deploying machine learning models to solve complex problems.\n\nProfessional Experience\n\nMachine Learning Engineer\n\nNexGen Technologies, Austin, TX\n\nAugust 2021 – Present\n\n* Developed and optimized machine learning models for classification, regression, and NLP tasks using TensorFlow and PyTorch.\n* Collaborated with data scientists and software engineers to integrate models into production systems, resulting in improved predictive analytics and automated customer support.\n* Conducted experiments to evaluate model performance and iterated on improvements, achieving 92% accuracy on a custom dataset for retail product recognition.\n* Preprocessed and analyzed large datasets to extract meaningful insights, utilizing Apache Spark and pandas.\n\nData Scientist\n\nInsight Analytics, San Francisco, CA (Remote)\n\nJune 2020 – July 2021\n\n* Developed time-series forecasting models using PyTorch to predict inventory demand, improving supply chain efficiency by 20%.\n* Conducted exploratory data analysis to uncover trends that informed marketing strategies, utilizing pandas and SQL.\n* Created interactive dashboards to visualize model outputs for executive stakeholders, using Plotly and Tableau.\n\nEducation\n\nMaster of Science in Artificial Intelligence\n\nCarnegie Mellon University, Pittsburgh, PA\n\nGraduated: May 2020\n\nFocus: Deep Learning and Reinforcement Learning\nCapstone Project: “Scalable RL Models for Autonomous Navigation”\n\nSkills\n\n* Programming: Python, C++, SQL, Bash\n* ML Frameworks: TensorFlow, PyTorch, scikit-learn, Hugging Face\n* Cloud Platforms: Google Cloud Platform (AI Platform, BigQuery), AWS, Azure\n* Tools: Docker, Jenkins, MLflow, Git, Jupyter\n* Data Processing: pandas, NumPy, Spark, Dask\n* Domains: Predictive Analytics, NLP, Reinforcement Learning, Time-Series Analysis\n\nAnalysis:\n\nThe tailored resume highlights the candidate's experience and skills in machine learning, predictive analytics, and NLP, which are directly relevant to the job description. The candidate's experience in developing and deploying machine learning models, collaborating with data scientists and software engineers, and conducting experiments to evaluate model performance are all aligned with the key responsibilities of the job.\n\nThe candidate's skills in Python, TensorFlow, and cloud platforms like GCP are also highlighted, as these are preferred skills for the job. The candidate's experience with MLOps tools like Kubeflow and big data frameworks like Spark are also mentioned, which are preferred skills for the job.\n\nThe candidate's education and certifications, including a Master's degree in Artificial Intelligence and a Google Cloud Professional Machine Learning Engineer certification, demonstrate their expertise in the field. The candidate's contributions to open-source AI/ML projects, such as PyTorch, and their publications in relevant fields, such as NeurIPS 2020, also demonstrate their expertise and commitment to the field.\n\nOverall, the tailored resume and analysis demonstrate that the candidate has the skills, experience, and education required for the Machine Learning Engineer position at InnovateAI Solutions."}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2048, 'stream': True, 'temperature': 0.1, 'top_p': 1}}
2025-04-16 20:00:30,158 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 20:00:30,159 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 20:00:30,161 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 20:00:30,162 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 20:00:30,163 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 20:00:30,164 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 20:00:30,339 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 14:30:30 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'93146186c9537eb0-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'no-cache'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'998'), (b'X-Ratelimit-Remaining-Tokens', b'9359'), (b'X-Ratelimit-Reset-Requests', b'2m52.583999999s'), (b'X-Ratelimit-Reset-Tokens', b'13.203s'), (b'X-Request-Id', b'req_01jrzg4c38fbbsdjzrr6rj0fea'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 20:00:30,342 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 20:00:30,343 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 14:30:30 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '93146186c9537eb0-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'no-cache', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '998', 'x-ratelimit-remaining-tokens': '9359', 'x-ratelimit-reset-requests': '2m52.583999999s', 'x-ratelimit-reset-tokens': '13.203s', 'x-request-id': 'req_01jrzg4c38fbbsdjzrr6rj0fea', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 20:00:30,345 - ResumeServer - INFO - Collecting response chunks...
2025-04-16 20:00:30,346 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 20:00:30,512 - ResumeServer - DEBUG - Received 10 chunks, response length: 23
2025-04-16 20:00:30,523 - ResumeServer - DEBUG - Received 20 chunks, response length: 74
2025-04-16 20:00:30,549 - ResumeServer - DEBUG - Received 30 chunks, response length: 141
2025-04-16 20:00:30,556 - ResumeServer - DEBUG - Received 40 chunks, response length: 198
2025-04-16 20:00:30,569 - ResumeServer - DEBUG - Received 50 chunks, response length: 251
2025-04-16 20:00:30,586 - ResumeServer - DEBUG - Received 60 chunks, response length: 290
2025-04-16 20:00:30,598 - ResumeServer - DEBUG - Received 70 chunks, response length: 357
2025-04-16 20:00:30,629 - ResumeServer - DEBUG - Received 80 chunks, response length: 400
2025-04-16 20:00:30,638 - ResumeServer - DEBUG - Received 90 chunks, response length: 450
2025-04-16 20:00:30,663 - ResumeServer - DEBUG - Received 100 chunks, response length: 484
2025-04-16 20:00:30,673 - ResumeServer - DEBUG - Received 110 chunks, response length: 554
2025-04-16 20:00:30,687 - ResumeServer - DEBUG - Received 120 chunks, response length: 602
2025-04-16 20:00:30,704 - ResumeServer - DEBUG - Received 130 chunks, response length: 647
2025-04-16 20:00:30,720 - ResumeServer - DEBUG - Received 140 chunks, response length: 715
2025-04-16 20:00:30,737 - ResumeServer - DEBUG - Received 150 chunks, response length: 791
2025-04-16 20:00:30,760 - ResumeServer - DEBUG - Received 160 chunks, response length: 853
2025-04-16 20:00:30,765 - ResumeServer - DEBUG - Received 170 chunks, response length: 900
2025-04-16 20:00:30,770 - ResumeServer - DEBUG - Received 180 chunks, response length: 955
2025-04-16 20:00:30,789 - ResumeServer - DEBUG - Received 190 chunks, response length: 1024
2025-04-16 20:00:30,810 - ResumeServer - DEBUG - Received 200 chunks, response length: 1080
2025-04-16 20:00:30,822 - ResumeServer - DEBUG - Received 210 chunks, response length: 1124
2025-04-16 20:00:30,832 - ResumeServer - DEBUG - Received 220 chunks, response length: 1147
2025-04-16 20:00:30,846 - ResumeServer - DEBUG - Received 230 chunks, response length: 1203
2025-04-16 20:00:30,858 - ResumeServer - DEBUG - Received 240 chunks, response length: 1269
2025-04-16 20:00:30,875 - ResumeServer - DEBUG - Received 250 chunks, response length: 1312
2025-04-16 20:00:30,892 - ResumeServer - DEBUG - Received 260 chunks, response length: 1383
2025-04-16 20:00:30,896 - ResumeServer - DEBUG - Received 270 chunks, response length: 1438
2025-04-16 20:00:30,911 - ResumeServer - DEBUG - Received 280 chunks, response length: 1497
2025-04-16 20:00:30,922 - ResumeServer - DEBUG - Received 290 chunks, response length: 1525
2025-04-16 20:00:30,933 - ResumeServer - DEBUG - Received 300 chunks, response length: 1578
2025-04-16 20:00:30,949 - ResumeServer - DEBUG - Received 310 chunks, response length: 1627
2025-04-16 20:00:30,963 - ResumeServer - DEBUG - Received 320 chunks, response length: 1659
2025-04-16 20:00:30,980 - ResumeServer - DEBUG - Received 330 chunks, response length: 1706
2025-04-16 20:00:30,996 - ResumeServer - DEBUG - Received 340 chunks, response length: 1755
2025-04-16 20:00:31,005 - ResumeServer - DEBUG - Received 350 chunks, response length: 1779
2025-04-16 20:00:31,019 - ResumeServer - DEBUG - Received 360 chunks, response length: 1818
2025-04-16 20:00:31,034 - ResumeServer - DEBUG - Received 370 chunks, response length: 1848
2025-04-16 20:00:31,045 - ResumeServer - DEBUG - Received 380 chunks, response length: 1882
2025-04-16 20:00:31,056 - ResumeServer - DEBUG - Received 390 chunks, response length: 1910
2025-04-16 20:00:31,087 - ResumeServer - DEBUG - Received 400 chunks, response length: 1964
2025-04-16 20:00:31,106 - ResumeServer - DEBUG - Received 410 chunks, response length: 2000
2025-04-16 20:00:31,118 - ResumeServer - DEBUG - Received 420 chunks, response length: 2033
2025-04-16 20:00:31,131 - ResumeServer - DEBUG - Received 430 chunks, response length: 2064
2025-04-16 20:00:31,157 - ResumeServer - DEBUG - Received 440 chunks, response length: 2107
2025-04-16 20:00:31,180 - ResumeServer - DEBUG - Received 450 chunks, response length: 2129
2025-04-16 20:00:31,204 - ResumeServer - DEBUG - Received 460 chunks, response length: 2176
2025-04-16 20:00:31,219 - ResumeServer - DEBUG - Received 470 chunks, response length: 2218
2025-04-16 20:00:31,233 - ResumeServer - DEBUG - Received 480 chunks, response length: 2251
2025-04-16 20:00:31,253 - ResumeServer - DEBUG - Received 490 chunks, response length: 2312
2025-04-16 20:00:31,296 - ResumeServer - DEBUG - Received 500 chunks, response length: 2348
2025-04-16 20:00:31,306 - ResumeServer - DEBUG - Received 510 chunks, response length: 2380
2025-04-16 20:00:31,334 - ResumeServer - DEBUG - Received 520 chunks, response length: 2406
2025-04-16 20:00:31,380 - ResumeServer - DEBUG - Received 530 chunks, response length: 2451
2025-04-16 20:00:31,453 - ResumeServer - DEBUG - Received 540 chunks, response length: 2482
2025-04-16 20:00:31,471 - ResumeServer - DEBUG - Received 550 chunks, response length: 2517
2025-04-16 20:00:31,503 - ResumeServer - DEBUG - Received 560 chunks, response length: 2555
2025-04-16 20:00:31,529 - ResumeServer - DEBUG - Received 570 chunks, response length: 2591
2025-04-16 20:00:31,575 - ResumeServer - DEBUG - Received 580 chunks, response length: 2618
2025-04-16 20:00:31,613 - ResumeServer - DEBUG - Received 590 chunks, response length: 2674
2025-04-16 20:00:31,630 - ResumeServer - DEBUG - Received 600 chunks, response length: 2698
2025-04-16 20:00:31,689 - ResumeServer - DEBUG - Received 610 chunks, response length: 2737
2025-04-16 20:00:31,748 - ResumeServer - DEBUG - Received 620 chunks, response length: 2764
2025-04-16 20:00:31,773 - ResumeServer - DEBUG - Received 630 chunks, response length: 2803
2025-04-16 20:00:31,824 - ResumeServer - DEBUG - Received 640 chunks, response length: 2850
2025-04-16 20:00:31,896 - ResumeServer - DEBUG - Received 650 chunks, response length: 2892
2025-04-16 20:00:31,934 - ResumeServer - DEBUG - Received 660 chunks, response length: 2940
2025-04-16 20:00:33,074 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 20:00:33,074 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 20:00:33,075 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 20:00:33,075 - ResumeServer - INFO - Response collection complete. Total 668 chunks, final length: 2976
2025-04-16 20:00:33,076 - ResumeServer - INFO - Response preview: <h2>Tailored Resume</h2>

Results-driven Machine Learning Engineer with 4+ years of experience devel...
2025-04-16 20:00:33,080 - ResumeServer - INFO - Building PDF document...
2025-04-16 20:00:33,087 - ResumeServer - INFO - PDF generation successful, size: 5308 bytes
2025-04-16 20:00:33,088 - ResumeServer - INFO - Resume generated successfully. PDF size: 5308 bytes
2025-04-16 20:00:33,088 - ResumeServer - DEBUG - Converting response to JSON
2025-04-16 20:00:33,089 - ResumeServer - DEBUG - Response headers set: application/json
2025-04-16 20:00:33,090 - ResumeServer - INFO - Successfully sent PDF response
2025-04-16 20:00:33,090 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpu7rcm5jz
2025-04-16 20:00:33,406 - ResumeServer - INFO - GET request for /history
2025-04-16 20:00:33,407 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:00:34,417 - ResumeServer - INFO - GET request for /download/undefined
2025-04-16 20:00:34,418 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:00:55,764 - ResumeServer - INFO - GET request for /download/undefined
2025-04-16 20:00:55,766 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:26:45,044 - ResumeServer - INFO - GET request for /
2025-04-16 20:26:45,045 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 20:26:45,046 - ResumeServer - INFO - Served index.html successfully
2025-04-16 20:26:45,062 - ResumeServer - INFO - GET request for /history
2025-04-16 20:26:45,063 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:26:59,855 - ResumeServer - INFO - POST request to /generate (Content-Length: 56870)
2025-04-16 20:26:59,856 - ResumeServer - INFO - Processing /generate request
2025-04-16 20:26:59,858 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpur_3f7yd
2025-04-16 20:26:59,860 - ResumeServer - DEBUG - Parsing form data
2025-04-16 20:26:59,870 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 20:26:59,871 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=posting.txt
2025-04-16 20:26:59,872 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 20:26:59,878 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 20:26:59,884 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmpur_3f7yd\template.txt
2025-04-16 20:26:59,886 - ResumeServer - INFO - Generating resume...
2025-04-16 20:26:59,893 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:26:59,899 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:26:59,917 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:26:59,923 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    class ResumeHandler(BaseHTTPRequestHandler):
                                   ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:26:59,925 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 20:27:01,926 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:27:01,928 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:27:01,930 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:27:01,932 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    class ResumeHandler(BaseHTTPRequestHandler):
                                   ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:27:01,934 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 20:27:03,936 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:27:03,939 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:27:03,940 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:27:03,942 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    class ResumeHandler(BaseHTTPRequestHandler):
                                   ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:27:03,945 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:27:03,946 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    try:
         
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    class ResumeHandler(BaseHTTPRequestHandler):
                                   ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:27:03,947 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:27:03,949 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpur_3f7yd
2025-04-16 20:27:09,373 - ResumeServer - INFO - POST request to /generate (Content-Length: 6912)
2025-04-16 20:27:09,374 - ResumeServer - INFO - Processing /generate request
2025-04-16 20:27:09,375 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpcwzv0w1f
2025-04-16 20:27:09,375 - ResumeServer - DEBUG - Parsing form data
2025-04-16 20:27:09,379 - ResumeServer - DEBUG - Form fields: ['job_desc', 'resume']
2025-04-16 20:27:09,380 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=posting.txt
2025-04-16 20:27:09,380 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 20:27:09,383 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 20:27:09,384 - ResumeServer - INFO - Generating resume...
2025-04-16 20:27:09,386 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:27:09,388 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:27:09,389 - ResumeServer - INFO - Initializing Groq client...
2025-04-16 20:27:10,000 - ResumeServer - INFO - Preparing messages for AI request...
2025-04-16 20:27:10,000 - ResumeServer - DEBUG - Using standard prompt (no template)
2025-04-16 20:27:10,001 - ResumeServer - INFO - Sending request to Groq API...
2025-04-16 20:27:10,003 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Respond with 'test ok'"}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 10, 'stream': False}}
2025-04-16 20:27:10,004 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 20:27:10,004 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-04-16 20:27:10,112 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC15EFC80>
2025-04-16 20:27:10,113 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EFC15B59D0> server_hostname='api.groq.com' timeout=5.0
2025-04-16 20:27:10,177 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC15D3B00>
2025-04-16 20:27:10,179 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 20:27:10,179 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 20:27:10,180 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 20:27:10,181 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 20:27:10,181 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 20:27:10,339 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 14:57:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'931488970fc37eca-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'999'), (b'X-Ratelimit-Remaining-Tokens', b'11990'), (b'X-Ratelimit-Reset-Requests', b'1m26.4s'), (b'X-Ratelimit-Reset-Tokens', b'50ms'), (b'X-Request-Id', b'req_01jrzhn6m2evn8wkcqvg930n2t'), (b'Set-Cookie', b'__cf_bm=567EqrQ3ATaTtdzpqmTcnOb..k5JHQOqlALU_v8sjH0-1744815430-1.0.1.1-Xnk2GV2mLdNkH5PBMSCNQ7VpqUiR.ha.gecX4N6A2cDkD3r1_VeTioAFr0vutoqOPLcS.YhIA8fT6TXrK.8p_ZoLrSsbYeEK_4av.iixRL8; path=/; expires=Wed, 16-Apr-25 15:27:10 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 20:27:10,342 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 20:27:10,343 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 20:27:10,344 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 20:27:10,345 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 20:27:10,345 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 20:27:10,346 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 14:57:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '931488970fc37eca-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '999', 'x-ratelimit-remaining-tokens': '11990', 'x-ratelimit-reset-requests': '1m26.4s', 'x-ratelimit-reset-tokens': '50ms', 'x-request-id': 'req_01jrzhn6m2evn8wkcqvg930n2t', 'set-cookie': '__cf_bm=567EqrQ3ATaTtdzpqmTcnOb..k5JHQOqlALU_v8sjH0-1744815430-1.0.1.1-Xnk2GV2mLdNkH5PBMSCNQ7VpqUiR.ha.gecX4N6A2cDkD3r1_VeTioAFr0vutoqOPLcS.YhIA8fT6TXrK.8p_ZoLrSsbYeEK_4av.iixRL8; path=/; expires=Wed, 16-Apr-25 15:27:10 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 20:27:10,348 - ResumeServer - INFO - API test successful: test ok
2025-04-16 20:27:10,348 - ResumeServer - INFO - Creating streaming completion...
2025-04-16 20:27:10,351 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a resume assistant. Format your response with HTML tags for styling. Use <strong> for bold, <h2> for section headers, <ul> and <li> for lists. Provide ONLY the resume content, no analysis or insights. Start directly with the resume content.'}, {'role': 'user', 'content': 'Create a tailored resume based on this resume and job description. Format the response with HTML tags. Provide ONLY the resume content, no analysis or insights.\n\nResume:\n\nResults-driven Machine Learning Engineer with 4+ years of experience developing and deploying AI models for diverse applications, including computer vision, NLP, and predictive analytics. Skilled in Python, TensorFlow, and cloud platforms like GCP. Adept at translating complex data into actionable insights and thriving in collaborative, fast-paced environments.\n\nProfessional Experience\n\nMachine Learning Engineer\n\nNexGen Technologies, Austin, TX\n\nAugust 2021 – Present\n\nBuilt convolutional neural networks (CNNs) with TensorFlow for image classification, achieving 92% accuracy on a custom dataset for retail product recognition.\nDesigned and deployed NLP models using BERT and Hugging Face for automated customer support, reducing response times by 40%.\nImplemented MLOps pipelines with Kubeflow and GCP, automating model retraining and monitoring for production systems.\nPreprocessed terabyte-scale datasets with Apache Spark, optimizing data pipelines for faster model training.\nMentored junior engineers on best practices for model development and version control with Git.\nData Scientist\n\nInsight Analytics, San Francisco, CA (Remote)\n\nJune 2020 – July 2021\n\nDeveloped time-series forecasting models with PyTorch to predict inventory demand, improving supply chain efficiency by 20%.\nConducted exploratory data analysis with pandas and SQL, uncovering trends that informed marketing strategies.\nCreated interactive dashboards with Plotly and Tableau to visualize model outputs for executive stakeholders.\nCollaborated with software engineers to integrate ML models into web applications using Flask APIs.\nResearch Intern, AI Lab\n\nStanford University, Stanford, CA\n\nJanuary 2019 – May 2020\n\nContributed to research on reinforcement learning algorithms, co-authoring a paper presented at NeurIPS 2020.\nBuilt simulation environments with OpenAI Gym to test agent performance in dynamic scenarios.\nOptimized model training workflows, reducing compute costs by 15% through efficient resource allocation.\nEducation\n\nMaster of Science in Artificial Intelligence\n\nCarnegie Mellon University, Pittsburgh, PA\n\nGraduated: May 2020\n\nFocus: Deep Learning and Reinforcement Learning\nCapstone Project: “Scalable RL Models for Autonomous Navigation”\nBachelor of Science in Computer Science\n\nUniversity of Texas at Austin, Austin, TX\n\nGraduated: May 2018\n\nMinor in Applied Mathematics\nSkills\n\nProgramming: Python, C++, SQL, Bash\nML Frameworks: TensorFlow, PyTorch, scikit-learn, Hugging Face, OpenCV\nCloud Platforms: Google Cloud Platform (AI Platform, BigQuery), AWS, Azure\nTools: Docker, Jenkins, MLflow, Git, Jupyter, Tableau\nData Processing: pandas, NumPy, Spark, Dask\nDomains: Computer Vision, NLP, Reinforcement Learning, Time-Series Analysis\nProjects\n\nAutonomous Drone Navigation (GitHub: github.com/alexcarter/drone-ai)\nDeveloped a reinforcement learning model with PyTorch to train drones for obstacle avoidance, tested in simulated environments.\nText Summarization Tool\nBuilt an NLP pipeline with Hugging Face transformers to generate concise summaries of news articles, deployed as a web app with Streamlit.\nFacial Recognition System\nCreated a real-time face detection model using OpenCV and TensorFlow, achieving 95% accuracy on public datasets.\nCertifications\n\nGoogle Cloud Professional Machine Learning Engineer (2023)\nCoursera: Deep Learning Specialization by Andrew Ng (2020)\nPublications & Talks\n\nCo-author, “Advances in Scalable Reinforcement Learning for Robotics,” NeurIPS 2020.\nGuest Speaker, “MLOps for Beginners,” Austin AI Meetup, March 2023.\nAdditional Information\n\nActive contributor to PyTorch (3 pull requests merged).\nVolunteer mentor at Code2AI, teaching high school students ML basics.\nProficient in French; conversational in Japanese.\n\nJob Description:\n\nJob Title: Machine Learning Engineer\n\nCompany: InnovateAI Solutions\n\nLocation: Remote (US-based preferred)\n\nPosted: April 15, 2025\n\nEmployment Type: Full-Time\n\nAbout InnovateAI Solutions:\n\nInnovateAI Solutions is a fast-growing tech company specializing in cutting-edge AI-driven products for healthcare and finance. Our mission is to empower businesses with intelligent solutions that transform industries.\n\nJob Description:\n\nWe are seeking a talented Machine Learning Engineer to join our AI Development team. You will design, develop, and deploy machine learning models to solve complex problems in predictive analytics and natural language processing. This role offers the opportunity to work on impactful projects with a collaborative, innovative team.\n\nKey Responsibilities:\n\nDevelop and optimize machine learning models for tasks such as classification, regression, and NLP.\nCollaborate with data scientists and software engineers to integrate models into production systems.\nConduct experiments to evaluate model performance and iterate on improvements.\nPreprocess and analyze large datasets to extract meaningful insights.\nStay updated on the latest AI/ML research and apply relevant advancements to projects.\nDocument processes and communicate findings to technical and non-technical stakeholders.\nQualifications:\n\nBachelor’s or Master’s degree in Computer Science, Data Science, or a related field.\n3+ years of experience building and deploying machine learning models.\nProficiency in Python and libraries such as TensorFlow, PyTorch, or scikit-learn.\nExperience with cloud platforms (e.g., AWS, Azure, or GCP) for model deployment.\nStrong understanding of algorithms, data structures, and statistics.\nFamiliarity with NLP techniques and tools (e.g., Hugging Face, spaCy) is a plus.\nExcellent problem-solving skills and ability to work in a fast-paced environment.\nPreferred Skills:\n\nExperience with MLOps tools (e.g., Kubeflow, MLflow).\nKnowledge of big data frameworks (e.g., Spark, Hadoop).\nContributions to open-source AI/ML projects or publications in relevant fields.\nBenefits:\n\nCompetitive salary and equity options.\nComprehensive health, dental, and vision insurance.\nFlexible work-from-home policy.\nAnnual learning stipend for professional development.\nCollaborative and inclusive team culture.\nHow to Apply:\n\nPlease submit your resume and a cover letter to careers@innovateai.com. Include links to your GitHub, LinkedIn, or portfolio if applicable. Applications will be reviewed on a rolling basis.\n\nInnovateAI Solutions is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2048, 'stream': True, 'temperature': 0.1, 'top_p': 1}}
2025-04-16 20:27:10,359 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 20:27:10,361 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 20:27:10,362 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 20:27:10,362 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 20:27:10,363 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 20:27:10,363 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 20:27:10,521 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 14:57:10 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'9314889838ab7eca-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'no-cache'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'998'), (b'X-Ratelimit-Remaining-Tokens', b'10249'), (b'X-Ratelimit-Reset-Requests', b'2m52.61s'), (b'X-Ratelimit-Reset-Tokens', b'8.751999999s'), (b'X-Request-Id', b'req_01jrzhn6t0evnagndn38zr7sda'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 20:27:10,523 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 20:27:10,524 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 14:57:10 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9314889838ab7eca-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'no-cache', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '998', 'x-ratelimit-remaining-tokens': '10249', 'x-ratelimit-reset-requests': '2m52.61s', 'x-ratelimit-reset-tokens': '8.751999999s', 'x-request-id': 'req_01jrzhn6t0evnagndn38zr7sda', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 20:27:10,525 - ResumeServer - INFO - Collecting response chunks...
2025-04-16 20:27:10,526 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 20:27:10,669 - ResumeServer - DEBUG - Received 10 chunks, response length: 44
2025-04-16 20:27:10,672 - ResumeServer - DEBUG - Received 20 chunks, response length: 73
2025-04-16 20:27:10,719 - ResumeServer - DEBUG - Received 30 chunks, response length: 128
2025-04-16 20:27:10,722 - ResumeServer - DEBUG - Received 40 chunks, response length: 200
2025-04-16 20:27:10,728 - ResumeServer - DEBUG - Received 50 chunks, response length: 257
2025-04-16 20:27:10,732 - ResumeServer - DEBUG - Received 60 chunks, response length: 299
2025-04-16 20:27:10,767 - ResumeServer - DEBUG - Received 70 chunks, response length: 345
2025-04-16 20:27:10,783 - ResumeServer - DEBUG - Received 80 chunks, response length: 425
2025-04-16 20:27:10,787 - ResumeServer - DEBUG - Received 90 chunks, response length: 461
2025-04-16 20:27:10,812 - ResumeServer - DEBUG - Received 100 chunks, response length: 501
2025-04-16 20:27:10,834 - ResumeServer - DEBUG - Received 110 chunks, response length: 556
2025-04-16 20:27:10,844 - ResumeServer - DEBUG - Received 120 chunks, response length: 591
2025-04-16 20:27:10,862 - ResumeServer - DEBUG - Received 130 chunks, response length: 618
2025-04-16 20:27:10,887 - ResumeServer - DEBUG - Received 140 chunks, response length: 669
2025-04-16 20:27:10,905 - ResumeServer - DEBUG - Received 150 chunks, response length: 725
2025-04-16 20:27:10,917 - ResumeServer - DEBUG - Received 160 chunks, response length: 788
2025-04-16 20:27:10,937 - ResumeServer - DEBUG - Received 170 chunks, response length: 822
2025-04-16 20:27:10,947 - ResumeServer - DEBUG - Received 180 chunks, response length: 873
2025-04-16 20:27:10,965 - ResumeServer - DEBUG - Received 190 chunks, response length: 916
2025-04-16 20:27:10,977 - ResumeServer - DEBUG - Received 200 chunks, response length: 940
2025-04-16 20:27:10,994 - ResumeServer - DEBUG - Received 210 chunks, response length: 975
2025-04-16 20:27:11,002 - ResumeServer - DEBUG - Received 220 chunks, response length: 1041
2025-04-16 20:27:11,018 - ResumeServer - DEBUG - Received 230 chunks, response length: 1072
2025-04-16 20:27:11,028 - ResumeServer - DEBUG - Received 240 chunks, response length: 1137
2025-04-16 20:27:11,043 - ResumeServer - DEBUG - Received 250 chunks, response length: 1177
2025-04-16 20:27:11,054 - ResumeServer - DEBUG - Received 260 chunks, response length: 1231
2025-04-16 20:27:11,064 - ResumeServer - DEBUG - Received 270 chunks, response length: 1281
2025-04-16 20:27:11,081 - ResumeServer - DEBUG - Received 280 chunks, response length: 1330
2025-04-16 20:27:11,108 - ResumeServer - DEBUG - Received 290 chunks, response length: 1364
2025-04-16 20:27:11,119 - ResumeServer - DEBUG - Received 300 chunks, response length: 1390
2025-04-16 20:27:11,133 - ResumeServer - DEBUG - Received 310 chunks, response length: 1416
2025-04-16 20:27:11,148 - ResumeServer - DEBUG - Received 320 chunks, response length: 1465
2025-04-16 20:27:11,162 - ResumeServer - DEBUG - Received 330 chunks, response length: 1529
2025-04-16 20:27:11,175 - ResumeServer - DEBUG - Received 340 chunks, response length: 1550
2025-04-16 20:27:11,184 - ResumeServer - DEBUG - Received 350 chunks, response length: 1603
2025-04-16 20:27:11,208 - ResumeServer - DEBUG - Received 360 chunks, response length: 1663
2025-04-16 20:27:11,215 - ResumeServer - DEBUG - Received 370 chunks, response length: 1711
2025-04-16 20:27:11,224 - ResumeServer - DEBUG - Received 380 chunks, response length: 1766
2025-04-16 20:27:11,249 - ResumeServer - DEBUG - Received 390 chunks, response length: 1802
2025-04-16 20:27:11,251 - ResumeServer - DEBUG - Received 400 chunks, response length: 1862
2025-04-16 20:27:11,271 - ResumeServer - DEBUG - Received 410 chunks, response length: 1906
2025-04-16 20:27:11,280 - ResumeServer - DEBUG - Received 420 chunks, response length: 1941
2025-04-16 20:27:11,289 - ResumeServer - DEBUG - Received 430 chunks, response length: 1988
2025-04-16 20:27:11,301 - ResumeServer - DEBUG - Received 440 chunks, response length: 2013
2025-04-16 20:27:11,317 - ResumeServer - DEBUG - Received 450 chunks, response length: 2042
2025-04-16 20:27:11,328 - ResumeServer - DEBUG - Received 460 chunks, response length: 2104
2025-04-16 20:27:11,343 - ResumeServer - DEBUG - Received 470 chunks, response length: 2139
2025-04-16 20:27:11,356 - ResumeServer - DEBUG - Received 480 chunks, response length: 2185
2025-04-16 20:27:11,371 - ResumeServer - DEBUG - Received 490 chunks, response length: 2243
2025-04-16 20:27:11,388 - ResumeServer - DEBUG - Received 500 chunks, response length: 2273
2025-04-16 20:27:11,397 - ResumeServer - DEBUG - Received 510 chunks, response length: 2323
2025-04-16 20:27:11,407 - ResumeServer - DEBUG - Received 520 chunks, response length: 2375
2025-04-16 20:27:11,426 - ResumeServer - DEBUG - Received 530 chunks, response length: 2398
2025-04-16 20:27:11,438 - ResumeServer - DEBUG - Received 540 chunks, response length: 2459
2025-04-16 20:27:11,446 - ResumeServer - DEBUG - Received 550 chunks, response length: 2505
2025-04-16 20:27:11,456 - ResumeServer - DEBUG - Received 560 chunks, response length: 2531
2025-04-16 20:27:11,477 - ResumeServer - DEBUG - Received 570 chunks, response length: 2581
2025-04-16 20:27:11,511 - ResumeServer - DEBUG - Received 580 chunks, response length: 2608
2025-04-16 20:27:11,516 - ResumeServer - DEBUG - Received 590 chunks, response length: 2654
2025-04-16 20:27:11,540 - ResumeServer - DEBUG - Received 600 chunks, response length: 2699
2025-04-16 20:27:11,545 - ResumeServer - DEBUG - Received 610 chunks, response length: 2747
2025-04-16 20:27:11,552 - ResumeServer - DEBUG - Received 620 chunks, response length: 2774
2025-04-16 20:27:11,573 - ResumeServer - DEBUG - Received 630 chunks, response length: 2817
2025-04-16 20:27:11,586 - ResumeServer - DEBUG - Received 640 chunks, response length: 2837
2025-04-16 20:27:11,596 - ResumeServer - DEBUG - Received 650 chunks, response length: 2871
2025-04-16 20:27:11,626 - ResumeServer - DEBUG - Received 660 chunks, response length: 2896
2025-04-16 20:27:11,628 - ResumeServer - DEBUG - Received 670 chunks, response length: 2930
2025-04-16 20:27:11,637 - ResumeServer - DEBUG - Received 680 chunks, response length: 2958
2025-04-16 20:27:11,651 - ResumeServer - DEBUG - Received 690 chunks, response length: 2984
2025-04-16 20:27:11,668 - ResumeServer - DEBUG - Received 700 chunks, response length: 3036
2025-04-16 20:27:11,688 - ResumeServer - DEBUG - Received 710 chunks, response length: 3065
2025-04-16 20:27:11,692 - ResumeServer - DEBUG - Received 720 chunks, response length: 3096
2025-04-16 20:27:11,703 - ResumeServer - DEBUG - Received 730 chunks, response length: 3126
2025-04-16 20:27:11,721 - ResumeServer - DEBUG - Received 740 chunks, response length: 3163
2025-04-16 20:27:11,746 - ResumeServer - DEBUG - Received 750 chunks, response length: 3187
2025-04-16 20:27:11,750 - ResumeServer - DEBUG - Received 760 chunks, response length: 3222
2025-04-16 20:27:11,763 - ResumeServer - DEBUG - Received 770 chunks, response length: 3272
2025-04-16 20:27:11,775 - ResumeServer - DEBUG - Received 780 chunks, response length: 3297
2025-04-16 20:27:11,786 - ResumeServer - DEBUG - Received 790 chunks, response length: 3317
2025-04-16 20:27:11,812 - ResumeServer - DEBUG - Received 800 chunks, response length: 3367
2025-04-16 20:27:11,824 - ResumeServer - DEBUG - Received 810 chunks, response length: 3394
2025-04-16 20:27:11,837 - ResumeServer - DEBUG - Received 820 chunks, response length: 3452
2025-04-16 20:27:11,863 - ResumeServer - DEBUG - Received 830 chunks, response length: 3506
2025-04-16 20:27:11,867 - ResumeServer - DEBUG - Received 840 chunks, response length: 3551
2025-04-16 20:27:11,884 - ResumeServer - DEBUG - Received 850 chunks, response length: 3591
2025-04-16 20:27:11,895 - ResumeServer - DEBUG - Received 860 chunks, response length: 3641
2025-04-16 20:27:11,909 - ResumeServer - DEBUG - Received 870 chunks, response length: 3700
2025-04-16 20:27:11,929 - ResumeServer - DEBUG - Received 880 chunks, response length: 3735
2025-04-16 20:27:11,965 - ResumeServer - DEBUG - Received 890 chunks, response length: 3779
2025-04-16 20:27:12,006 - ResumeServer - DEBUG - Received 900 chunks, response length: 3833
2025-04-16 20:27:12,029 - ResumeServer - DEBUG - Received 910 chunks, response length: 3877
2025-04-16 20:27:12,055 - ResumeServer - DEBUG - Received 920 chunks, response length: 3910
2025-04-16 20:27:12,082 - ResumeServer - DEBUG - Received 930 chunks, response length: 3939
2025-04-16 20:27:12,109 - ResumeServer - DEBUG - Received 940 chunks, response length: 3997
2025-04-16 20:27:12,154 - ResumeServer - DEBUG - Received 950 chunks, response length: 4020
2025-04-16 20:27:12,188 - ResumeServer - DEBUG - Received 960 chunks, response length: 4067
2025-04-16 20:27:12,212 - ResumeServer - DEBUG - Received 970 chunks, response length: 4089
2025-04-16 20:27:12,242 - ResumeServer - DEBUG - Received 980 chunks, response length: 4117
2025-04-16 20:27:12,261 - ResumeServer - DEBUG - Received 990 chunks, response length: 4142
2025-04-16 20:27:12,303 - ResumeServer - DEBUG - Received 1000 chunks, response length: 4198
2025-04-16 20:27:12,331 - ResumeServer - DEBUG - Received 1010 chunks, response length: 4220
2025-04-16 20:27:12,374 - ResumeServer - DEBUG - Received 1020 chunks, response length: 4247
2025-04-16 20:27:12,425 - ResumeServer - DEBUG - Received 1030 chunks, response length: 4289
2025-04-16 20:27:12,458 - ResumeServer - DEBUG - Received 1040 chunks, response length: 4310
2025-04-16 20:27:12,467 - ResumeServer - DEBUG - Received 1050 chunks, response length: 4345
2025-04-16 20:27:12,498 - ResumeServer - DEBUG - Received 1060 chunks, response length: 4382
2025-04-16 20:27:12,542 - ResumeServer - DEBUG - Received 1070 chunks, response length: 4419
2025-04-16 20:27:12,601 - ResumeServer - DEBUG - Received 1080 chunks, response length: 4450
2025-04-16 20:27:12,640 - ResumeServer - DEBUG - Received 1090 chunks, response length: 4500
2025-04-16 20:27:12,693 - ResumeServer - DEBUG - Received 1100 chunks, response length: 4541
2025-04-16 20:27:14,778 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 20:27:14,778 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 20:27:14,778 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 20:27:14,779 - ResumeServer - INFO - Response collection complete. Total 1109 chunks, final length: 4565
2025-04-16 20:27:14,779 - ResumeServer - INFO - Response preview: <h2>Results-Driven Machine Learning Engineer</h2>
<p>Highly motivated and experienced Machine Learni...
2025-04-16 20:27:14,783 - ResumeServer - INFO - Building PDF document...
2025-04-16 20:27:14,795 - ResumeServer - INFO - PDF generation successful, size: 6228 bytes
2025-04-16 20:27:14,796 - ResumeServer - INFO - Resume generated successfully. PDF size: 6228 bytes
2025-04-16 20:27:14,796 - ResumeServer - DEBUG - Converting response to JSON
2025-04-16 20:27:14,797 - ResumeServer - DEBUG - Response headers set: application/json
2025-04-16 20:27:14,797 - ResumeServer - INFO - Successfully sent PDF response
2025-04-16 20:27:14,799 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpcwzv0w1f
2025-04-16 20:27:14,805 - ResumeServer - INFO - GET request for /history
2025-04-16 20:27:14,806 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:27:16,133 - ResumeServer - INFO - GET request for /download/undefined
2025-04-16 20:27:16,133 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:27:20,131 - ResumeServer - INFO - GET request for /download/undefined
2025-04-16 20:27:20,132 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:27:22,846 - ResumeServer - INFO - GET request for /download/undefined
2025-04-16 20:27:22,847 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:30:55,121 - ResumeServer - INFO - GET request for /
2025-04-16 20:30:55,121 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 20:30:55,123 - ResumeServer - INFO - Served index.html successfully
2025-04-16 20:30:55,147 - ResumeServer - INFO - GET request for /history
2025-04-16 20:30:55,148 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:31:09,878 - ResumeServer - INFO - POST request to /generate (Content-Length: 56870)
2025-04-16 20:31:09,879 - ResumeServer - INFO - Processing /generate request
2025-04-16 20:31:09,880 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpymolr2l_
2025-04-16 20:31:09,880 - ResumeServer - DEBUG - Parsing form data
2025-04-16 20:31:09,888 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 20:31:09,890 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=posting.txt
2025-04-16 20:31:09,891 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 20:31:09,894 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 20:31:09,895 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmpymolr2l_\template.txt
2025-04-16 20:31:09,896 - ResumeServer - INFO - Generating resume...
2025-04-16 20:31:09,899 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:31:09,902 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:31:09,907 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:31:09,909 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    class ResumeHandler(BaseHTTPRequestHandler):
                                   ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:31:09,911 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 20:31:11,913 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:31:11,914 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:31:11,915 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:31:11,916 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    class ResumeHandler(BaseHTTPRequestHandler):
                                   ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:31:11,917 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 20:31:13,919 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:31:13,920 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:31:13,921 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:31:13,923 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    class ResumeHandler(BaseHTTPRequestHandler):
                                   ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:31:13,925 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:31:13,926 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    try:
         
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    class ResumeHandler(BaseHTTPRequestHandler):
                                   ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:31:13,927 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:31:13,929 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpymolr2l_
2025-04-16 20:31:15,221 - ResumeServer - INFO - POST request to /generate (Content-Length: 56870)
2025-04-16 20:31:15,223 - ResumeServer - INFO - Processing /generate request
2025-04-16 20:31:15,223 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpwtzyzr58
2025-04-16 20:31:15,223 - ResumeServer - DEBUG - Parsing form data
2025-04-16 20:31:15,227 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 20:31:15,228 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=posting.txt
2025-04-16 20:31:15,228 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 20:31:15,229 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 20:31:15,230 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmpwtzyzr58\template.txt
2025-04-16 20:31:15,230 - ResumeServer - INFO - Generating resume...
2025-04-16 20:31:15,232 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:31:15,233 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:31:15,236 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:31:15,237 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    class ResumeHandler(BaseHTTPRequestHandler):
                                   ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:31:15,238 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 20:31:17,240 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:31:17,241 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:31:17,242 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:31:17,244 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    class ResumeHandler(BaseHTTPRequestHandler):
                                   ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:31:17,246 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 20:31:19,248 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:31:19,248 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:31:19,250 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:31:19,251 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    class ResumeHandler(BaseHTTPRequestHandler):
                                   ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:31:19,252 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:31:19,253 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
    try:
         
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    class ResumeHandler(BaseHTTPRequestHandler):
                                   ^^^^^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:31:19,255 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:31:19,257 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpwtzyzr58
2025-04-16 20:33:00,288 - ResumeServer - INFO - POST request to /generate (Content-Length: 9309)
2025-04-16 20:33:00,289 - ResumeServer - INFO - Processing /generate request
2025-04-16 20:33:00,290 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp37zwy56o
2025-04-16 20:33:00,290 - ResumeServer - DEBUG - Parsing form data
2025-04-16 20:33:00,294 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 20:33:00,295 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=posting.txt
2025-04-16 20:33:00,295 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 20:33:00,298 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 20:33:00,300 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmp37zwy56o\template.txt
2025-04-16 20:33:00,300 - ResumeServer - INFO - Generating resume...
2025-04-16 20:33:00,302 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:33:00,305 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:33:00,307 - ResumeServer - DEBUG - Template content length: 2198 chars
2025-04-16 20:33:00,308 - ResumeServer - INFO - Initializing Groq client...
2025-04-16 20:33:00,941 - ResumeServer - INFO - Preparing messages for AI request...
2025-04-16 20:33:00,942 - ResumeServer - DEBUG - Using template in prompt
2025-04-16 20:33:00,943 - ResumeServer - INFO - Sending request to Groq API...
2025-04-16 20:33:00,946 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Respond with 'test ok'"}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 10, 'stream': False}}
2025-04-16 20:33:00,946 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 20:33:00,948 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-04-16 20:33:01,068 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC15FBF20>
2025-04-16 20:33:01,070 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EFC15D64D0> server_hostname='api.groq.com' timeout=5.0
2025-04-16 20:33:01,131 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC15ECA40>
2025-04-16 20:33:01,132 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 20:33:01,132 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 20:33:01,133 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 20:33:01,134 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 20:33:01,135 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 20:33:01,477 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 15:03:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'931491288b36a92f-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'999'), (b'X-Ratelimit-Remaining-Tokens', b'11990'), (b'X-Ratelimit-Reset-Requests', b'1m26.4s'), (b'X-Ratelimit-Reset-Tokens', b'50ms'), (b'X-Request-Id', b'req_01jrzhzxejf50tkj2aym5qh6nr'), (b'Set-Cookie', b'__cf_bm=3BUwYfN6HMxoCbR7CcdKU2rt7Oo6AZ77zwVz4qhe1MQ-1744815781-1.0.1.1-lLEoGDI9DGmrOOnnddut.TmE34owi3Y85lj.7n0WMVNoVQtNJVCXKINJalLi2am0.BeDo_wvl2bvj3qelkHIYxtcgHla.ByTGpGsvr.qB28; path=/; expires=Wed, 16-Apr-25 15:33:01 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 20:33:01,480 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 20:33:01,480 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 20:33:01,480 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 20:33:01,481 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 20:33:01,481 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 20:33:01,481 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 15:03:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '931491288b36a92f-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '999', 'x-ratelimit-remaining-tokens': '11990', 'x-ratelimit-reset-requests': '1m26.4s', 'x-ratelimit-reset-tokens': '50ms', 'x-request-id': 'req_01jrzhzxejf50tkj2aym5qh6nr', 'set-cookie': '__cf_bm=3BUwYfN6HMxoCbR7CcdKU2rt7Oo6AZ77zwVz4qhe1MQ-1744815781-1.0.1.1-lLEoGDI9DGmrOOnnddut.TmE34owi3Y85lj.7n0WMVNoVQtNJVCXKINJalLi2am0.BeDo_wvl2bvj3qelkHIYxtcgHla.ByTGpGsvr.qB28; path=/; expires=Wed, 16-Apr-25 15:33:01 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 20:33:01,482 - ResumeServer - INFO - API test successful: test ok
2025-04-16 20:33:01,482 - ResumeServer - INFO - Creating streaming completion...
2025-04-16 20:33:01,484 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a resume assistant. Format your response with HTML tags for styling. Use <strong> for bold, <h2> for section headers, <ul> and <li> for lists. Provide ONLY the resume content, no analysis or insights. Start directly with the resume content.'}, {'role': 'user', 'content': 'Create a tailored resume based on this resume and job description, following this template structure. Format the response with HTML tags. Provide ONLY the resume content, no analysis or insights.\n\nResume:\n\nResults-driven Machine Learning Engineer with 4+ years of experience developing and deploying AI models for diverse applications, including computer vision, NLP, and predictive analytics. Skilled in Python, TensorFlow, and cloud platforms like GCP. Adept at translating complex data into actionable insights and thriving in collaborative, fast-paced environments.\n\nProfessional Experience\n\nMachine Learning Engineer\n\nNexGen Technologies, Austin, TX\n\nAugust 2021 – Present\n\nBuilt convolutional neural networks (CNNs) with TensorFlow for image classification, achieving 92% accuracy on a custom dataset for retail product recognition.\nDesigned and deployed NLP models using BERT and Hugging Face for automated customer support, reducing response times by 40%.\nImplemented MLOps pipelines with Kubeflow and GCP, automating model retraining and monitoring for production systems.\nPreprocessed terabyte-scale datasets with Apache Spark, optimizing data pipelines for faster model training.\nMentored junior engineers on best practices for model development and version control with Git.\nData Scientist\n\nInsight Analytics, San Francisco, CA (Remote)\n\nJune 2020 – July 2021\n\nDeveloped time-series forecasting models with PyTorch to predict inventory demand, improving supply chain efficiency by 20%.\nConducted exploratory data analysis with pandas and SQL, uncovering trends that informed marketing strategies.\nCreated interactive dashboards with Plotly and Tableau to visualize model outputs for executive stakeholders.\nCollaborated with software engineers to integrate ML models into web applications using Flask APIs.\nResearch Intern, AI Lab\n\nStanford University, Stanford, CA\n\nJanuary 2019 – May 2020\n\nContributed to research on reinforcement learning algorithms, co-authoring a paper presented at NeurIPS 2020.\nBuilt simulation environments with OpenAI Gym to test agent performance in dynamic scenarios.\nOptimized model training workflows, reducing compute costs by 15% through efficient resource allocation.\nEducation\n\nMaster of Science in Artificial Intelligence\n\nCarnegie Mellon University, Pittsburgh, PA\n\nGraduated: May 2020\n\nFocus: Deep Learning and Reinforcement Learning\nCapstone Project: “Scalable RL Models for Autonomous Navigation”\nBachelor of Science in Computer Science\n\nUniversity of Texas at Austin, Austin, TX\n\nGraduated: May 2018\n\nMinor in Applied Mathematics\nSkills\n\nProgramming: Python, C++, SQL, Bash\nML Frameworks: TensorFlow, PyTorch, scikit-learn, Hugging Face, OpenCV\nCloud Platforms: Google Cloud Platform (AI Platform, BigQuery), AWS, Azure\nTools: Docker, Jenkins, MLflow, Git, Jupyter, Tableau\nData Processing: pandas, NumPy, Spark, Dask\nDomains: Computer Vision, NLP, Reinforcement Learning, Time-Series Analysis\nProjects\n\nAutonomous Drone Navigation (GitHub: github.com/alexcarter/drone-ai)\nDeveloped a reinforcement learning model with PyTorch to train drones for obstacle avoidance, tested in simulated environments.\nText Summarization Tool\nBuilt an NLP pipeline with Hugging Face transformers to generate concise summaries of news articles, deployed as a web app with Streamlit.\nFacial Recognition System\nCreated a real-time face detection model using OpenCV and TensorFlow, achieving 95% accuracy on public datasets.\nCertifications\n\nGoogle Cloud Professional Machine Learning Engineer (2023)\nCoursera: Deep Learning Specialization by Andrew Ng (2020)\nPublications & Talks\n\nCo-author, “Advances in Scalable Reinforcement Learning for Robotics,” NeurIPS 2020.\nGuest Speaker, “MLOps for Beginners,” Austin AI Meetup, March 2023.\nAdditional Information\n\nActive contributor to PyTorch (3 pull requests merged).\nVolunteer mentor at Code2AI, teaching high school students ML basics.\nProficient in French; conversational in Japanese.\n\nJob Description:\n\nJob Title: Machine Learning Engineer\n\nCompany: InnovateAI Solutions\n\nLocation: Remote (US-based preferred)\n\nPosted: April 15, 2025\n\nEmployment Type: Full-Time\n\nAbout InnovateAI Solutions:\n\nInnovateAI Solutions is a fast-growing tech company specializing in cutting-edge AI-driven products for healthcare and finance. Our mission is to empower businesses with intelligent solutions that transform industries.\n\nJob Description:\n\nWe are seeking a talented Machine Learning Engineer to join our AI Development team. You will design, develop, and deploy machine learning models to solve complex problems in predictive analytics and natural language processing. This role offers the opportunity to work on impactful projects with a collaborative, innovative team.\n\nKey Responsibilities:\n\nDevelop and optimize machine learning models for tasks such as classification, regression, and NLP.\nCollaborate with data scientists and software engineers to integrate models into production systems.\nConduct experiments to evaluate model performance and iterate on improvements.\nPreprocess and analyze large datasets to extract meaningful insights.\nStay updated on the latest AI/ML research and apply relevant advancements to projects.\nDocument processes and communicate findings to technical and non-technical stakeholders.\nQualifications:\n\nBachelor’s or Master’s degree in Computer Science, Data Science, or a related field.\n3+ years of experience building and deploying machine learning models.\nProficiency in Python and libraries such as TensorFlow, PyTorch, or scikit-learn.\nExperience with cloud platforms (e.g., AWS, Azure, or GCP) for model deployment.\nStrong understanding of algorithms, data structures, and statistics.\nFamiliarity with NLP techniques and tools (e.g., Hugging Face, spaCy) is a plus.\nExcellent problem-solving skills and ability to work in a fast-paced environment.\nPreferred Skills:\n\nExperience with MLOps tools (e.g., Kubeflow, MLflow).\nKnowledge of big data frameworks (e.g., Spark, Hadoop).\nContributions to open-source AI/ML projects or publications in relevant fields.\nBenefits:\n\nCompetitive salary and equity options.\nComprehensive health, dental, and vision insurance.\nFlexible work-from-home policy.\nAnnual learning stipend for professional development.\nCollaborative and inclusive team culture.\nHow to Apply:\n\nPlease submit your resume and a cover letter to careers@innovateai.com. Include links to your GitHub, LinkedIn, or portfolio if applicable. Applications will be reviewed on a rolling basis.\n\nInnovateAI Solutions is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.\n\nTemplate:\n\nJanna Gardner\n4567 Main Street, Chicago, Illinois 98052 • (716) 555-0100 • janna@example.com\n\nHuman Resources Generalist with 6+ years of experience assisting with and fulfilling organization staffing needs and requirements. A proven track record of using my excellent personal, communication and organization skills to lead and improve HR departments, recruit excellent personnel, and improve department efficiencies. Team player with excellent communication skills, high quality of work, driven and highly self-motivated. Strong negotiating skills and business acumen and able to work independently.\nExperience\n20XX – PRESENT\nHuman Resources Generalist | Lamna Healthcare Company | Chicago, Illinois\nReview, update, and revise company hiring practices, vacation, and other human resources policies to ensure compliance with OSHA and all local, state, and federal labor regulations. By creating and maintaining a positive and responsive work environment, we raised employee retention rates by over 10% to achieve a greater than 90% employee retention over a 2-year period. Developed recruitment programs to successfully increase minority recruitment and meet affirmative action requirements. Led development team to build and deploy a dedicated recruitment website which reduced year-over-year recruitment costs by 14%.\nJUNE 20XX – AUGUST 20XX\nHuman Resources Intern | Wholeness Healthcare | Boomtown, Ohio\nAssisted in recruitment outreach to prospective employees. Organized and conducted several seminars for hospital employees to educate and update them regarding available employment benefit options. Arranged hospital-wide guest speakers symposia to educate management about new employment laws and workplace confidence and morale building techniques. Administrative tasks.\nSkills\nType 96 words per minute • Proficient with project management software • Team player • Excellent time management skills • Conflict management • Public speaking • Data analytics \nEducation\nMAY 20XX\nBachelor of Arts Human Resources Management | Jasper University | Ft. Lauderdale, FL\n3.8 GPA • Member of university’s Honor Society\nActivities\nLiterature • Environmental conservation • Art • Yoga • Skiing • Travel\n'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2048, 'stream': True, 'temperature': 0.1, 'top_p': 1}}
2025-04-16 20:33:01,491 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 20:33:01,493 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 20:33:01,494 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 20:33:01,494 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 20:33:01,495 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 20:33:01,495 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 20:33:01,709 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 15:03:01 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'9314912aed38a92f-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'no-cache'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'998'), (b'X-Ratelimit-Remaining-Tokens', b'9694'), (b'X-Ratelimit-Reset-Requests', b'2m52.535s'), (b'X-Ratelimit-Reset-Tokens', b'11.53s'), (b'X-Request-Id', b'req_01jrzhzxrxfkkszcvrwjx9ckcj'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 20:33:01,711 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 20:33:01,711 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 15:03:01 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9314912aed38a92f-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'no-cache', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '998', 'x-ratelimit-remaining-tokens': '9694', 'x-ratelimit-reset-requests': '2m52.535s', 'x-ratelimit-reset-tokens': '11.53s', 'x-request-id': 'req_01jrzhzxrxfkkszcvrwjx9ckcj', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 20:33:01,713 - ResumeServer - INFO - Collecting response chunks...
2025-04-16 20:33:01,714 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 20:33:01,855 - ResumeServer - DEBUG - Received 10 chunks, response length: 44
2025-04-16 20:33:01,919 - ResumeServer - DEBUG - Received 20 chunks, response length: 77
2025-04-16 20:33:01,932 - ResumeServer - DEBUG - Received 30 chunks, response length: 110
2025-04-16 20:33:01,969 - ResumeServer - DEBUG - Received 40 chunks, response length: 129
2025-04-16 20:33:01,983 - ResumeServer - DEBUG - Received 50 chunks, response length: 158
2025-04-16 20:33:01,994 - ResumeServer - DEBUG - Received 60 chunks, response length: 197
2025-04-16 20:33:02,032 - ResumeServer - DEBUG - Received 70 chunks, response length: 248
2025-04-16 20:33:02,041 - ResumeServer - DEBUG - Received 80 chunks, response length: 315
2025-04-16 20:33:02,063 - ResumeServer - DEBUG - Received 90 chunks, response length: 365
2025-04-16 20:33:02,074 - ResumeServer - DEBUG - Received 100 chunks, response length: 418
2025-04-16 20:33:02,115 - ResumeServer - DEBUG - Received 110 chunks, response length: 457
2025-04-16 20:33:02,122 - ResumeServer - DEBUG - Received 120 chunks, response length: 537
2025-04-16 20:33:02,140 - ResumeServer - DEBUG - Received 130 chunks, response length: 581
2025-04-16 20:33:02,157 - ResumeServer - DEBUG - Received 140 chunks, response length: 607
2025-04-16 20:33:02,179 - ResumeServer - DEBUG - Received 150 chunks, response length: 655
2025-04-16 20:33:02,218 - ResumeServer - DEBUG - Received 160 chunks, response length: 691
2025-04-16 20:33:02,242 - ResumeServer - DEBUG - Received 170 chunks, response length: 736
2025-04-16 20:33:02,248 - ResumeServer - DEBUG - Received 180 chunks, response length: 791
2025-04-16 20:33:02,272 - ResumeServer - DEBUG - Received 190 chunks, response length: 842
2025-04-16 20:33:02,305 - ResumeServer - DEBUG - Received 200 chunks, response length: 879
2025-04-16 20:33:02,307 - ResumeServer - DEBUG - Received 210 chunks, response length: 922
2025-04-16 20:33:02,317 - ResumeServer - DEBUG - Received 220 chunks, response length: 986
2025-04-16 20:33:02,327 - ResumeServer - DEBUG - Received 230 chunks, response length: 1003
2025-04-16 20:33:02,347 - ResumeServer - DEBUG - Received 240 chunks, response length: 1048
2025-04-16 20:33:02,365 - ResumeServer - DEBUG - Received 250 chunks, response length: 1096
2025-04-16 20:33:02,369 - ResumeServer - DEBUG - Received 260 chunks, response length: 1132
2025-04-16 20:33:02,385 - ResumeServer - DEBUG - Received 270 chunks, response length: 1187
2025-04-16 20:33:02,390 - ResumeServer - DEBUG - Received 280 chunks, response length: 1246
2025-04-16 20:33:02,414 - ResumeServer - DEBUG - Received 290 chunks, response length: 1285
2025-04-16 20:33:02,429 - ResumeServer - DEBUG - Received 300 chunks, response length: 1349
2025-04-16 20:33:02,443 - ResumeServer - DEBUG - Received 310 chunks, response length: 1371
2025-04-16 20:33:02,457 - ResumeServer - DEBUG - Received 320 chunks, response length: 1412
2025-04-16 20:33:02,482 - ResumeServer - DEBUG - Received 330 chunks, response length: 1455
2025-04-16 20:33:02,494 - ResumeServer - DEBUG - Received 340 chunks, response length: 1483
2025-04-16 20:33:02,507 - ResumeServer - DEBUG - Received 350 chunks, response length: 1538
2025-04-16 20:33:02,522 - ResumeServer - DEBUG - Received 360 chunks, response length: 1596
2025-04-16 20:33:02,532 - ResumeServer - DEBUG - Received 370 chunks, response length: 1619
2025-04-16 20:33:02,547 - ResumeServer - DEBUG - Received 380 chunks, response length: 1674
2025-04-16 20:33:02,562 - ResumeServer - DEBUG - Received 390 chunks, response length: 1727
2025-04-16 20:33:02,602 - ResumeServer - DEBUG - Received 400 chunks, response length: 1774
2025-04-16 20:33:02,608 - ResumeServer - DEBUG - Received 410 chunks, response length: 1840
2025-04-16 20:33:02,620 - ResumeServer - DEBUG - Received 420 chunks, response length: 1865
2025-04-16 20:33:02,647 - ResumeServer - DEBUG - Received 430 chunks, response length: 1934
2025-04-16 20:33:02,656 - ResumeServer - DEBUG - Received 440 chunks, response length: 1972
2025-04-16 20:33:02,678 - ResumeServer - DEBUG - Received 450 chunks, response length: 1996
2025-04-16 20:33:02,684 - ResumeServer - DEBUG - Received 460 chunks, response length: 2031
2025-04-16 20:33:02,709 - ResumeServer - DEBUG - Received 470 chunks, response length: 2073
2025-04-16 20:33:02,717 - ResumeServer - DEBUG - Received 480 chunks, response length: 2127
2025-04-16 20:33:02,733 - ResumeServer - DEBUG - Received 490 chunks, response length: 2176
2025-04-16 20:33:02,744 - ResumeServer - DEBUG - Received 500 chunks, response length: 2196
2025-04-16 20:33:02,757 - ResumeServer - DEBUG - Received 510 chunks, response length: 2247
2025-04-16 20:33:02,774 - ResumeServer - DEBUG - Received 520 chunks, response length: 2299
2025-04-16 20:33:02,807 - ResumeServer - DEBUG - Received 530 chunks, response length: 2348
2025-04-16 20:33:02,810 - ResumeServer - DEBUG - Received 540 chunks, response length: 2407
2025-04-16 20:33:02,813 - ResumeServer - DEBUG - Received 550 chunks, response length: 2434
2025-04-16 20:33:02,831 - ResumeServer - DEBUG - Received 560 chunks, response length: 2456
2025-04-16 20:33:02,849 - ResumeServer - DEBUG - Received 570 chunks, response length: 2510
2025-04-16 20:33:02,862 - ResumeServer - DEBUG - Received 580 chunks, response length: 2560
2025-04-16 20:33:02,916 - ResumeServer - DEBUG - Received 590 chunks, response length: 2592
2025-04-16 20:33:02,926 - ResumeServer - DEBUG - Received 600 chunks, response length: 2627
2025-04-16 20:33:02,966 - ResumeServer - DEBUG - Received 610 chunks, response length: 2664
2025-04-16 20:33:02,996 - ResumeServer - DEBUG - Received 620 chunks, response length: 2704
2025-04-16 20:33:03,030 - ResumeServer - DEBUG - Received 630 chunks, response length: 2740
2025-04-16 20:33:03,044 - ResumeServer - DEBUG - Received 640 chunks, response length: 2791
2025-04-16 20:33:03,058 - ResumeServer - DEBUG - Received 650 chunks, response length: 2821
2025-04-16 20:33:03,092 - ResumeServer - DEBUG - Received 660 chunks, response length: 2860
2025-04-16 20:33:03,110 - ResumeServer - DEBUG - Received 670 chunks, response length: 2881
2025-04-16 20:33:03,137 - ResumeServer - DEBUG - Received 680 chunks, response length: 2913
2025-04-16 20:33:03,182 - ResumeServer - DEBUG - Received 690 chunks, response length: 2936
2025-04-16 20:33:03,191 - ResumeServer - DEBUG - Received 700 chunks, response length: 2970
2025-04-16 20:33:03,222 - ResumeServer - DEBUG - Received 710 chunks, response length: 2998
2025-04-16 20:33:03,252 - ResumeServer - DEBUG - Received 720 chunks, response length: 3022
2025-04-16 20:33:03,296 - ResumeServer - DEBUG - Received 730 chunks, response length: 3074
2025-04-16 20:33:03,343 - ResumeServer - DEBUG - Received 740 chunks, response length: 3103
2025-04-16 20:33:03,381 - ResumeServer - DEBUG - Received 750 chunks, response length: 3132
2025-04-16 20:33:03,439 - ResumeServer - DEBUG - Received 760 chunks, response length: 3162
2025-04-16 20:33:03,461 - ResumeServer - DEBUG - Received 770 chunks, response length: 3197
2025-04-16 20:33:03,503 - ResumeServer - DEBUG - Received 780 chunks, response length: 3221
2025-04-16 20:33:03,514 - ResumeServer - DEBUG - Received 790 chunks, response length: 3254
2025-04-16 20:33:03,569 - ResumeServer - DEBUG - Received 800 chunks, response length: 3304
2025-04-16 20:33:03,587 - ResumeServer - DEBUG - Received 810 chunks, response length: 3329
2025-04-16 20:33:03,606 - ResumeServer - DEBUG - Received 820 chunks, response length: 3347
2025-04-16 20:33:03,645 - ResumeServer - DEBUG - Received 830 chunks, response length: 3379
2025-04-16 20:33:03,678 - ResumeServer - DEBUG - Received 840 chunks, response length: 3422
2025-04-16 20:33:03,727 - ResumeServer - DEBUG - Received 850 chunks, response length: 3450
2025-04-16 20:33:03,738 - ResumeServer - DEBUG - Received 860 chunks, response length: 3474
2025-04-16 20:33:03,780 - ResumeServer - DEBUG - Received 870 chunks, response length: 3506
2025-04-16 20:33:03,812 - ResumeServer - DEBUG - Received 880 chunks, response length: 3541
2025-04-16 20:33:03,829 - ResumeServer - DEBUG - Received 890 chunks, response length: 3570
2025-04-16 20:33:03,833 - ResumeServer - DEBUG - Received 900 chunks, response length: 3587
2025-04-16 20:33:03,880 - ResumeServer - DEBUG - Received 910 chunks, response length: 3647
2025-04-16 20:33:03,903 - ResumeServer - DEBUG - Received 920 chunks, response length: 3666
2025-04-16 20:33:03,945 - ResumeServer - DEBUG - Received 930 chunks, response length: 3714
2025-04-16 20:33:03,966 - ResumeServer - DEBUG - Received 940 chunks, response length: 3738
2025-04-16 20:33:03,996 - ResumeServer - DEBUG - Received 950 chunks, response length: 3764
2025-04-16 20:33:04,046 - ResumeServer - DEBUG - Received 960 chunks, response length: 3792
2025-04-16 20:33:04,115 - ResumeServer - DEBUG - Received 970 chunks, response length: 3844
2025-04-16 20:33:04,118 - ResumeServer - DEBUG - Received 980 chunks, response length: 3864
2025-04-16 20:33:04,149 - ResumeServer - DEBUG - Received 990 chunks, response length: 3900
2025-04-16 20:33:04,206 - ResumeServer - DEBUG - Received 1000 chunks, response length: 3931
2025-04-16 20:33:04,234 - ResumeServer - DEBUG - Received 1010 chunks, response length: 3959
2025-04-16 20:33:04,249 - ResumeServer - DEBUG - Received 1020 chunks, response length: 3987
2025-04-16 20:33:04,305 - ResumeServer - DEBUG - Received 1030 chunks, response length: 4025
2025-04-16 20:33:04,328 - ResumeServer - DEBUG - Received 1040 chunks, response length: 4058
2025-04-16 20:33:04,421 - ResumeServer - DEBUG - Received 1050 chunks, response length: 4104
2025-04-16 20:33:04,443 - ResumeServer - DEBUG - Received 1060 chunks, response length: 4136
2025-04-16 20:33:04,505 - ResumeServer - DEBUG - Received 1070 chunks, response length: 4187
2025-04-16 20:33:05,810 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 20:33:05,811 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 20:33:05,812 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 20:33:05,812 - ResumeServer - INFO - Response collection complete. Total 1076 chunks, final length: 4196
2025-04-16 20:33:05,812 - ResumeServer - INFO - Response preview: <h2>Results-Driven Machine Learning Engineer</h2>
<strong>Alex Carter</strong>
123 Main Street, Aust...
2025-04-16 20:33:05,817 - ResumeServer - INFO - Building PDF document...
2025-04-16 20:33:05,832 - ResumeServer - INFO - PDF generation successful, size: 6110 bytes
2025-04-16 20:33:05,832 - ResumeServer - INFO - Resume generated successfully. PDF size: 6110 bytes
2025-04-16 20:33:05,832 - ResumeServer - DEBUG - Converting response to JSON
2025-04-16 20:33:05,834 - ResumeServer - DEBUG - Response headers set: application/json
2025-04-16 20:33:05,834 - ResumeServer - INFO - Successfully sent PDF response
2025-04-16 20:33:05,836 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmp37zwy56o
2025-04-16 20:33:05,843 - ResumeServer - INFO - GET request for /history
2025-04-16 20:33:05,844 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:33:07,159 - ResumeServer - INFO - GET request for /download/undefined
2025-04-16 20:33:07,160 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:33:12,869 - ResumeServer - INFO - GET request for /download/undefined
2025-04-16 20:33:12,870 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:33:14,844 - ResumeServer - INFO - GET request for /download/undefined
2025-04-16 20:33:14,845 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:38:54,394 - ResumeServer - INFO - Server running on http://localhost:8000
2025-04-16 20:39:00,959 - ResumeServer - INFO - GET request for /download/undefined
2025-04-16 20:39:00,960 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:39:02,842 - ResumeServer - INFO - GET request for /download/undefined
2025-04-16 20:39:02,844 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:39:03,443 - ResumeServer - INFO - GET request for /
2025-04-16 20:39:03,444 - ResumeServer - DEBUG - Response headers set: text/html
2025-04-16 20:39:03,445 - ResumeServer - INFO - Served index.html successfully
2025-04-16 20:39:03,759 - ResumeServer - INFO - GET request for /history
2025-04-16 20:39:03,761 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:39:38,938 - ResumeServer - INFO - POST request to /generate (Content-Length: 9309)
2025-04-16 20:39:38,939 - ResumeServer - INFO - Processing /generate request
2025-04-16 20:39:38,940 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpoy6n8ahb
2025-04-16 20:39:38,941 - ResumeServer - DEBUG - Parsing form data
2025-04-16 20:39:38,945 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 20:39:38,946 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=posting.txt
2025-04-16 20:39:38,947 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 20:39:38,950 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 20:39:38,952 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmpoy6n8ahb\template.txt
2025-04-16 20:39:38,952 - ResumeServer - INFO - Generating resume...
2025-04-16 20:39:38,956 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:39:38,959 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:39:38,963 - ResumeServer - DEBUG - Template content length: 2198 chars
2025-04-16 20:39:38,964 - ResumeServer - INFO - Initializing Groq client...
2025-04-16 20:39:39,820 - ResumeServer - INFO - Preparing messages for AI request...
2025-04-16 20:39:39,821 - ResumeServer - DEBUG - Using template in prompt
2025-04-16 20:39:39,821 - ResumeServer - INFO - Sending request to Groq API...
2025-04-16 20:39:39,825 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Respond with 'test ok'"}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 10, 'stream': False}}
2025-04-16 20:39:39,827 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 20:39:39,828 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-04-16 20:39:39,963 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC1603DD0>
2025-04-16 20:39:39,964 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EFC13E8AD0> server_hostname='api.groq.com' timeout=5.0
2025-04-16 20:39:40,021 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC1603C80>
2025-04-16 20:39:40,022 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 20:39:40,023 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 20:39:40,024 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 20:39:40,024 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 20:39:40,025 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 20:39:40,179 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 15:09:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'93149ae599c3ad28-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'999'), (b'X-Ratelimit-Remaining-Tokens', b'11990'), (b'X-Ratelimit-Reset-Requests', b'1m26.4s'), (b'X-Ratelimit-Reset-Tokens', b'50ms'), (b'X-Request-Id', b'req_01jrzjc2wzfgva3g2wkenxqwgt'), (b'Set-Cookie', b'__cf_bm=BlOeo7_3JSvsCgnTbw2FnWYH31WMfq2Tfn67hI8f2.s-1744816180-1.0.1.1-6XL65Wa0sirA08UNJRXtrnZXefwM2DJcjj71qBUW8Ja_lhtftt_1btskT0cylI38CHjbKEogkfShIM6E5EGoHh0kK03TnfDgwJFTdxFwgio; path=/; expires=Wed, 16-Apr-25 15:39:40 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 20:39:40,181 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 20:39:40,182 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 20:39:40,183 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 20:39:40,183 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 20:39:40,185 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 20:39:40,186 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 15:09:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '93149ae599c3ad28-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '999', 'x-ratelimit-remaining-tokens': '11990', 'x-ratelimit-reset-requests': '1m26.4s', 'x-ratelimit-reset-tokens': '50ms', 'x-request-id': 'req_01jrzjc2wzfgva3g2wkenxqwgt', 'set-cookie': '__cf_bm=BlOeo7_3JSvsCgnTbw2FnWYH31WMfq2Tfn67hI8f2.s-1744816180-1.0.1.1-6XL65Wa0sirA08UNJRXtrnZXefwM2DJcjj71qBUW8Ja_lhtftt_1btskT0cylI38CHjbKEogkfShIM6E5EGoHh0kK03TnfDgwJFTdxFwgio; path=/; expires=Wed, 16-Apr-25 15:39:40 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 20:39:40,189 - ResumeServer - INFO - API test successful: test ok
2025-04-16 20:39:40,189 - ResumeServer - INFO - Creating streaming completion...
2025-04-16 20:39:40,192 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a resume assistant. Format your response with HTML tags for styling. Use <strong> for bold, <h2> for section headers, <ul> and <li> for lists. Provide ONLY the resume content, no analysis or insights. Start directly with the resume content.'}, {'role': 'user', 'content': 'Create a tailored resume based on this resume and job description, following this template structure. Format the response with HTML tags. Provide ONLY the resume content, no analysis or insights.\n\nResume:\n\nResults-driven Machine Learning Engineer with 4+ years of experience developing and deploying AI models for diverse applications, including computer vision, NLP, and predictive analytics. Skilled in Python, TensorFlow, and cloud platforms like GCP. Adept at translating complex data into actionable insights and thriving in collaborative, fast-paced environments.\n\nProfessional Experience\n\nMachine Learning Engineer\n\nNexGen Technologies, Austin, TX\n\nAugust 2021 – Present\n\nBuilt convolutional neural networks (CNNs) with TensorFlow for image classification, achieving 92% accuracy on a custom dataset for retail product recognition.\nDesigned and deployed NLP models using BERT and Hugging Face for automated customer support, reducing response times by 40%.\nImplemented MLOps pipelines with Kubeflow and GCP, automating model retraining and monitoring for production systems.\nPreprocessed terabyte-scale datasets with Apache Spark, optimizing data pipelines for faster model training.\nMentored junior engineers on best practices for model development and version control with Git.\nData Scientist\n\nInsight Analytics, San Francisco, CA (Remote)\n\nJune 2020 – July 2021\n\nDeveloped time-series forecasting models with PyTorch to predict inventory demand, improving supply chain efficiency by 20%.\nConducted exploratory data analysis with pandas and SQL, uncovering trends that informed marketing strategies.\nCreated interactive dashboards with Plotly and Tableau to visualize model outputs for executive stakeholders.\nCollaborated with software engineers to integrate ML models into web applications using Flask APIs.\nResearch Intern, AI Lab\n\nStanford University, Stanford, CA\n\nJanuary 2019 – May 2020\n\nContributed to research on reinforcement learning algorithms, co-authoring a paper presented at NeurIPS 2020.\nBuilt simulation environments with OpenAI Gym to test agent performance in dynamic scenarios.\nOptimized model training workflows, reducing compute costs by 15% through efficient resource allocation.\nEducation\n\nMaster of Science in Artificial Intelligence\n\nCarnegie Mellon University, Pittsburgh, PA\n\nGraduated: May 2020\n\nFocus: Deep Learning and Reinforcement Learning\nCapstone Project: “Scalable RL Models for Autonomous Navigation”\nBachelor of Science in Computer Science\n\nUniversity of Texas at Austin, Austin, TX\n\nGraduated: May 2018\n\nMinor in Applied Mathematics\nSkills\n\nProgramming: Python, C++, SQL, Bash\nML Frameworks: TensorFlow, PyTorch, scikit-learn, Hugging Face, OpenCV\nCloud Platforms: Google Cloud Platform (AI Platform, BigQuery), AWS, Azure\nTools: Docker, Jenkins, MLflow, Git, Jupyter, Tableau\nData Processing: pandas, NumPy, Spark, Dask\nDomains: Computer Vision, NLP, Reinforcement Learning, Time-Series Analysis\nProjects\n\nAutonomous Drone Navigation (GitHub: github.com/alexcarter/drone-ai)\nDeveloped a reinforcement learning model with PyTorch to train drones for obstacle avoidance, tested in simulated environments.\nText Summarization Tool\nBuilt an NLP pipeline with Hugging Face transformers to generate concise summaries of news articles, deployed as a web app with Streamlit.\nFacial Recognition System\nCreated a real-time face detection model using OpenCV and TensorFlow, achieving 95% accuracy on public datasets.\nCertifications\n\nGoogle Cloud Professional Machine Learning Engineer (2023)\nCoursera: Deep Learning Specialization by Andrew Ng (2020)\nPublications & Talks\n\nCo-author, “Advances in Scalable Reinforcement Learning for Robotics,” NeurIPS 2020.\nGuest Speaker, “MLOps for Beginners,” Austin AI Meetup, March 2023.\nAdditional Information\n\nActive contributor to PyTorch (3 pull requests merged).\nVolunteer mentor at Code2AI, teaching high school students ML basics.\nProficient in French; conversational in Japanese.\n\nJob Description:\n\nJob Title: Machine Learning Engineer\n\nCompany: InnovateAI Solutions\n\nLocation: Remote (US-based preferred)\n\nPosted: April 15, 2025\n\nEmployment Type: Full-Time\n\nAbout InnovateAI Solutions:\n\nInnovateAI Solutions is a fast-growing tech company specializing in cutting-edge AI-driven products for healthcare and finance. Our mission is to empower businesses with intelligent solutions that transform industries.\n\nJob Description:\n\nWe are seeking a talented Machine Learning Engineer to join our AI Development team. You will design, develop, and deploy machine learning models to solve complex problems in predictive analytics and natural language processing. This role offers the opportunity to work on impactful projects with a collaborative, innovative team.\n\nKey Responsibilities:\n\nDevelop and optimize machine learning models for tasks such as classification, regression, and NLP.\nCollaborate with data scientists and software engineers to integrate models into production systems.\nConduct experiments to evaluate model performance and iterate on improvements.\nPreprocess and analyze large datasets to extract meaningful insights.\nStay updated on the latest AI/ML research and apply relevant advancements to projects.\nDocument processes and communicate findings to technical and non-technical stakeholders.\nQualifications:\n\nBachelor’s or Master’s degree in Computer Science, Data Science, or a related field.\n3+ years of experience building and deploying machine learning models.\nProficiency in Python and libraries such as TensorFlow, PyTorch, or scikit-learn.\nExperience with cloud platforms (e.g., AWS, Azure, or GCP) for model deployment.\nStrong understanding of algorithms, data structures, and statistics.\nFamiliarity with NLP techniques and tools (e.g., Hugging Face, spaCy) is a plus.\nExcellent problem-solving skills and ability to work in a fast-paced environment.\nPreferred Skills:\n\nExperience with MLOps tools (e.g., Kubeflow, MLflow).\nKnowledge of big data frameworks (e.g., Spark, Hadoop).\nContributions to open-source AI/ML projects or publications in relevant fields.\nBenefits:\n\nCompetitive salary and equity options.\nComprehensive health, dental, and vision insurance.\nFlexible work-from-home policy.\nAnnual learning stipend for professional development.\nCollaborative and inclusive team culture.\nHow to Apply:\n\nPlease submit your resume and a cover letter to careers@innovateai.com. Include links to your GitHub, LinkedIn, or portfolio if applicable. Applications will be reviewed on a rolling basis.\n\nInnovateAI Solutions is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.\n\nTemplate:\n\nJanna Gardner\n4567 Main Street, Chicago, Illinois 98052 • (716) 555-0100 • janna@example.com\n\nHuman Resources Generalist with 6+ years of experience assisting with and fulfilling organization staffing needs and requirements. A proven track record of using my excellent personal, communication and organization skills to lead and improve HR departments, recruit excellent personnel, and improve department efficiencies. Team player with excellent communication skills, high quality of work, driven and highly self-motivated. Strong negotiating skills and business acumen and able to work independently.\nExperience\n20XX – PRESENT\nHuman Resources Generalist | Lamna Healthcare Company | Chicago, Illinois\nReview, update, and revise company hiring practices, vacation, and other human resources policies to ensure compliance with OSHA and all local, state, and federal labor regulations. By creating and maintaining a positive and responsive work environment, we raised employee retention rates by over 10% to achieve a greater than 90% employee retention over a 2-year period. Developed recruitment programs to successfully increase minority recruitment and meet affirmative action requirements. Led development team to build and deploy a dedicated recruitment website which reduced year-over-year recruitment costs by 14%.\nJUNE 20XX – AUGUST 20XX\nHuman Resources Intern | Wholeness Healthcare | Boomtown, Ohio\nAssisted in recruitment outreach to prospective employees. Organized and conducted several seminars for hospital employees to educate and update them regarding available employment benefit options. Arranged hospital-wide guest speakers symposia to educate management about new employment laws and workplace confidence and morale building techniques. Administrative tasks.\nSkills\nType 96 words per minute • Proficient with project management software • Team player • Excellent time management skills • Conflict management • Public speaking • Data analytics \nEducation\nMAY 20XX\nBachelor of Arts Human Resources Management | Jasper University | Ft. Lauderdale, FL\n3.8 GPA • Member of university’s Honor Society\nActivities\nLiterature • Environmental conservation • Art • Yoga • Skiing • Travel\n'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2048, 'stream': True, 'temperature': 0.1, 'top_p': 1}}
2025-04-16 20:39:40,205 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 20:39:40,206 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 20:39:40,207 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 20:39:40,208 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 20:39:40,209 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 20:39:40,209 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 20:39:40,396 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 15:09:40 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'93149ae6cc2bad28-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'no-cache'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'998'), (b'X-Ratelimit-Remaining-Tokens', b'9682'), (b'X-Ratelimit-Reset-Requests', b'2m52.591s'), (b'X-Ratelimit-Reset-Tokens', b'11.586999999s'), (b'X-Request-Id', b'req_01jrzjc33gf2kvezjgn70f169c'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 20:39:40,399 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 20:39:40,400 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 15:09:40 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '93149ae6cc2bad28-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'no-cache', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '998', 'x-ratelimit-remaining-tokens': '9682', 'x-ratelimit-reset-requests': '2m52.591s', 'x-ratelimit-reset-tokens': '11.586999999s', 'x-request-id': 'req_01jrzjc33gf2kvezjgn70f169c', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 20:39:40,402 - ResumeServer - INFO - Collecting response chunks...
2025-04-16 20:39:40,402 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 20:39:40,589 - ResumeServer - DEBUG - Received 10 chunks, response length: 46
2025-04-16 20:39:40,597 - ResumeServer - DEBUG - Received 20 chunks, response length: 82
2025-04-16 20:39:40,644 - ResumeServer - DEBUG - Received 30 chunks, response length: 118
2025-04-16 20:39:40,649 - ResumeServer - DEBUG - Received 40 chunks, response length: 142
2025-04-16 20:39:40,655 - ResumeServer - DEBUG - Received 50 chunks, response length: 185
2025-04-16 20:39:40,694 - ResumeServer - DEBUG - Received 60 chunks, response length: 230
2025-04-16 20:39:40,728 - ResumeServer - DEBUG - Received 70 chunks, response length: 261
2025-04-16 20:39:40,758 - ResumeServer - DEBUG - Received 80 chunks, response length: 298
2025-04-16 20:39:40,775 - ResumeServer - DEBUG - Received 90 chunks, response length: 324
2025-04-16 20:39:40,787 - ResumeServer - DEBUG - Received 100 chunks, response length: 374
2025-04-16 20:39:40,799 - ResumeServer - DEBUG - Received 110 chunks, response length: 434
2025-04-16 20:39:40,808 - ResumeServer - DEBUG - Received 120 chunks, response length: 488
2025-04-16 20:39:40,835 - ResumeServer - DEBUG - Received 130 chunks, response length: 544
2025-04-16 20:39:40,841 - ResumeServer - DEBUG - Received 140 chunks, response length: 581
2025-04-16 20:39:40,852 - ResumeServer - DEBUG - Received 150 chunks, response length: 650
2025-04-16 20:39:40,868 - ResumeServer - DEBUG - Received 160 chunks, response length: 708
2025-04-16 20:39:40,888 - ResumeServer - DEBUG - Received 170 chunks, response length: 755
2025-04-16 20:39:40,922 - ResumeServer - DEBUG - Received 180 chunks, response length: 795
2025-04-16 20:39:40,942 - ResumeServer - DEBUG - Received 190 chunks, response length: 819
2025-04-16 20:39:40,961 - ResumeServer - DEBUG - Received 200 chunks, response length: 865
2025-04-16 20:39:40,982 - ResumeServer - DEBUG - Received 210 chunks, response length: 925
2025-04-16 20:39:40,990 - ResumeServer - DEBUG - Received 220 chunks, response length: 981
2025-04-16 20:39:41,002 - ResumeServer - DEBUG - Received 230 chunks, response length: 1014
2025-04-16 20:39:41,018 - ResumeServer - DEBUG - Received 240 chunks, response length: 1063
2025-04-16 20:39:41,032 - ResumeServer - DEBUG - Received 250 chunks, response length: 1112
2025-04-16 20:39:41,043 - ResumeServer - DEBUG - Received 260 chunks, response length: 1140
2025-04-16 20:39:41,061 - ResumeServer - DEBUG - Received 270 chunks, response length: 1175
2025-04-16 20:39:41,075 - ResumeServer - DEBUG - Received 280 chunks, response length: 1241
2025-04-16 20:39:41,090 - ResumeServer - DEBUG - Received 290 chunks, response length: 1270
2025-04-16 20:39:41,103 - ResumeServer - DEBUG - Received 300 chunks, response length: 1335
2025-04-16 20:39:41,115 - ResumeServer - DEBUG - Received 310 chunks, response length: 1373
2025-04-16 20:39:41,139 - ResumeServer - DEBUG - Received 320 chunks, response length: 1427
2025-04-16 20:39:41,149 - ResumeServer - DEBUG - Received 330 chunks, response length: 1477
2025-04-16 20:39:41,180 - ResumeServer - DEBUG - Received 340 chunks, response length: 1530
2025-04-16 20:39:41,191 - ResumeServer - DEBUG - Received 350 chunks, response length: 1554
2025-04-16 20:39:41,205 - ResumeServer - DEBUG - Received 360 chunks, response length: 1575
2025-04-16 20:39:41,222 - ResumeServer - DEBUG - Received 370 chunks, response length: 1626
2025-04-16 20:39:41,234 - ResumeServer - DEBUG - Received 380 chunks, response length: 1683
2025-04-16 20:39:41,248 - ResumeServer - DEBUG - Received 390 chunks, response length: 1711
2025-04-16 20:39:41,261 - ResumeServer - DEBUG - Received 400 chunks, response length: 1761
2025-04-16 20:39:41,273 - ResumeServer - DEBUG - Received 410 chunks, response length: 1823
2025-04-16 20:39:41,289 - ResumeServer - DEBUG - Received 420 chunks, response length: 1860
2025-04-16 20:39:41,323 - ResumeServer - DEBUG - Received 430 chunks, response length: 1909
2025-04-16 20:39:41,338 - ResumeServer - DEBUG - Received 440 chunks, response length: 1956
2025-04-16 20:39:41,345 - ResumeServer - DEBUG - Received 450 chunks, response length: 2009
2025-04-16 20:39:41,355 - ResumeServer - DEBUG - Received 460 chunks, response length: 2062
2025-04-16 20:39:41,366 - ResumeServer - DEBUG - Received 470 chunks, response length: 2102
2025-04-16 20:39:41,373 - ResumeServer - DEBUG - Received 480 chunks, response length: 2141
2025-04-16 20:39:41,390 - ResumeServer - DEBUG - Received 490 chunks, response length: 2161
2025-04-16 20:39:41,406 - ResumeServer - DEBUG - Received 500 chunks, response length: 2224
2025-04-16 20:39:41,413 - ResumeServer - DEBUG - Received 510 chunks, response length: 2264
2025-04-16 20:39:41,426 - ResumeServer - DEBUG - Received 520 chunks, response length: 2284
2025-04-16 20:39:41,449 - ResumeServer - DEBUG - Received 530 chunks, response length: 2338
2025-04-16 20:39:41,466 - ResumeServer - DEBUG - Received 540 chunks, response length: 2387
2025-04-16 20:39:41,475 - ResumeServer - DEBUG - Received 550 chunks, response length: 2442
2025-04-16 20:39:41,487 - ResumeServer - DEBUG - Received 560 chunks, response length: 2496
2025-04-16 20:39:41,510 - ResumeServer - DEBUG - Received 570 chunks, response length: 2522
2025-04-16 20:39:41,523 - ResumeServer - DEBUG - Received 580 chunks, response length: 2571
2025-04-16 20:39:41,550 - ResumeServer - DEBUG - Received 590 chunks, response length: 2625
2025-04-16 20:39:41,557 - ResumeServer - DEBUG - Received 600 chunks, response length: 2644
2025-04-16 20:39:41,611 - ResumeServer - DEBUG - Received 610 chunks, response length: 2694
2025-04-16 20:39:41,631 - ResumeServer - DEBUG - Received 620 chunks, response length: 2722
2025-04-16 20:39:41,653 - ResumeServer - DEBUG - Received 630 chunks, response length: 2769
2025-04-16 20:39:41,681 - ResumeServer - DEBUG - Received 640 chunks, response length: 2802
2025-04-16 20:39:41,698 - ResumeServer - DEBUG - Received 650 chunks, response length: 2854
2025-04-16 20:39:41,713 - ResumeServer - DEBUG - Received 660 chunks, response length: 2885
2025-04-16 20:39:41,733 - ResumeServer - DEBUG - Received 670 chunks, response length: 2906
2025-04-16 20:39:41,758 - ResumeServer - DEBUG - Received 680 chunks, response length: 2942
2025-04-16 20:39:41,779 - ResumeServer - DEBUG - Received 690 chunks, response length: 2963
2025-04-16 20:39:41,814 - ResumeServer - DEBUG - Received 700 chunks, response length: 2996
2025-04-16 20:39:41,854 - ResumeServer - DEBUG - Received 710 chunks, response length: 3025
2025-04-16 20:39:41,858 - ResumeServer - DEBUG - Received 720 chunks, response length: 3055
2025-04-16 20:39:41,899 - ResumeServer - DEBUG - Received 730 chunks, response length: 3085
2025-04-16 20:39:41,916 - ResumeServer - DEBUG - Received 740 chunks, response length: 3118
2025-04-16 20:39:41,978 - ResumeServer - DEBUG - Received 750 chunks, response length: 3162
2025-04-16 20:39:42,007 - ResumeServer - DEBUG - Received 760 chunks, response length: 3186
2025-04-16 20:39:42,055 - ResumeServer - DEBUG - Received 770 chunks, response length: 3217
2025-04-16 20:39:42,104 - ResumeServer - DEBUG - Received 780 chunks, response length: 3243
2025-04-16 20:39:42,125 - ResumeServer - DEBUG - Received 790 chunks, response length: 3283
2025-04-16 20:39:42,158 - ResumeServer - DEBUG - Received 800 chunks, response length: 3301
2025-04-16 20:39:42,215 - ResumeServer - DEBUG - Received 810 chunks, response length: 3345
2025-04-16 20:39:42,240 - ResumeServer - DEBUG - Received 820 chunks, response length: 3386
2025-04-16 20:39:42,253 - ResumeServer - DEBUG - Received 830 chunks, response length: 3410
2025-04-16 20:39:42,278 - ResumeServer - DEBUG - Received 840 chunks, response length: 3447
2025-04-16 20:39:42,323 - ResumeServer - DEBUG - Received 850 chunks, response length: 3482
2025-04-16 20:39:42,344 - ResumeServer - DEBUG - Received 860 chunks, response length: 3502
2025-04-16 20:39:42,388 - ResumeServer - DEBUG - Received 870 chunks, response length: 3532
2025-04-16 20:39:42,409 - ResumeServer - DEBUG - Received 880 chunks, response length: 3568
2025-04-16 20:39:42,420 - ResumeServer - DEBUG - Received 890 chunks, response length: 3595
2025-04-16 20:39:42,435 - ResumeServer - DEBUG - Received 900 chunks, response length: 3639
2025-04-16 20:39:42,483 - ResumeServer - DEBUG - Received 910 chunks, response length: 3673
2025-04-16 20:39:42,521 - ResumeServer - DEBUG - Received 920 chunks, response length: 3714
2025-04-16 20:39:42,553 - ResumeServer - DEBUG - Received 930 chunks, response length: 3742
2025-04-16 20:39:42,588 - ResumeServer - DEBUG - Received 940 chunks, response length: 3773
2025-04-16 20:39:42,609 - ResumeServer - DEBUG - Received 950 chunks, response length: 3790
2025-04-16 20:39:42,642 - ResumeServer - DEBUG - Received 960 chunks, response length: 3834
2025-04-16 20:39:42,681 - ResumeServer - DEBUG - Received 970 chunks, response length: 3871
2025-04-16 20:39:42,704 - ResumeServer - DEBUG - Received 980 chunks, response length: 3898
2025-04-16 20:39:42,753 - ResumeServer - DEBUG - Received 990 chunks, response length: 3936
2025-04-16 20:39:42,790 - ResumeServer - DEBUG - Received 1000 chunks, response length: 3959
2025-04-16 20:39:42,812 - ResumeServer - DEBUG - Received 1010 chunks, response length: 3994
2025-04-16 20:39:42,850 - ResumeServer - DEBUG - Received 1020 chunks, response length: 4028
2025-04-16 20:39:42,887 - ResumeServer - DEBUG - Received 1030 chunks, response length: 4066
2025-04-16 20:39:42,917 - ResumeServer - DEBUG - Received 1040 chunks, response length: 4098
2025-04-16 20:39:42,983 - ResumeServer - DEBUG - Received 1050 chunks, response length: 4145
2025-04-16 20:39:43,010 - ResumeServer - DEBUG - Received 1060 chunks, response length: 4175
2025-04-16 20:39:43,057 - ResumeServer - DEBUG - Received 1070 chunks, response length: 4214
2025-04-16 20:39:44,533 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 20:39:44,534 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 20:39:44,535 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 20:39:44,536 - ResumeServer - INFO - Response collection complete. Total 1072 chunks, final length: 4215
2025-04-16 20:39:44,537 - ResumeServer - INFO - Response preview: <h2>Results-driven Machine Learning Engineer</h2>
<strong>Address:</strong> Austin, TX 
<strong>Phon...
2025-04-16 20:39:44,550 - ResumeServer - INFO - Building PDF document...
2025-04-16 20:39:44,587 - ResumeServer - INFO - PDF generation successful, size: 6212 bytes
2025-04-16 20:39:44,589 - ResumeServer - INFO - Resume generated successfully. PDF size: 6212 bytes
2025-04-16 20:39:44,590 - ResumeServer - DEBUG - Converting response to JSON
2025-04-16 20:39:44,592 - ResumeServer - DEBUG - Response headers set: application/json
2025-04-16 20:39:44,593 - ResumeServer - INFO - Successfully sent PDF response
2025-04-16 20:39:44,598 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpoy6n8ahb
2025-04-16 20:39:44,613 - ResumeServer - INFO - GET request for /history
2025-04-16 20:39:44,615 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:39:46,163 - ResumeServer - INFO - GET request for /download/undefined
2025-04-16 20:39:46,164 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:39:58,480 - ResumeServer - INFO - GET request for /download/undefined
2025-04-16 20:39:58,481 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:40:00,849 - ResumeServer - INFO - GET request for /download/undefined
2025-04-16 20:40:00,850 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:40:10,406 - ResumeServer - INFO - POST request to /generate (Content-Length: 9309)
2025-04-16 20:40:10,407 - ResumeServer - INFO - Processing /generate request
2025-04-16 20:40:10,408 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpooqdlkid
2025-04-16 20:40:10,408 - ResumeServer - DEBUG - Parsing form data
2025-04-16 20:40:10,414 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 20:40:10,415 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=posting.txt
2025-04-16 20:40:10,415 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 20:40:10,418 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 20:40:10,420 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmpooqdlkid\template.txt
2025-04-16 20:40:10,421 - ResumeServer - INFO - Generating resume...
2025-04-16 20:40:10,424 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:40:10,427 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:40:10,430 - ResumeServer - DEBUG - Template content length: 2198 chars
2025-04-16 20:40:10,430 - ResumeServer - INFO - Initializing Groq client...
2025-04-16 20:40:11,239 - ResumeServer - INFO - Preparing messages for AI request...
2025-04-16 20:40:11,240 - ResumeServer - DEBUG - Using template in prompt
2025-04-16 20:40:11,241 - ResumeServer - INFO - Sending request to Groq API...
2025-04-16 20:40:11,244 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "Respond with 'test ok'"}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 10, 'stream': False}}
2025-04-16 20:40:11,247 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 20:40:11,248 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-04-16 20:40:11,291 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC161BC50>
2025-04-16 20:40:11,292 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EFC13E8E50> server_hostname='api.groq.com' timeout=5.0
2025-04-16 20:40:11,355 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EFC161BB30>
2025-04-16 20:40:11,358 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 20:40:11,360 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 20:40:11,361 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 20:40:11,362 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 20:40:11,363 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 20:40:11,512 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 15:10:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'93149ba969a27e98-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'997'), (b'X-Ratelimit-Remaining-Tokens', b'11990'), (b'X-Ratelimit-Reset-Requests', b'3m48.076999999s'), (b'X-Ratelimit-Reset-Tokens', b'50ms'), (b'X-Request-Id', b'req_01jrzjd1g3fsyr6y1njwr2ayzd'), (b'Set-Cookie', b'__cf_bm=27fTx7i1dm1NdxLnwjTqWLFzWYj7tGm7Q9ggflGqZdI-1744816211-1.0.1.1-WfjGZh1BYKdhNLZR2xVjhm.yBT_EWsnbapvYpEBWI3B8x2_2rVxhBLmAYZazXAL3whT3ABZ4i4ejyIh5Of30AXfnxTe0HSueFeT6ndqnDkY; path=/; expires=Wed, 16-Apr-25 15:40:11 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 20:40:11,518 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 20:40:11,520 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 20:40:11,522 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 20:40:11,524 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 20:40:11,525 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 20:40:11,526 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 15:10:11 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '93149ba969a27e98-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '997', 'x-ratelimit-remaining-tokens': '11990', 'x-ratelimit-reset-requests': '3m48.076999999s', 'x-ratelimit-reset-tokens': '50ms', 'x-request-id': 'req_01jrzjd1g3fsyr6y1njwr2ayzd', 'set-cookie': '__cf_bm=27fTx7i1dm1NdxLnwjTqWLFzWYj7tGm7Q9ggflGqZdI-1744816211-1.0.1.1-WfjGZh1BYKdhNLZR2xVjhm.yBT_EWsnbapvYpEBWI3B8x2_2rVxhBLmAYZazXAL3whT3ABZ4i4ejyIh5Of30AXfnxTe0HSueFeT6ndqnDkY; path=/; expires=Wed, 16-Apr-25 15:40:11 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 20:40:11,534 - ResumeServer - INFO - API test successful: test ok
2025-04-16 20:40:11,535 - ResumeServer - INFO - Creating streaming completion...
2025-04-16 20:40:11,544 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a resume assistant. Format your response with HTML tags for styling. Use <strong> for bold, <h2> for section headers, <ul> and <li> for lists. Provide ONLY the resume content, no analysis or insights. Start directly with the resume content.'}, {'role': 'user', 'content': 'Create a tailored resume based on this resume and job description, following this template structure. Format the response with HTML tags. Provide ONLY the resume content, no analysis or insights.\n\nResume:\n\nResults-driven Machine Learning Engineer with 4+ years of experience developing and deploying AI models for diverse applications, including computer vision, NLP, and predictive analytics. Skilled in Python, TensorFlow, and cloud platforms like GCP. Adept at translating complex data into actionable insights and thriving in collaborative, fast-paced environments.\n\nProfessional Experience\n\nMachine Learning Engineer\n\nNexGen Technologies, Austin, TX\n\nAugust 2021 – Present\n\nBuilt convolutional neural networks (CNNs) with TensorFlow for image classification, achieving 92% accuracy on a custom dataset for retail product recognition.\nDesigned and deployed NLP models using BERT and Hugging Face for automated customer support, reducing response times by 40%.\nImplemented MLOps pipelines with Kubeflow and GCP, automating model retraining and monitoring for production systems.\nPreprocessed terabyte-scale datasets with Apache Spark, optimizing data pipelines for faster model training.\nMentored junior engineers on best practices for model development and version control with Git.\nData Scientist\n\nInsight Analytics, San Francisco, CA (Remote)\n\nJune 2020 – July 2021\n\nDeveloped time-series forecasting models with PyTorch to predict inventory demand, improving supply chain efficiency by 20%.\nConducted exploratory data analysis with pandas and SQL, uncovering trends that informed marketing strategies.\nCreated interactive dashboards with Plotly and Tableau to visualize model outputs for executive stakeholders.\nCollaborated with software engineers to integrate ML models into web applications using Flask APIs.\nResearch Intern, AI Lab\n\nStanford University, Stanford, CA\n\nJanuary 2019 – May 2020\n\nContributed to research on reinforcement learning algorithms, co-authoring a paper presented at NeurIPS 2020.\nBuilt simulation environments with OpenAI Gym to test agent performance in dynamic scenarios.\nOptimized model training workflows, reducing compute costs by 15% through efficient resource allocation.\nEducation\n\nMaster of Science in Artificial Intelligence\n\nCarnegie Mellon University, Pittsburgh, PA\n\nGraduated: May 2020\n\nFocus: Deep Learning and Reinforcement Learning\nCapstone Project: “Scalable RL Models for Autonomous Navigation”\nBachelor of Science in Computer Science\n\nUniversity of Texas at Austin, Austin, TX\n\nGraduated: May 2018\n\nMinor in Applied Mathematics\nSkills\n\nProgramming: Python, C++, SQL, Bash\nML Frameworks: TensorFlow, PyTorch, scikit-learn, Hugging Face, OpenCV\nCloud Platforms: Google Cloud Platform (AI Platform, BigQuery), AWS, Azure\nTools: Docker, Jenkins, MLflow, Git, Jupyter, Tableau\nData Processing: pandas, NumPy, Spark, Dask\nDomains: Computer Vision, NLP, Reinforcement Learning, Time-Series Analysis\nProjects\n\nAutonomous Drone Navigation (GitHub: github.com/alexcarter/drone-ai)\nDeveloped a reinforcement learning model with PyTorch to train drones for obstacle avoidance, tested in simulated environments.\nText Summarization Tool\nBuilt an NLP pipeline with Hugging Face transformers to generate concise summaries of news articles, deployed as a web app with Streamlit.\nFacial Recognition System\nCreated a real-time face detection model using OpenCV and TensorFlow, achieving 95% accuracy on public datasets.\nCertifications\n\nGoogle Cloud Professional Machine Learning Engineer (2023)\nCoursera: Deep Learning Specialization by Andrew Ng (2020)\nPublications & Talks\n\nCo-author, “Advances in Scalable Reinforcement Learning for Robotics,” NeurIPS 2020.\nGuest Speaker, “MLOps for Beginners,” Austin AI Meetup, March 2023.\nAdditional Information\n\nActive contributor to PyTorch (3 pull requests merged).\nVolunteer mentor at Code2AI, teaching high school students ML basics.\nProficient in French; conversational in Japanese.\n\nJob Description:\n\nJob Title: Machine Learning Engineer\n\nCompany: InnovateAI Solutions\n\nLocation: Remote (US-based preferred)\n\nPosted: April 15, 2025\n\nEmployment Type: Full-Time\n\nAbout InnovateAI Solutions:\n\nInnovateAI Solutions is a fast-growing tech company specializing in cutting-edge AI-driven products for healthcare and finance. Our mission is to empower businesses with intelligent solutions that transform industries.\n\nJob Description:\n\nWe are seeking a talented Machine Learning Engineer to join our AI Development team. You will design, develop, and deploy machine learning models to solve complex problems in predictive analytics and natural language processing. This role offers the opportunity to work on impactful projects with a collaborative, innovative team.\n\nKey Responsibilities:\n\nDevelop and optimize machine learning models for tasks such as classification, regression, and NLP.\nCollaborate with data scientists and software engineers to integrate models into production systems.\nConduct experiments to evaluate model performance and iterate on improvements.\nPreprocess and analyze large datasets to extract meaningful insights.\nStay updated on the latest AI/ML research and apply relevant advancements to projects.\nDocument processes and communicate findings to technical and non-technical stakeholders.\nQualifications:\n\nBachelor’s or Master’s degree in Computer Science, Data Science, or a related field.\n3+ years of experience building and deploying machine learning models.\nProficiency in Python and libraries such as TensorFlow, PyTorch, or scikit-learn.\nExperience with cloud platforms (e.g., AWS, Azure, or GCP) for model deployment.\nStrong understanding of algorithms, data structures, and statistics.\nFamiliarity with NLP techniques and tools (e.g., Hugging Face, spaCy) is a plus.\nExcellent problem-solving skills and ability to work in a fast-paced environment.\nPreferred Skills:\n\nExperience with MLOps tools (e.g., Kubeflow, MLflow).\nKnowledge of big data frameworks (e.g., Spark, Hadoop).\nContributions to open-source AI/ML projects or publications in relevant fields.\nBenefits:\n\nCompetitive salary and equity options.\nComprehensive health, dental, and vision insurance.\nFlexible work-from-home policy.\nAnnual learning stipend for professional development.\nCollaborative and inclusive team culture.\nHow to Apply:\n\nPlease submit your resume and a cover letter to careers@innovateai.com. Include links to your GitHub, LinkedIn, or portfolio if applicable. Applications will be reviewed on a rolling basis.\n\nInnovateAI Solutions is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.\n\nTemplate:\n\nJanna Gardner\n4567 Main Street, Chicago, Illinois 98052 • (716) 555-0100 • janna@example.com\n\nHuman Resources Generalist with 6+ years of experience assisting with and fulfilling organization staffing needs and requirements. A proven track record of using my excellent personal, communication and organization skills to lead and improve HR departments, recruit excellent personnel, and improve department efficiencies. Team player with excellent communication skills, high quality of work, driven and highly self-motivated. Strong negotiating skills and business acumen and able to work independently.\nExperience\n20XX – PRESENT\nHuman Resources Generalist | Lamna Healthcare Company | Chicago, Illinois\nReview, update, and revise company hiring practices, vacation, and other human resources policies to ensure compliance with OSHA and all local, state, and federal labor regulations. By creating and maintaining a positive and responsive work environment, we raised employee retention rates by over 10% to achieve a greater than 90% employee retention over a 2-year period. Developed recruitment programs to successfully increase minority recruitment and meet affirmative action requirements. Led development team to build and deploy a dedicated recruitment website which reduced year-over-year recruitment costs by 14%.\nJUNE 20XX – AUGUST 20XX\nHuman Resources Intern | Wholeness Healthcare | Boomtown, Ohio\nAssisted in recruitment outreach to prospective employees. Organized and conducted several seminars for hospital employees to educate and update them regarding available employment benefit options. Arranged hospital-wide guest speakers symposia to educate management about new employment laws and workplace confidence and morale building techniques. Administrative tasks.\nSkills\nType 96 words per minute • Proficient with project management software • Team player • Excellent time management skills • Conflict management • Public speaking • Data analytics \nEducation\nMAY 20XX\nBachelor of Arts Human Resources Management | Jasper University | Ft. Lauderdale, FL\n3.8 GPA • Member of university’s Honor Society\nActivities\nLiterature • Environmental conservation • Art • Yoga • Skiing • Travel\n'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2048, 'stream': True, 'temperature': 0.1, 'top_p': 1}}
2025-04-16 20:40:11,576 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-04-16 20:40:11,578 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-16 20:40:11,582 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-16 20:40:11,584 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-16 20:40:11,586 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-16 20:40:11,588 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-16 20:40:11,784 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 16 Apr 2025 15:10:11 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-Ray', b'93149baadb027e98-MAA'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Cache-Control', b'no-cache'), (b'Vary', b'Origin, Accept-Encoding'), (b'X-Groq-Region', b'gcp-asia-south1'), (b'X-Ratelimit-Limit-Requests', b'1000'), (b'X-Ratelimit-Limit-Tokens', b'12000'), (b'X-Ratelimit-Remaining-Requests', b'996'), (b'X-Ratelimit-Remaining-Tokens', b'9696'), (b'X-Ratelimit-Reset-Requests', b'5m45.321s'), (b'X-Ratelimit-Reset-Tokens', b'11.518s'), (b'X-Request-Id', b'req_01jrzjd1rvfhxtp5tk0fbgf13c'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-16 20:40:11,789 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-16 20:40:11,791 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 16 Apr 2025 15:10:11 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '93149baadb027e98-MAA', 'cf-cache-status': 'DYNAMIC', 'cache-control': 'no-cache', 'vary': 'Origin, Accept-Encoding', 'x-groq-region': 'gcp-asia-south1', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '996', 'x-ratelimit-remaining-tokens': '9696', 'x-ratelimit-reset-requests': '5m45.321s', 'x-ratelimit-reset-tokens': '11.518s', 'x-request-id': 'req_01jrzjd1rvfhxtp5tk0fbgf13c', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-04-16 20:40:11,796 - ResumeServer - INFO - Collecting response chunks...
2025-04-16 20:40:11,798 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-16 20:40:11,968 - ResumeServer - DEBUG - Received 10 chunks, response length: 44
2025-04-16 20:40:11,990 - ResumeServer - DEBUG - Received 20 chunks, response length: 77
2025-04-16 20:40:12,027 - ResumeServer - DEBUG - Received 30 chunks, response length: 110
2025-04-16 20:40:12,038 - ResumeServer - DEBUG - Received 40 chunks, response length: 129
2025-04-16 20:40:12,051 - ResumeServer - DEBUG - Received 50 chunks, response length: 158
2025-04-16 20:40:12,072 - ResumeServer - DEBUG - Received 60 chunks, response length: 197
2025-04-16 20:40:12,089 - ResumeServer - DEBUG - Received 70 chunks, response length: 248
2025-04-16 20:40:12,108 - ResumeServer - DEBUG - Received 80 chunks, response length: 315
2025-04-16 20:40:12,127 - ResumeServer - DEBUG - Received 90 chunks, response length: 365
2025-04-16 20:40:12,140 - ResumeServer - DEBUG - Received 100 chunks, response length: 418
2025-04-16 20:40:12,152 - ResumeServer - DEBUG - Received 110 chunks, response length: 457
2025-04-16 20:40:12,169 - ResumeServer - DEBUG - Received 120 chunks, response length: 537
2025-04-16 20:40:12,188 - ResumeServer - DEBUG - Received 130 chunks, response length: 581
2025-04-16 20:40:12,208 - ResumeServer - DEBUG - Received 140 chunks, response length: 607
2025-04-16 20:40:12,225 - ResumeServer - DEBUG - Received 150 chunks, response length: 655
2025-04-16 20:40:12,260 - ResumeServer - DEBUG - Received 160 chunks, response length: 691
2025-04-16 20:40:12,280 - ResumeServer - DEBUG - Received 170 chunks, response length: 736
2025-04-16 20:40:12,297 - ResumeServer - DEBUG - Received 180 chunks, response length: 791
2025-04-16 20:40:12,313 - ResumeServer - DEBUG - Received 190 chunks, response length: 842
2025-04-16 20:40:12,328 - ResumeServer - DEBUG - Received 200 chunks, response length: 879
2025-04-16 20:40:12,354 - ResumeServer - DEBUG - Received 210 chunks, response length: 922
2025-04-16 20:40:12,368 - ResumeServer - DEBUG - Received 220 chunks, response length: 986
2025-04-16 20:40:12,379 - ResumeServer - DEBUG - Received 230 chunks, response length: 1003
2025-04-16 20:40:12,395 - ResumeServer - DEBUG - Received 240 chunks, response length: 1048
2025-04-16 20:40:12,409 - ResumeServer - DEBUG - Received 250 chunks, response length: 1096
2025-04-16 20:40:12,429 - ResumeServer - DEBUG - Received 260 chunks, response length: 1132
2025-04-16 20:40:12,452 - ResumeServer - DEBUG - Received 270 chunks, response length: 1187
2025-04-16 20:40:12,467 - ResumeServer - DEBUG - Received 280 chunks, response length: 1246
2025-04-16 20:40:12,478 - ResumeServer - DEBUG - Received 290 chunks, response length: 1285
2025-04-16 20:40:12,492 - ResumeServer - DEBUG - Received 300 chunks, response length: 1349
2025-04-16 20:40:12,512 - ResumeServer - DEBUG - Received 310 chunks, response length: 1371
2025-04-16 20:40:12,526 - ResumeServer - DEBUG - Received 320 chunks, response length: 1412
2025-04-16 20:40:12,538 - ResumeServer - DEBUG - Received 330 chunks, response length: 1455
2025-04-16 20:40:12,555 - ResumeServer - DEBUG - Received 340 chunks, response length: 1483
2025-04-16 20:40:12,564 - ResumeServer - DEBUG - Received 350 chunks, response length: 1538
2025-04-16 20:40:12,574 - ResumeServer - DEBUG - Received 360 chunks, response length: 1596
2025-04-16 20:40:12,583 - ResumeServer - DEBUG - Received 370 chunks, response length: 1619
2025-04-16 20:40:12,598 - ResumeServer - DEBUG - Received 380 chunks, response length: 1674
2025-04-16 20:40:12,614 - ResumeServer - DEBUG - Received 390 chunks, response length: 1727
2025-04-16 20:40:12,632 - ResumeServer - DEBUG - Received 400 chunks, response length: 1774
2025-04-16 20:40:12,644 - ResumeServer - DEBUG - Received 410 chunks, response length: 1840
2025-04-16 20:40:12,653 - ResumeServer - DEBUG - Received 420 chunks, response length: 1865
2025-04-16 20:40:12,674 - ResumeServer - DEBUG - Received 430 chunks, response length: 1934
2025-04-16 20:40:12,689 - ResumeServer - DEBUG - Received 440 chunks, response length: 1972
2025-04-16 20:40:12,704 - ResumeServer - DEBUG - Received 450 chunks, response length: 1996
2025-04-16 20:40:12,723 - ResumeServer - DEBUG - Received 460 chunks, response length: 2031
2025-04-16 20:40:12,744 - ResumeServer - DEBUG - Received 470 chunks, response length: 2073
2025-04-16 20:40:12,773 - ResumeServer - DEBUG - Received 480 chunks, response length: 2127
2025-04-16 20:40:12,783 - ResumeServer - DEBUG - Received 490 chunks, response length: 2176
2025-04-16 20:40:12,794 - ResumeServer - DEBUG - Received 500 chunks, response length: 2196
2025-04-16 20:40:12,805 - ResumeServer - DEBUG - Received 510 chunks, response length: 2247
2025-04-16 20:40:12,814 - ResumeServer - DEBUG - Received 520 chunks, response length: 2299
2025-04-16 20:40:12,822 - ResumeServer - DEBUG - Received 530 chunks, response length: 2348
2025-04-16 20:40:12,837 - ResumeServer - DEBUG - Received 540 chunks, response length: 2407
2025-04-16 20:40:12,846 - ResumeServer - DEBUG - Received 550 chunks, response length: 2434
2025-04-16 20:40:12,865 - ResumeServer - DEBUG - Received 560 chunks, response length: 2456
2025-04-16 20:40:12,884 - ResumeServer - DEBUG - Received 570 chunks, response length: 2510
2025-04-16 20:40:12,897 - ResumeServer - DEBUG - Received 580 chunks, response length: 2560
2025-04-16 20:40:12,933 - ResumeServer - DEBUG - Received 590 chunks, response length: 2592
2025-04-16 20:40:12,945 - ResumeServer - DEBUG - Received 600 chunks, response length: 2627
2025-04-16 20:40:12,981 - ResumeServer - DEBUG - Received 610 chunks, response length: 2664
2025-04-16 20:40:13,010 - ResumeServer - DEBUG - Received 620 chunks, response length: 2704
2025-04-16 20:40:13,036 - ResumeServer - DEBUG - Received 630 chunks, response length: 2740
2025-04-16 20:40:13,057 - ResumeServer - DEBUG - Received 640 chunks, response length: 2791
2025-04-16 20:40:13,068 - ResumeServer - DEBUG - Received 650 chunks, response length: 2821
2025-04-16 20:40:13,106 - ResumeServer - DEBUG - Received 660 chunks, response length: 2860
2025-04-16 20:40:13,113 - ResumeServer - DEBUG - Received 670 chunks, response length: 2881
2025-04-16 20:40:13,142 - ResumeServer - DEBUG - Received 680 chunks, response length: 2913
2025-04-16 20:40:13,180 - ResumeServer - DEBUG - Received 690 chunks, response length: 2936
2025-04-16 20:40:13,191 - ResumeServer - DEBUG - Received 700 chunks, response length: 2970
2025-04-16 20:40:13,217 - ResumeServer - DEBUG - Received 710 chunks, response length: 2998
2025-04-16 20:40:13,247 - ResumeServer - DEBUG - Received 720 chunks, response length: 3022
2025-04-16 20:40:13,285 - ResumeServer - DEBUG - Received 730 chunks, response length: 3074
2025-04-16 20:40:13,328 - ResumeServer - DEBUG - Received 740 chunks, response length: 3103
2025-04-16 20:40:13,364 - ResumeServer - DEBUG - Received 750 chunks, response length: 3132
2025-04-16 20:40:13,422 - ResumeServer - DEBUG - Received 760 chunks, response length: 3162
2025-04-16 20:40:13,453 - ResumeServer - DEBUG - Received 770 chunks, response length: 3197
2025-04-16 20:40:13,482 - ResumeServer - DEBUG - Received 780 chunks, response length: 3221
2025-04-16 20:40:13,507 - ResumeServer - DEBUG - Received 790 chunks, response length: 3254
2025-04-16 20:40:13,550 - ResumeServer - DEBUG - Received 800 chunks, response length: 3304
2025-04-16 20:40:13,578 - ResumeServer - DEBUG - Received 810 chunks, response length: 3329
2025-04-16 20:40:13,598 - ResumeServer - DEBUG - Received 820 chunks, response length: 3347
2025-04-16 20:40:13,624 - ResumeServer - DEBUG - Received 830 chunks, response length: 3379
2025-04-16 20:40:13,686 - ResumeServer - DEBUG - Received 840 chunks, response length: 3422
2025-04-16 20:40:13,718 - ResumeServer - DEBUG - Received 850 chunks, response length: 3450
2025-04-16 20:40:13,726 - ResumeServer - DEBUG - Received 860 chunks, response length: 3474
2025-04-16 20:40:13,762 - ResumeServer - DEBUG - Received 870 chunks, response length: 3506
2025-04-16 20:40:13,772 - ResumeServer - DEBUG - Received 880 chunks, response length: 3541
2025-04-16 20:40:13,808 - ResumeServer - DEBUG - Received 890 chunks, response length: 3570
2025-04-16 20:40:13,820 - ResumeServer - DEBUG - Received 900 chunks, response length: 3587
2025-04-16 20:40:13,874 - ResumeServer - DEBUG - Received 910 chunks, response length: 3647
2025-04-16 20:40:13,888 - ResumeServer - DEBUG - Received 920 chunks, response length: 3666
2025-04-16 20:40:13,930 - ResumeServer - DEBUG - Received 930 chunks, response length: 3714
2025-04-16 20:40:13,953 - ResumeServer - DEBUG - Received 940 chunks, response length: 3738
2025-04-16 20:40:13,989 - ResumeServer - DEBUG - Received 950 chunks, response length: 3764
2025-04-16 20:40:14,035 - ResumeServer - DEBUG - Received 960 chunks, response length: 3792
2025-04-16 20:40:14,079 - ResumeServer - DEBUG - Received 970 chunks, response length: 3844
2025-04-16 20:40:14,095 - ResumeServer - DEBUG - Received 980 chunks, response length: 3864
2025-04-16 20:40:14,125 - ResumeServer - DEBUG - Received 990 chunks, response length: 3900
2025-04-16 20:40:14,195 - ResumeServer - DEBUG - Received 1000 chunks, response length: 3931
2025-04-16 20:40:14,200 - ResumeServer - DEBUG - Received 1010 chunks, response length: 3959
2025-04-16 20:40:14,218 - ResumeServer - DEBUG - Received 1020 chunks, response length: 3987
2025-04-16 20:40:14,261 - ResumeServer - DEBUG - Received 1030 chunks, response length: 4025
2025-04-16 20:40:14,292 - ResumeServer - DEBUG - Received 1040 chunks, response length: 4058
2025-04-16 20:40:14,378 - ResumeServer - DEBUG - Received 1050 chunks, response length: 4104
2025-04-16 20:40:14,396 - ResumeServer - DEBUG - Received 1060 chunks, response length: 4136
2025-04-16 20:40:14,456 - ResumeServer - DEBUG - Received 1070 chunks, response length: 4187
2025-04-16 20:40:15,822 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-16 20:40:15,823 - httpcore.http11 - DEBUG - response_closed.started
2025-04-16 20:40:15,823 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-16 20:40:15,824 - ResumeServer - INFO - Response collection complete. Total 1076 chunks, final length: 4196
2025-04-16 20:40:15,824 - ResumeServer - INFO - Response preview: <h2>Results-Driven Machine Learning Engineer</h2>
<strong>Alex Carter</strong>
123 Main Street, Aust...
2025-04-16 20:40:15,831 - ResumeServer - INFO - Building PDF document...
2025-04-16 20:40:15,852 - ResumeServer - INFO - PDF generation successful, size: 6110 bytes
2025-04-16 20:40:15,853 - ResumeServer - INFO - Resume generated successfully. PDF size: 6110 bytes
2025-04-16 20:40:15,853 - ResumeServer - DEBUG - Converting response to JSON
2025-04-16 20:40:15,856 - ResumeServer - DEBUG - Response headers set: application/json
2025-04-16 20:40:15,856 - ResumeServer - INFO - Successfully sent PDF response
2025-04-16 20:40:15,858 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpooqdlkid
2025-04-16 20:40:15,867 - ResumeServer - INFO - GET request for /history
2025-04-16 20:40:15,868 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:40:17,198 - ResumeServer - INFO - GET request for /download/undefined
2025-04-16 20:40:17,199 - ResumeServer - ERROR - Error 404: Not Found
2025-04-16 20:40:59,569 - ResumeServer - INFO - POST request to /generate (Content-Length: 56870)
2025-04-16 20:40:59,573 - ResumeServer - INFO - Processing /generate request
2025-04-16 20:40:59,584 - ResumeServer - DEBUG - Created temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpnxja5s83
2025-04-16 20:40:59,613 - ResumeServer - DEBUG - Parsing form data
2025-04-16 20:40:59,633 - ResumeServer - DEBUG - Form fields: ['job_desc', 'template', 'resume']
2025-04-16 20:40:59,648 - ResumeServer - INFO - Got files: resume=resume.txt, job_desc=posting.txt
2025-04-16 20:40:59,651 - ResumeServer - DEBUG - Saving uploaded files...
2025-04-16 20:40:59,669 - ResumeServer - DEBUG - Files saved successfully
2025-04-16 20:40:59,676 - ResumeServer - DEBUG - Template file saved: C:\Users\Rohith\AppData\Local\Temp\tmpnxja5s83\template.txt
2025-04-16 20:40:59,740 - ResumeServer - INFO - Generating resume...
2025-04-16 20:40:59,791 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:40:59,815 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:40:59,864 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:40:59,877 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    self.send_header('Access-Control-Allow-Origin', '*')
                           ~~~~~~~~~~~~~~~^~~~~
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:40:59,881 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 20:41:01,884 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:41:01,885 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:41:01,887 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:41:01,889 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    self.send_header('Access-Control-Allow-Origin', '*')
                           ~~~~~~~~~~~~~~~^~~~~
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:41:01,892 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 20:41:03,895 - ResumeServer - DEBUG - Resume content length: 3757 chars
2025-04-16 20:41:03,896 - ResumeServer - DEBUG - Job description content length: 2672 chars
2025-04-16 20:41:03,897 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:41:03,898 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    self.send_header('Access-Control-Allow-Origin', '*')
                           ~~~~~~~~~~~~~~~^~~~~
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:41:03,899 - ResumeServer - ERROR - Error generating resume: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:41:03,900 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 320, in do_POST
  File "D:\resume\resumeBuilder.py", line 455, in generate_resume
    self.send_header('Access-Control-Allow-Origin', '*')
                           ~~~~~~~~~~~~~~~^~~~~
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte

2025-04-16 20:41:03,903 - ResumeServer - ERROR - Error 500: Error generating resume: 'utf-8' codec can't decode byte 0xca in position 10: invalid continuation byte
2025-04-16 20:41:03,904 - ResumeServer - DEBUG - Cleaned up temp directory: C:\Users\Rohith\AppData\Local\Temp\tmpnxja5s83
2025-04-16 20:43:40,546 - ResumeServer - INFO - Server running on http://localhost:8000
2025-04-16 20:43:57,676 - ResumeServer - INFO - Loading history from file
2025-04-16 20:43:57,679 - ResumeServer - INFO - Loaded 1 history items
2025-04-16 20:44:23,464 - ResumeServer - INFO - Created temporary directory: C:\Users\Rohith\AppData\Local\Temp\tmpigd15teo
2025-04-16 20:44:23,471 - ResumeServer - INFO - Saved resume file to C:\Users\Rohith\AppData\Local\Temp\tmpigd15teo\resume.txt
2025-04-16 20:44:23,472 - ResumeServer - INFO - Saved job description file to C:\Users\Rohith\AppData\Local\Temp\tmpigd15teo\job_desc.txt
2025-04-16 20:44:23,474 - ResumeServer - INFO - Saved template file to C:\Users\Rohith\AppData\Local\Temp\tmpigd15teo\template.txt
2025-04-16 20:44:23,475 - ResumeServer - INFO - Reading template file: C:\Users\Rohith\AppData\Local\Temp\tmpigd15teo\template.txt
2025-04-16 20:44:23,478 - ResumeServer - INFO - Read TXT file successfully: 2198 characters
2025-04-16 20:44:23,478 - ResumeServer - INFO - Template text length: 2198
2025-04-16 20:44:23,478 - ResumeServer - INFO - Reading resume file
2025-04-16 20:44:23,481 - ResumeServer - INFO - Read TXT file successfully: 3757 characters
2025-04-16 20:44:23,481 - ResumeServer - INFO - Reading job description file
2025-04-16 20:44:23,483 - ResumeServer - INFO - Read TXT file successfully: 2672 characters
2025-04-16 20:44:23,484 - ResumeServer - INFO - Generating resume
2025-04-16 20:44:23,484 - ResumeServer - INFO - Initializing Groq client
2025-04-16 20:44:23,485 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable
2025-04-16 20:44:23,485 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 20:44:25,486 - ResumeServer - INFO - Initializing Groq client
2025-04-16 20:44:25,487 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable
2025-04-16 20:44:25,487 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 20:44:27,489 - ResumeServer - INFO - Initializing Groq client
2025-04-16 20:44:27,490 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable
2025-04-16 20:44:27,490 - ResumeServer - ERROR - Error in do_POST: Failed to generate resume after 3 attempts: The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable
2025-04-16 20:44:27,492 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 354, in generate_resume_with_extracted_text
    client = Groq()
             ^^^^^^
  File "C:\Users\Rohith\AppData\Local\Programs\Python\Python312\Lib\site-packages\groq\_client.py", line 84, in __init__
    raise GroqError(
groq.GroqError: The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 708, in do_POST
    result = generate_resume_with_extracted_text(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\resume\resumeBuilder.py", line 469, in generate_resume_with_extracted_text
    raise Exception(f"Failed to generate resume after {max_retries} attempts: {str(e)}")
Exception: Failed to generate resume after 3 attempts: The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable

2025-04-16 20:44:27,498 - ResumeServer - INFO - Removed temporary directory: C:\Users\Rohith\AppData\Local\Temp\tmpigd15teo
2025-04-16 20:44:32,093 - ResumeServer - INFO - Created temporary directory: C:\Users\Rohith\AppData\Local\Temp\tmpfk7tetfv
2025-04-16 20:44:32,097 - ResumeServer - INFO - Saved resume file to C:\Users\Rohith\AppData\Local\Temp\tmpfk7tetfv\resume.txt
2025-04-16 20:44:32,100 - ResumeServer - INFO - Saved job description file to C:\Users\Rohith\AppData\Local\Temp\tmpfk7tetfv\job_desc.txt
2025-04-16 20:44:32,102 - ResumeServer - INFO - Saved template file to C:\Users\Rohith\AppData\Local\Temp\tmpfk7tetfv\template.txt
2025-04-16 20:44:32,103 - ResumeServer - INFO - Reading template file: C:\Users\Rohith\AppData\Local\Temp\tmpfk7tetfv\template.txt
2025-04-16 20:44:32,105 - ResumeServer - INFO - Read TXT file successfully: 2198 characters
2025-04-16 20:44:32,106 - ResumeServer - INFO - Template text length: 2198
2025-04-16 20:44:32,106 - ResumeServer - INFO - Reading resume file
2025-04-16 20:44:32,109 - ResumeServer - INFO - Read TXT file successfully: 3757 characters
2025-04-16 20:44:32,110 - ResumeServer - INFO - Reading job description file
2025-04-16 20:44:32,113 - ResumeServer - INFO - Read TXT file successfully: 2672 characters
2025-04-16 20:44:32,114 - ResumeServer - INFO - Generating resume
2025-04-16 20:44:32,114 - ResumeServer - INFO - Initializing Groq client
2025-04-16 20:44:32,115 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable
2025-04-16 20:44:32,115 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 20:44:34,116 - ResumeServer - INFO - Initializing Groq client
2025-04-16 20:44:34,116 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable
2025-04-16 20:44:34,117 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 20:44:36,118 - ResumeServer - INFO - Initializing Groq client
2025-04-16 20:44:36,118 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable
2025-04-16 20:44:36,119 - ResumeServer - ERROR - Error in do_POST: Failed to generate resume after 3 attempts: The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable
2025-04-16 20:44:36,120 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 354, in generate_resume_with_extracted_text
    client = Groq()
             ^^^^^^
  File "C:\Users\Rohith\AppData\Local\Programs\Python\Python312\Lib\site-packages\groq\_client.py", line 84, in __init__
    raise GroqError(
groq.GroqError: The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 708, in do_POST
    result = generate_resume_with_extracted_text(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\resume\resumeBuilder.py", line 469, in generate_resume_with_extracted_text
    raise Exception(f"Failed to generate resume after {max_retries} attempts: {str(e)}")
Exception: Failed to generate resume after 3 attempts: The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable

2025-04-16 20:44:36,125 - ResumeServer - INFO - Removed temporary directory: C:\Users\Rohith\AppData\Local\Temp\tmpfk7tetfv
2025-04-16 20:44:40,876 - ResumeServer - INFO - Created temporary directory: C:\Users\Rohith\AppData\Local\Temp\tmpxmqkgnxg
2025-04-16 20:44:40,889 - ResumeServer - INFO - Saved resume file to C:\Users\Rohith\AppData\Local\Temp\tmpxmqkgnxg\resume.txt
2025-04-16 20:44:40,894 - ResumeServer - INFO - Saved job description file to C:\Users\Rohith\AppData\Local\Temp\tmpxmqkgnxg\job_desc.txt
2025-04-16 20:44:40,899 - ResumeServer - INFO - Saved template file to C:\Users\Rohith\AppData\Local\Temp\tmpxmqkgnxg\template.docx
2025-04-16 20:44:40,902 - ResumeServer - INFO - Reading template file: C:\Users\Rohith\AppData\Local\Temp\tmpxmqkgnxg\template.docx
2025-04-16 20:44:41,079 - ResumeServer - INFO - Read DOCX file successfully: 2196 characters
2025-04-16 20:44:41,081 - ResumeServer - INFO - Template text length: 2196
2025-04-16 20:44:41,082 - ResumeServer - INFO - Reading resume file
2025-04-16 20:44:41,090 - ResumeServer - INFO - Read TXT file successfully: 3757 characters
2025-04-16 20:44:41,091 - ResumeServer - INFO - Reading job description file
2025-04-16 20:44:41,097 - ResumeServer - INFO - Read TXT file successfully: 2672 characters
2025-04-16 20:44:41,099 - ResumeServer - INFO - Generating resume
2025-04-16 20:44:41,100 - ResumeServer - INFO - Initializing Groq client
2025-04-16 20:44:41,101 - ResumeServer - ERROR - Error in generate_resume (attempt 1/3): The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable
2025-04-16 20:44:41,103 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 20:44:43,104 - ResumeServer - INFO - Initializing Groq client
2025-04-16 20:44:43,105 - ResumeServer - ERROR - Error in generate_resume (attempt 2/3): The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable
2025-04-16 20:44:43,106 - ResumeServer - INFO - Retrying in 2 seconds...
2025-04-16 20:44:45,108 - ResumeServer - INFO - Initializing Groq client
2025-04-16 20:44:45,108 - ResumeServer - ERROR - Error in generate_resume (attempt 3/3): The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable
2025-04-16 20:44:45,109 - ResumeServer - ERROR - Error in do_POST: Failed to generate resume after 3 attempts: The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable
2025-04-16 20:44:45,111 - ResumeServer - ERROR - Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 354, in generate_resume_with_extracted_text
    client = Groq()
             ^^^^^^
  File "C:\Users\Rohith\AppData\Local\Programs\Python\Python312\Lib\site-packages\groq\_client.py", line 84, in __init__
    raise GroqError(
groq.GroqError: The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\resume\resumeBuilder.py", line 708, in do_POST
    result = generate_resume_with_extracted_text(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\resume\resumeBuilder.py", line 469, in generate_resume_with_extracted_text
    raise Exception(f"Failed to generate resume after {max_retries} attempts: {str(e)}")
Exception: Failed to generate resume after 3 attempts: The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable

2025-04-16 20:44:45,118 - ResumeServer - INFO - Removed temporary directory: C:\Users\Rohith\AppData\Local\Temp\tmpxmqkgnxg
